<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[opengl帧缓冲]]></title>
    <url>%2F2019%2F01%2F04%2Fopengl%E5%B8%A7%E7%BC%93%E5%86%B2%2F</url>
    <content type="text"><![CDATA[缓冲区用于写入颜色值的颜色缓冲、用于写入深度信息的深度缓冲和允许我们根据一些条件丢弃特定片段的模板缓冲。这些缓冲结合起来叫做帧缓冲(Framebuffer)，它被储存在内存中。OpenGL允许我们定义我们自己的帧缓冲，也就是说我们能够定义我们自己的颜色缓冲，甚至是深度缓冲和模板缓冲。 我们目前所做的所有操作都是在默认帧缓冲的渲染缓冲上进行的。默认的帧缓冲是在你创建窗口的时候生成和配置的（GLFW帮我们做了这些）。有了我们自己的帧缓冲，我们就能够有更多方式来渲染了。 创建缓冲区和OpenGL中的其它对象一样，我们会使用一个叫做glGenFramebuffers的函数来创建一个帧缓冲对象(Framebuffer Object, FBO)： unsigned int fbo; glGenFramebuffers(1, &amp;fbo); 这种创建和使用对象的方式我们已经见过很多次了，所以它的使用函数也和其它的对象类似。首先我们创建一个帧缓冲对象，将它绑定为激活的(Active)帧缓冲，做一些操作，之后解绑帧缓冲。我们使用glBindFramebuffer来绑定帧缓冲。 glBindFramebuffer(GL_FRAMEBUFFER, fbo); 在绑定到GL_FRAMEBUFFER目标之后，所有的读取和写入帧缓冲的操作将会影响当前绑定的帧缓冲。 一个完整的帧缓冲需要满足以下的条件： 附加至少一个缓冲（颜色、深度或模板缓冲）。 至少有一个颜色附件(Attachment)。 所有的附件都必须是完整的（保留了内存）。 每个缓冲都应该有相同的样本数。 从上面的条件中可以知道，我们需要为帧缓冲创建一些附件，并将附件附加到帧缓冲上。在完成所有的条件之后，我们可以以GL_FRAMEBUFFER为参数调用glCheckFramebufferStatus，检查帧缓冲是否完整。它将会检测当前绑定的帧缓冲，并返回规范中这些值的其中之一。如果它返回的是GL_FRAMEBUFFER_COMPLETE，帧缓冲就是完整的了。 之后所有的渲染操作将会渲染到当前绑定帧缓冲的附件中。由于我们的帧缓冲不是默认帧缓冲，渲染指令将不会对窗口的视觉输出有任何影响。出于这个原因，渲染到一个不同的帧缓冲被叫做离屏渲染(Off-screen Rendering)。要保证所有的渲染操作在主窗口中有视觉效果，我们需要再次激活默认帧缓冲，将它绑定到0。 glBindFramebuffer(GL_FRAMEBUFFER, 0); 在完成所有的帧缓冲操作之后，不要忘记删除这个帧缓冲对象： glDeleteFramebuffers(1, &amp;fbo);在完整性检查执行之前，我们需要给帧缓冲附加一个附件。附件是一个内存位置，它能够作为帧缓冲的一个缓冲，可以将它想象为一个图像。当创建一个附件的时候我们有两个选项：纹理或渲染缓冲对象(Renderbuffer Object) 纹理附件当把一个纹理附加到帧缓冲的时候，所有的渲染指令将会写入到这个纹理中，就想它是一个普通的颜色/深度或模板缓冲一样。使用纹理的优点是，所有渲染操作的结果将会被储存在一个纹理图像中，我们之后可以在着色器中很方便地使用它。 为帧缓冲创建一个纹理和创建一个普通的纹理差不多：unsigned int texture; glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 主要的区别就是，我们将维度设置为了屏幕大小（，并且我们给纹理的data参数传递了NULL。对于这个纹理，我们仅仅分配了内存而没有填充它。填充这个纹理将会在我们渲染到帧缓冲之后来进行。同样注意我们并不关心环绕方式或多级渐远纹理，我们在大多数情况下都不会需要它们。 如果你想将你的屏幕渲染到一个更小或更大的纹理上，你需要（在渲染到你的帧缓冲之前）再次调用glViewport，使用纹理的新维度作为参数，否则只有一小部分的纹理或屏幕会被渲染到这个纹理上。 现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texture, 0); glFrameBufferTexture2D有以下的参数： target：帧缓冲的目标（绘制、读取或者两者皆有）attachment：我们想要附加的附件类型。当前我们正在附加一个颜色附件。注意最后的0意味着我们可以附加多个颜色附件。我们将在之后的教程中提到。textarget：你希望附加的纹理类型texture：要附加的纹理本身level：多级渐远纹理的级别。我们将它保留为0。除了颜色附件之外，我们还可以附加一个深度和模板缓冲纹理到帧缓冲对象中。要附加深度缓冲的话，我们将附件类型设置为GL_DEPTH_ATTACHMENT。注意纹理的格式(Format)和内部格式(Internalformat)类型将变为GL_DEPTH_COMPONENT，来反映深度缓冲的储存格式。要附加模板缓冲的话，你要将第二个参数设置为GL_STENCIL_ATTACHMENT，并将纹理的格式设定为GL_STENCIL_INDEX。 也可以将深度缓冲和模板缓冲附加为一个单独的纹理。纹理的每32位数值将包含24位的深度信息和8位的模板信息。要将深度和模板缓冲附加为一个纹理的话，我们使用GL_DEPTH_STENCIL_ATTACHMENT类型，并配置纹理的格式，让它包含合并的深度和模板值。将一个深度和模板缓冲附加为一个纹理到帧缓冲的例子可以在下面找到： glTexImage2D( GL_TEXTURE_2D, 0, GL_DEPTH24_STENCIL8, 800, 600, 0, GL_DEPTH_STENCIL, GL_UNSIGNED_INT_24_8, NULL ); glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_TEXTURE_2D, texture, 0); 渲染缓冲对象附件渲染缓冲对象(Renderbuffer Object)是在纹理之后引入到OpenGL中，作为一个可用的帧缓冲附件类型的，所以在过去纹理是唯一可用的附件。和纹理图像一样，渲染缓冲对象是一个真正的缓冲，即一系列的字节、整数、像素等。渲染缓冲对象附加的好处是，它会将数据储存为OpenGL原生的渲染格式，它是为离屏渲染到帧缓冲优化过的。 渲染缓冲对象直接将所有的渲染数据储存到它的缓冲中，不会做任何针对纹理格式的转换，让它变为一个更快的可写储存介质。然而，渲染缓冲对象通常都是只写的，所以你不能读取它们（比如使用纹理访问）。当然你仍然还是能够使用glReadPixels来读取它，这会从当前绑定的帧缓冲，而不是附件本身，中返回特定区域的像素。 因为它的数据已经是原生的格式了，当写入或者复制它的数据到其它缓冲中时是非常快的。所以，交换缓冲这样的操作在使用渲染缓冲对象时会非常快。我们在每个渲染迭代最后使用的glfwSwapBuffers，也可以通过渲染缓冲对象实现：只需要写入一个渲染缓冲图像，并在最后交换到另外一个渲染缓冲就可以了。渲染缓冲对象对这种操作非常完美。 创建一个渲染缓冲对象的代码和帧缓冲的代码很类似： unsigned int rbo; glGenRenderbuffers(1, &amp;rbo); 类似，我们需要绑定这个渲染缓冲对象，让之后所有的渲染缓冲操作影响当前的rbo： glBindRenderbuffer(GL_RENDERBUFFER, rbo); 由于渲染缓冲对象通常都是只写的，它们会经常用于深度和模板附件，因为大部分时间我们都不需要从深度和模板缓冲中读取值，只关心深度和模板测试。我们需要深度和模板值用于测试，但不需要对它们进行采样，所以渲染缓冲对象非常适合它们。当我们不需要从这些缓冲中采样的时候，通常都会选择渲染缓冲对象，因为它会更优化一点。 创建一个深度和模板渲染缓冲对象可以通过调用glRenderbufferStorage函数来完成： glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, 800, 600); 创建一个渲染缓冲对象和纹理对象类似，不同的是这个对象是专门被设计作为图像使用的，而不是纹理那样的通用数据缓冲(General Purpose Data Buffer)。这里我们选择GL_DEPTH24_STENCIL8作为内部格式，它封装了24位的深度和8位的模板缓冲。 最后一件事就是附加这个渲染缓冲对象： glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo); 渲染缓冲对象能为你的帧缓冲对象提供一些优化，但知道什么时候使用渲染缓冲对象，什么时候使用纹理是很重要的。通常的规则是，如果你不需要从一个缓冲中采样数据，那么对这个缓冲使用渲染缓冲对象会是明智的选择。如果你需要从缓冲中采样颜色或深度值等数据，那么你应该选择纹理附件。性能方面它不会产生非常大的影响的。 渲染到纹理既然我们已经知道帧缓冲（大概）是怎么工作的了，是时候实践它们了。我们将会将场景渲染到一个附加到帧缓冲对象上的颜色纹理中，之后将在一个横跨整个屏幕的四边形上绘制这个纹理。这样视觉输出和没使用帧缓冲时是完全一样的，但这次是打印到了一个四边形上。这为什么很有用呢？我们会在下一部分中知道原因。 首先要创建一个帧缓冲对象，并绑定它，这些都很直观： unsigned int framebuffer; glGenFramebuffers(1, &amp;framebuffer); glBindFramebuffer(GL_FRAMEBUFFER, framebuffer); 接下来我们需要创建一个纹理图像，我们将它作为一个颜色附件附加到帧缓冲上。我们将纹理的维度设置为窗口的宽度和高度，并且不初始化它的数据： // 生成纹理 unsigned int texColorBuffer; glGenTextures(1, &amp;texColorBuffer); glBindTexture(GL_TEXTURE_2D, texColorBuffer); glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR ); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glBindTexture(GL_TEXTURE_2D, 0); // 将它附加到当前绑定的帧缓冲对象 glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texColorBuffer, 0); 添加一个深度（和模板）附件到帧缓冲中。由于我们只希望采样颜色缓冲，而不是其它的缓冲，我们可以为它们创建一个渲染缓冲对象。 创建一个渲染缓冲对象不是非常复杂。我们需要记住的唯一事情是，我们将它创建为一个深度和模板附件渲染缓冲对象。我们将它的内部格式设置为GL_DEPTH24_STENCIL8。 unsigned int rbo; glGenRenderbuffers(1, &amp;rbo); glBindRenderbuffer(GL_RENDERBUFFER, rbo); glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, 800, 600); glBindRenderbuffer(GL_RENDERBUFFER, 0); 当我们为渲染缓冲对象分配了足够的内存之后，我们可以解绑这个渲染缓冲。 将渲染缓冲对象附加到帧缓冲的深度和模板附件上： glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo); 要想绘制场景到一个纹理上，我们需要采取以下的步骤： 将新的帧缓冲绑定为激活的帧缓冲，和往常一样渲染场景 绑定默认的帧缓冲 绘制一个横跨整个屏幕的四边形，将帧缓冲的颜色缓冲作为它的纹理。]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl测试操作]]></title>
    <url>%2F2019%2F01%2F04%2Fopengl%E6%B5%8B%E8%AF%95%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[深度测试深度缓冲(Depth Buffer)来防止被阻挡的面渲染到其它面的前面。在这一节中，我们将会更加深入地讨论这些储存在深度缓冲（或z缓冲(z-buffer)）中的深度值(Depth Value)，以及它们是如何确定一个片段是处于其它片段后方的。 深度缓冲就像颜色缓冲(Color Buffer)（储存所有的片段颜色：视觉输出）一样，在每个片段中储存了信息，并且（通常）和颜色缓冲有着一样的宽度和高度。深度缓冲是由窗口系统自动创建的，它会以16、24或32位float的形式储存它的深度值。在大部分的系统中，深度缓冲的精度都是24位的。 当深度测试(Depth Testing)被启用的时候，OpenGL会将一个片段的的深度值与深度缓冲的内容进行对比。OpenGL会执行一个深度测试，如果这个测试通过了的话，深度缓冲将会更新为新的深度值。如果深度测试失败了，片段将会被丢弃。 深度缓冲是在片段着色器运行之后（以及模板测试(Stencil Testing)运行之后，我们将在下一节中讨论）在屏幕空间中运行的。屏幕空间坐标与通过OpenGL的glViewport所定义的视口密切相关，并且可以直接使用GLSL内建变量gl_FragCoord从片段着色器中直接访问。gl_FragCoord的x和y分量代表了片段的屏幕空间坐标（其中(0, 0)位于左下角）。gl_FragCoord中也包含了一个z分量，它包含了片段真正的深度值。z值就是需要与深度缓冲内容所对比的那个值。 开启关闭深度测试深度测试默认是禁用的，所以如果要启用深度测试的话，我们需要用GL_DEPTH_TEST选项来启用它： glEnable(GL_DEPTH_TEST);当它启用的时候，如果一个片段通过了深度测试的话，OpenGL会在深度缓冲中储存该片段的z值；如果没有通过深度缓冲，则会丢弃该片段。如果你启用了深度缓冲，你还应该在每个渲染迭代之前使用GL_DEPTH_BUFFER_BIT来清除深度缓冲，否则你会仍在使用上一次渲染迭代中的写入的深度值： glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);可以想象，在某些情况下你会需要对所有片段都执行深度测试并丢弃相应的片段，但不希望更新深度缓冲。基本上来说，你在使用一个只读的(Read-only)深度缓冲。OpenGL允许我们禁用深度缓冲的写入，只需要设置它的深度掩码(Depth Mask)设置为GL_FALSE就可以了： glDepthMask(GL_FALSE);注意这只在深度测试被启用的时候才有效果。 深度测试函数OpenGL允许我们修改深度测试中使用的比较运算符。这允许我们来控制OpenGL什么时候该通过或丢弃一个片段，什么时候去更新深度缓冲。我们可以调用glDepthFunc函数来设置比较运算符（或者说深度函数(Depth Function)）： glDepthFunc(GL_LESS);这个函数接受下面表格中的比较运算符： 函数 描述GL_ALWAYS 永远通过深度测试GL_NEVER 永远不通过深度测试GL_LESS 在片段深度值小于缓冲的深度值时通过测试GL_EQUAL 在片段深度值等于缓冲区的深度值时通过测试GL_LEQUAL 在片段深度值小于等于缓冲区的深度值时通过测试GL_GREATER 在片段深度值大于缓冲区的深度值时通过测试GL_NOTEQUAL 在片段深度值不等于缓冲区的深度值时通过测试GL_GEQUAL 在片段深度值大于等于缓冲区的深度值时通过测试默认情况下使用的深度函数是GL_LESS，它将会丢弃深度值大于等于当前深度缓冲值的所有片段。 模板测试当片段着色器处理完一个片段之后，模板测试(Stencil Test)会开始执行，和深度测试一样，它也可能会丢弃片段。接下来，被保留的片段会进入深度测试，它可能会丢弃更多的片段。模板测试是根据又一个缓冲来进行的，它叫做模板缓冲(Stencil Buffer)，我们可以在渲染的时候更新它来获得一些很有意思的效果。 一个模板缓冲中，（通常）每个模板值(Stencil Value)是8位的。所以每个像素/片段一共能有256种不同的模板值。我们可以将这些模板值设置为我们想要的值，然后当某一个片段有某一个模板值的时候，我们就可以选择丢弃或是保留这个片段了。 模板缓冲的一个简单的例子如下： 模板缓冲首先会被清除为0，之后在模板缓冲中使用1填充了一个空心矩形。场景中的片段将会只在片段的模板值为1的时候会被渲染（其它的都被丢弃了）。 模板缓冲操作允许我们在渲染片段时将模板缓冲设定为一个特定的值。通过在渲染时修改模板缓冲的内容，我们写入了模板缓冲。在同一个（或者接下来的）渲染迭代中，我们可以读取这些值，来决定丢弃还是保留某个片段。使用模板缓冲的时候你可以尽情发挥，但大体的步骤如下： 启用模板缓冲的写入。 渲染物体，更新模板缓冲的内容。 禁用模板缓冲的写入。 渲染（其它）物体，这次根据模板缓冲的内容丢弃特定的片段。所以，通过使用模板缓冲，我们可以根据场景中已绘制的其它物体的片段，来决定是否丢弃特定的片段。 开启关闭模板测试你可以启用GL_STENCIL_TEST来启用模板测试。在这一行代码之后，所有的渲染调用都会以某种方式影响着模板缓冲。 glEnable(GL_STENCIL_TEST);注意，和颜色和深度缓冲一样，你也需要在每次迭代之前清除模板缓冲。 glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT);和深度测试的glDepthMask函数一样，模板缓冲也有一个类似的函数。glStencilMask允许我们设置一个位掩码(Bitmask)，它会与将要写入缓冲的模板值进行与(AND)运算。默认情况下设置的位掩码所有位都为1，不影响输出，但如果我们将它设置为0x00，写入缓冲的所有模板值最后都会变成0.这与深度测试中的glDepthMask(GL_FALSE)是等价的。 glStencilMask(0xFF); // 每一位写入模板缓冲时都保持原样 glStencilMask(0x00); // 每一位在写入模板缓冲时都会变成0（禁用写入） 大部分情况下你都只会使用0x00或者0xFF作为模板掩码(Stencil Mask)，但是知道有选项可以设置自定义的位掩码总是好的。 模板测试函数和深度测试一样，我们对模板缓冲应该通过还是失败，以及它应该如何影响模板缓冲，也是有一定控制的。一共有两个函数能够用来配置模板测试：glStencilFunc和glStencilOp。 glStencilFunc(GLenum func, GLint ref, GLuint mask)一共包含三个参数： func：设置模板测试函数(Stencil Test Function)。这个测试函数将会应用到已储存的模板值上和glStencilFunc函数的ref值上。可用的选项有：GL_NEVER、GL_LESS、GL_LEQUAL、GL_GREATER、GL_GEQUAL、GL_EQUAL、GL_NOTEQUAL和GL_ALWAYS。它们的语义和深度缓冲的函数类似。 ref：设置了模板测试的参考值(Reference Value)。模板缓冲的内容将会与这个值进行比较。 mask：设置一个掩码，它将会与参考值和储存的模板值在测试比较它们之前进行与(AND)运算。初始情况下所有位都为1。 在一开始的那个简单的模板例子中，函数被设置为： glStencilFunc(GL_EQUAL, 1, 0xFF)这会告诉OpenGL，只要一个片段的模板值等于(GL_EQUAL)参考值1，片段将会通过测试并被绘制，否则会被丢弃。 但是glStencilFunc仅仅描述了OpenGL应该对模板缓冲内容做什么，而不是我们应该如何更新缓冲。这就需要glStencilOp这个函数了。 glStencilOp(GLenum sfail, GLenum dpfail, GLenum dppass)一共包含三个选项，我们能够设定每个选项应该采取的行为： sfail：模板测试失败时采取的行为。 dpfail：模板测试通过，但深度测试失败时采取的行为。 dppass：模板测试和深度测试都通过时采取的行为。每个选项都可以选用以下的其中一种行为： 行为 描述GL_KEEP 保持当前储存的模板值GL_ZERO 将模板值设置为0GL_REPLACE 将模板值设置为glStencilFunc函数设置的ref值GL_INCR 如果模板值小于最大值则将模板值加1GL_INCR_WRAP 与GL_INCR一样，但如果模板值超过了最大值则归零GL_DECR 如果模板值大于最小值则将模板值减1GL_DECR_WRAP 与GL_DECR一样，但如果模板值小于0则将其设置为最大值GL_INVERT 按位翻转当前的模板缓冲值默认情况下glStencilOp是设置为(GL_KEEP, GL_KEEP, GL_KEEP)的，所以不论任何测试的结果是如何，模板缓冲都会保留它的值。默认的行为不会更新模板缓冲，所以如果你想写入模板缓冲的话，你需要至少对其中一个选项设置不同的值。 所以，通过使用glStencilFunc和glStencilOp，我们可以精确地指定更新模板缓冲的时机与行为了，我们也可以指定什么时候该让模板缓冲通过，即什么时候片段需要被丢弃.]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl光照]]></title>
    <url>%2F2019%2F01%2F04%2Fopengl%E5%85%89%E7%85%A7%2F</url>
    <content type="text"><![CDATA[基础光照这些光照模型都是基于我们对光的物理特性的理解。其中一个模型被称为冯氏光照模型(Phong Lighting Model)。冯氏光照模型的主要结构由3个分量组成：环境(Ambient)、漫反射(Diffuse)和镜面(Specular)光照。下面这张图展示了这些光照分量看起来的样子： 环境光照(Ambient Lighting)：即使在黑暗的情况下，世界上通常也仍然有一些光亮（月亮、远处的光），所以物体几乎永远不会是完全黑暗的。为了模拟这个，我们会使用一个环境光照常量，它永远会给物体一些颜色。 漫反射光照(Diffuse Lighting)：模拟光源对物体的方向性影响(Directional Impact)。它是冯氏光照模型中视觉上最显著的分量。物体的某一部分越是正对着光源，它就会越亮。 镜面光照(Specular Lighting)：模拟有光泽物体上面出现的亮点。镜面光照的颜色相比于物体的颜色会更倾向于光的颜色。 材质在现实世界里，每个物体会对光产生不同的反应。比如说，钢看起来通常会比陶瓷花瓶更闪闪发光，木头箱子也不会像钢制箱子那样对光产生很强的反射。每个物体对镜面高光也有不同的反应。有些物体反射光的时候不会有太多的散射(Scatter)，因而产生一个较小的高光点，而有些物体则会散射很多，产生一个有着更大半径的高光点。如果我们想要在OpenGL中模拟多种类型的物体，我们必须为每个物体分别定义一个材质(Material)属性。 我们指定了一个物体和光的颜色，以及结合环境光和镜面强度分量，来定义物体的视觉输出。当描述一个物体的时候，我们可以用这三个分量来定义一个材质颜色(Material Color)：环境光照(Ambient Lighting)、漫反射光照(Diffuse Lighting)和镜面光照(Specular Lighting)。通过为每个分量指定一个颜色，我们就能够对物体的颜色输出有着精细的控制了。现在，我们再添加反光度(Shininess)这个分量到上述的三个颜色中，这就有我们需要的所有材质属性了. 光照贴图漫反射和镜面光贴图(Map)。这允许我们对物体的漫反射分量（以及间接地对环境光分量，它们几乎总是一样的）和镜面光分量有着更精确的控制。 投光物平行光当一个光源处于很远的地方时，来自光源的每条光线就会近似于互相平行。不论物体和/或者观察者的位置，看起来好像所有的光都来自于同一个方向。当我们使用一个假设光源处于无限远处的模型时，它就被称为定向光，因为它的所有光线都有着相同的方向，它与光源的位置是没有关系的。 定向光非常好的一个例子就是太阳。太阳距离我们并不是无限远，但它已经远到在光照计算中可以把它视为无限远了。所以来自太阳的所有光线将被模拟为平行光线，我们可以在下图看到： 因为所有的光线都是平行的，所以物体与光源的相对位置是不重要的，因为对场景中每一个物体光的方向都是一致的。由于光的位置向量保持一致，场景中每个物体的光照计算将会是类似的。 点光源定向光对于照亮整个场景的全局光源是非常棒的，但除了定向光之外我们也需要一些分散在场景中的点光源(Point Light)。点光源是处于世界中某一个位置的光源，它会朝着所有方向发光，但光线会随着距离逐渐衰减。想象作为投光物的灯泡和火把，它们都是点光源。 聚光源聚光是位于环境中某个位置的光源，它只朝一个特定方向而不是所有方向照射光线。这样的结果就是只有在聚光方向的特定半径内的物体才会被照亮，其它的物体都会保持黑暗。聚光很好的例子就是路灯或手电筒。 OpenGL中聚光是用一个世界空间位置、一个方向和一个切光角(Cutoff Angle)来表示的，切光角指定了聚光的半径（译注：是圆锥的半径不是距光源距离那个半径）。对于每个片段，我们会计算片段是否位于聚光的切光方向之间（也就是在锥形内），如果是的话，我们就会相应地照亮片段。下面这张图会让你明白聚光是如何工作的： LightDir：从片段指向光源的向量。SpotDir：聚光所指向的方向。Phiϕ：指定了聚光半径的切光角。落在这个角度之外的物体都不会被这个聚光所照亮。Thetaθ：LightDir向量和SpotDir向量之间的夹角。在聚光内部的话θ值应该比ϕ值小。所以我们要做的就是计算LightDir向量和SpotDir向量之间的点积（还记得它会返回两个单位向量夹角的余弦值吗？），并将它与切光角ϕ值对比。]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl摄像机]]></title>
    <url>%2F2019%2F01%2F04%2Fopengl%E6%91%84%E5%83%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[摄像机/观察空间当我们讨论摄像机/观察空间(Camera/View Space)的时候，是在讨论以摄像机的视角作为场景原点时场景中所有的顶点坐标：观察矩阵把所有的世界坐标变换为相对于摄像机位置与方向的观察坐标。要定义一个摄像机，我们需要它在世界空间中的位置、观察的方向、一个指向它右测的向量以及一个指向它上方的向量。细心的读者可能已经注意到我们实际上创建了一个三个单位轴相互垂直的、以摄像机的位置为原点的坐标系。 摄像机位置 获取摄像机位置很简单。摄像机位置简单来说就是世界空间中一个指向摄像机位置的向量。我们把摄像机位置设置为上一节中的那个相同的位置： glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f);不要忘记正z轴是从屏幕指向你的，如果我们希望摄像机向后移动，我们就沿着z轴的正方向移动。 摄像机方向 下一个需要的向量是摄像机的方向，这里指的是摄像机指向哪个方向。现在我们让摄像机指向场景原点：(0, 0, 0)。还记得如果将两个矢量相减，我们就能得到这两个矢量的差吗？用场景原点向量减去摄像机位置向量的结果就是摄像机的指向向量。由于我们知道摄像机指向z轴负方向，但我们希望方向向量(Direction Vector)指向摄像机的z轴正方向。如果我们交换相减的顺序，我们就会获得一个指向摄像机正z轴方向的向量： glm::vec3 cameraTarget = glm::vec3(0.0f, 0.0f, 0.0f); glm::vec3 cameraDirection = glm::normalize(cameraPos - cameraTarget); 方向向量(Direction Vector)并不是最好的名字，因为它实际上指向从它到目标向量的相反方向（译注：注意看前面的那个图，蓝色的方向向量大概指向z轴的正方向，与摄像机实际指向的方向是正好相反的）。 右轴我们需要的另一个向量是一个右向量(Right Vector)，它代表摄像机空间的x轴的正方向。为获取右向量我们需要先使用一个小技巧：先定义一个上向量(Up Vector)。接下来把上向量和第二步得到的方向向量进行叉乘。两个向量叉乘的结果会同时垂直于两向量，因此我们会得到指向x轴正方向的那个向量（如果我们交换两个向量叉乘的顺序就会得到相反的指向x轴负方向的向量）： glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection)); 上轴现在我们已经有了x轴向量和z轴向量，获取一个指向摄像机的正y轴向量就相对简单了：我们把右向量和方向向量进行叉乘： glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight); LookAt你可以用这3个轴外加一个平移向量来创建一个矩阵，并且你可以用这个矩阵乘以任何向量来将其变换到那个坐标空间。这正是LookAt矩阵所做的，现在我们有了3个相互垂直的轴和一个定义摄像机空间的位置坐标，我们可以创建我们自己的LookAt矩阵了： 其中R是右向量，U是上向量，D是方向向量P是摄像机位置向量。注意，位置向量是相反的，因为我们最终希望把世界平移到与我们自身移动的相反方向。把这个LookAt矩阵作为观察矩阵可以很高效地把所有世界坐标变换到刚刚定义的观察空间。LookAt矩阵就像它的名字表达的那样：它会创建一个看着(Look at)给定目标的观察矩阵。 接着GLM就会创建一个LookAt矩阵，我们可以把它当作我们的观察矩阵： glm::mat4 view; view = glm::lookAt(glm::vec3(0.0f, 0.0f, 3.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 1.0f, 0.0f)); glm::LookAt函数需要一个位置、目标和上向量。它会创建一个和在上面使用的一样的观察矩阵。 摄像机移动让摄像机绕着场景转的确很有趣，但是让我们自己移动摄像机会更有趣！首先我们必须设置一个摄像机系统，所以在我们的程序前面定义一些摄像机变量很有用： glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f); glm::vec3 cameraFront = glm::vec3(0.0f, 0.0f, -1.0f); glm::vec3 cameraUp = glm::vec3(0.0f, 1.0f, 0.0f); view = glm::lookAt(cameraPos, cameraPos + cameraFront, cameraUp); 我们首先将摄像机位置设置为之前定义的cameraPos。方向是当前的位置加上我们刚刚定义的方向向量。这样能保证无论我们怎么移动，摄像机都会注视着目标方向。让我们摆弄一下这些向量，在按下某些按钮时更新cameraPos向量。]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl坐标系统]]></title>
    <url>%2F2019%2F01%2F04%2F%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[概述为了将坐标从一个坐标系变换到另一个坐标系，我们需要用到几个变换矩阵，最重要的几个分别是模型(Model)、观察(View)、投影(Projection)三个矩阵。我们的顶点坐标起始于局部空间(Local Space)，在这里它称为局部坐标(Local Coordinate)，它在之后会变为世界坐标(World Coordinate)，观察坐标(View Coordinate)，裁剪坐标(Clip Coordinate)，并最后以屏幕坐标(Screen Coordinate)的形式结束。下面的这张图展示了整个流程以及各个变换过程做了什么： 局部坐标是对象相对于局部原点的坐标，也是物体起始的坐标。 下一步是将局部坐标变换为世界空间坐标，世界空间坐标是处于一个更大的空间范围的。这些坐标相对于世界的全局原点，它们会和其它物体一起相对于世界的原点进行摆放。 接下来我们将世界坐标变换为观察空间坐标，使得每个坐标都是从摄像机或者说观察者的角度进行观察的。 坐标到达观察空间之后，我们需要将其投影到裁剪坐标。裁剪坐标会被处理至-1.0到1.0的范围内，并判断哪些顶点将会出现在屏幕上。 最后，我们将裁剪坐标变换为屏幕坐标，我们将使用一个叫做视口变换(Viewport Transform)的过程。视口变换将位于-1.0到1.0范围的坐标变换到由glViewport函数所定义的坐标范围内。最后变换出来的坐标将会送到光栅器，将其转化为片段。 局部空间局部空间是指物体所在的坐标空间，即对象最开始所在的地方。想象你在一个建模软件（比如说Blender）中创建了一个立方体。你创建的立方体的原点有可能位于(0, 0, 0)，即便它有可能最后在程序中处于完全不同的位置。甚至有可能你创建的所有模型都以(0, 0, 0)为初始位置（译注：然而它们会最终出现在世界的不同位置）。所以，你的模型的所有顶点都是在局部空间中：它们相对于你的物体来说都是局部的。 我们一直使用的那个箱子的顶点是被设定在-0.5到0.5的坐标范围中，(0, 0)是它的原点。这些都是局部坐标。 世界空间如果我们将我们所有的物体导入到程序当中，它们有可能会全挤在世界的原点(0, 0, 0)上，这并不是我们想要的结果。我们想为每一个物体定义一个位置，从而能在更大的世界当中放置它们。世界空间中的坐标正如其名：是指顶点相对于（游戏）世界的坐标。如果你希望将物体分散在世界上摆放（特别是非常真实的那样），这就是你希望物体变换到的空间。物体的坐标将会从局部变换到世界空间；该变换是由模型矩阵(Model Matrix)实现的。 模型矩阵是一种变换矩阵，它能通过对物体进行位移、缩放、旋转来将它置于它本应该在的位置或朝向。你可以将它想像为变换一个房子，你需要先将它缩小（它在局部空间中太大了），并将其位移至郊区的一个小镇，然后在y轴上往左旋转一点以搭配附近的房子。 观察空间观察空间经常被人们称之OpenGL的摄像机(Camera)（所以有时也称为摄像机空间(Camera Space)或视觉空间(Eye Space)）。观察空间是将世界空间坐标转化为用户视野前方的坐标而产生的结果。因此观察空间就是从摄像机的视角所观察到的空间。而这通常是由一系列的位移和旋转的组合来完成，平移/旋转场景从而使得特定的对象被变换到摄像机的前方。这些组合在一起的变换通常存储在一个观察矩阵(View Matrix)里，它被用来将世界坐标变换到观察空间。 裁剪空间在一个顶点着色器运行的最后，OpenGL期望所有的坐标都能落在一个特定的范围内，且任何在这个范围之外的点都应该被裁剪掉(Clipped)。被裁剪掉的坐标就会被忽略，所以剩下的坐标就将变为屏幕上可见的片段。这也就是裁剪空间(Clip Space)名字的由来。 因为将所有可见的坐标都指定在-1.0到1.0的范围内不是很直观，所以我们会指定自己的坐标集(Coordinate Set)并将它变换回标准化设备坐标系，就像OpenGL期望的那样。 为了将顶点坐标从观察变换到裁剪空间，我们需要定义一个投影矩阵(Projection Matrix)，它指定了一个范围的坐标，比如在每个维度上的-1000到1000。投影矩阵接着会将在这个指定的范围内的坐标变换为标准化设备坐标的范围(-1.0, 1.0)。所有在范围外的坐标不会被映射到在-1.0到1.0的范围之间，所以会被裁剪掉。在上面这个投影矩阵所指定的范围内，坐标(1250, 500, 750)将是不可见的，这是由于它的x坐标超出了范围，它被转化为一个大于1.0的标准化设备坐标，所以被裁剪掉了。 如果只是图元(Primitive)，例如三角形，的一部分超出了裁剪体积(Clipping Volume)，则OpenGL会重新构建这个三角形为一个或多个三角形让其能够适合这个裁剪范围。 由投影矩阵创建的观察箱(Viewing Box)被称为平截头体(Frustum)，每个出现在平截头体范围内的坐标都会最终出现在用户的屏幕上。将特定范围内的坐标转化到标准化设备坐标系的过程（而且它很容易被映射到2D观察空间坐标）被称之为投影(Projection)，因为使用投影矩阵能将3D坐标投影(Project)到很容易映射到2D的标准化设备坐标系中。 一旦所有顶点被变换到裁剪空间，最终的操作——透视除法(Perspective Division)将会执行，在这个过程中我们将位置向量的x，y，z分量分别除以向量的齐次w分量；透视除法是将4D裁剪空间坐标变换为3D标准化设备坐标的过程。这一步会在每一个顶点着色器运行的最后被自动执行。 在这一阶段之后，最终的坐标将会被映射到屏幕空间中（使用glViewport中的设定），并被变换成片段。 将观察坐标变换为裁剪坐标的投影矩阵可以为两种不同的形式，每种形式都定义了不同的平截头体。我们可以选择创建一个正射投影矩阵(Orthographic Projection Matrix)或一个透视投影矩阵(Perspective Projection Matrix)。 正射投影正射投影矩阵定义了一个类似立方体的平截头箱，它定义了一个裁剪空间，在这空间之外的顶点都会被裁剪掉。创建一个正射投影矩阵需要指定可见平截头体的宽、高和长度。在使用正射投影矩阵变换至裁剪空间之后处于这个平截头体内的所有坐标将不会被裁剪掉。它的平截头体看起来像一个容器： 上面的平截头体定义了可见的坐标，它由由宽、高、近(Near)平面和远(Far)平面所指定。任何出现在近平面之前或远平面之后的坐标都会被裁剪掉。正射平截头体直接将平截头体内部的所有坐标映射为标准化设备坐标，因为每个向量的w分量都没有进行改变；如果w分量等于1.0，透视除法则不会改变这个坐标。 要创建一个正射投影矩阵，我们可以使用GLM的内置函数glm::ortho： glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);前两个参数指定了平截头体的左右坐标，第三和第四参数指定了平截头体的底部和顶部。通过这四个参数我们定义了近平面和远平面的大小，然后第五和第六个参数则定义了近平面和远平面的距离。这个投影矩阵会将处于这些x，y，z值范围内的坐标变换为标准化设备坐标。 正射投影矩阵直接将坐标映射到2D平面中，即你的屏幕，但实际上一个直接的投影矩阵会产生不真实的结果，因为这个投影没有将透视(Perspective)考虑进去。所以我们需要透视投影矩阵来解决这个问题。 透视投影如果你曾经体验过实际生活给你带来的景象，你就会注意到离你越远的东西看起来更小。这个奇怪的效果称之为透视(Perspective)。透视的效果在我们看一条无限长的高速公路或铁路时尤其明显，正如下面图片显示的那样： 正如你看到的那样，由于透视，这两条线在很远的地方看起来会相交。这正是透视投影想要模仿的效果，它是使用透视投影矩阵来完成的。这个投影矩阵将给定的平截头体范围映射到裁剪空间，除此之外还修改了每个顶点坐标的w值，从而使得离观察者越远的顶点坐标w分量越大。被变换到裁剪空间的坐标都会在-w到w的范围之间（任何大于这个范围的坐标都会被裁剪掉）。OpenGL要求所有可见的坐标都落在-1.0到1.0范围内，作为顶点着色器最后的输出，因此，一旦坐标在裁剪空间内之后，透视除法就会被应用到裁剪空间坐标上： 顶点坐标的每个分量都会除以它的w分量，距离观察者越远顶点坐标就会越小。这是也是w分量非常重要的另一个原因，它能够帮助我们进行透视投影。最后的结果坐标就是处于标准化设备空间中的。 在GLM中可以这样创建一个透视投影矩阵： glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f); 同样，glm::perspective所做的其实就是创建了一个定义了可视空间的大平截头体，任何在这个平截头体以外的东西最后都不会出现在裁剪空间体积内，并且将会受到裁剪。一个透视平截头体可以被看作一个不均匀形状的箱子，在这个箱子内部的每个坐标都会被映射到裁剪空间上的一个点。下面是一张透视平截头体的图片： 它的第一个参数定义了fov的值，它表示的是视野(Field of View)，并且设置了观察空间的大小。如果想要一个真实的观察效果，它的值通常设置为45.0f，但想要一个末日风格的结果你可以将其设置一个更大的值。第二个参数设置了宽高比，由视口的宽除以高所得。第三和第四个参数设置了平截头体的近和远平面。我们通常设置近距离为0.1f，而远距离设为100.0f。所有在近平面和远平面内且处于平截头体内的顶点都会被渲染。 当你把透视矩阵的 near 值设置太大时（如10.0f），OpenGL会将靠近摄像机的坐标（在0.0f和10.0f之间）都裁剪掉，这会导致一个你在游戏中很熟悉的视觉效果：在太过靠近一个物体的时候你的视线会直接穿过去。 当使用正射投影时，每一个顶点坐标都会直接映射到裁剪空间中而不经过任何精细的透视除法（它仍然会进行透视除法，只是w分量没有被改变（它保持为1），因此没有起作用）。因为正射投影没有使用透视，远处的物体不会显得更小，所以产生奇怪的视觉效果。由于这个原因，正射投影主要用于二维渲染以及一些建筑或工程的程序，在这些场景中我们更希望顶点不会被透视所干扰。某些如 Blender 等进行三维建模的软件有时在建模时也会使用正射投影，因为它在各个维度下都更准确地描绘了每个物体。下面你能够看到在Blender里面使用两种投影方式的对比： 你可以看到，使用透视投影的话，远处的顶点看起来比较小，而在正射投影中每个顶点距离观察者的距离都是一样的。 模型视图投影矩阵我们为上述的每一个步骤都创建了一个变换矩阵：模型矩阵、观察矩阵和投影矩阵。一个顶点坐标将会根据以下过程被变换到裁剪坐标： 注意矩阵运算的顺序是相反的（记住我们需要从右往左阅读矩阵的乘法）。最后的顶点应该被赋值到顶点着色器中的gl_Position，OpenGL将会自动进行透视除法和裁剪。 顶点着色器的输出要求所有的顶点都在裁剪空间内，这正是我们刚才使用变换矩阵所做的。OpenGL然后对裁剪坐标执行透视除法从而将它们变换到标准化设备坐标。OpenGL会使用glViewPort内部的参数来将标准化设备坐标映射到屏幕坐标，每个坐标都关联了一个屏幕上的点。这个过程称为视口变换。 右手坐标系(Right-handed System)OpenGL是一个右手坐标系。简单来说，就是正x轴在你的右手边，正y轴朝上，而正z轴是朝向后方的。想象你的屏幕处于三个轴的中心，则正z轴穿过你的屏幕朝向你。坐标系画起来如下： 为了理解为什么被称为右手坐标系，按如下的步骤做： 沿着正y轴方向伸出你的右臂，手指着上方。 大拇指指向右方。 食指指向上方。 中指向下弯曲90度。如果你的动作正确，那么你的大拇指指向正x轴方向，食指指向正y轴方向，中指指向正z轴方向。如果你用左臂来做这些动作，你会发现z轴的方向是相反的。这个叫做左手坐标系，它被DirectX广泛地使用。注意在标准化设备坐标系中OpenGL实际上使用的是左手坐标系（投影矩阵交换了左右手）。 Z缓冲OpenGL存储它的所有深度信息于一个Z缓冲(Z-buffer)中，也被称为深度缓冲(Depth Buffer)。GLFW会自动为你生成这样一个缓冲（就像它也有一个颜色缓冲来存储输出图像的颜色）。深度值存储在每个片段里面（作为片段的z值），当片段想要输出它的颜色时，OpenGL会将它的深度值和z缓冲进行比较，如果当前的片段在其它片段之后，它将会被丢弃，否则将会覆盖。这个过程称为深度测试(Depth Testing)，它是由OpenGL自动完成的。 然而，如果我们想要确定OpenGL真的执行了深度测试，首先我们要告诉OpenGL我们想要启用深度测试；它默认是关闭的。我们可以通过glEnable函数来开启深度测试。glEnable和glDisable函数允许我们启用或禁用某个OpenGL功能。这个功能会一直保持启用/禁用状态，直到另一个调用来禁用/启用它。现在我们想启用深度测试，需要开启GL_DEPTH_TEST： glEnable(GL_DEPTH_TEST);因为我们使用了深度测试，我们也想要在每次渲染迭代之前清除深度缓冲（否则前一帧的深度信息仍然保存在缓冲中）。就像清除颜色缓冲一样，我们可以通过在glClear函数中指定DEPTH_BUFFER_BIT位来清除深度缓冲： glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl矩阵向量]]></title>
    <url>%2F2019%2F01%2F03%2Fopengl%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F%2F</url>
    <content type="text"><![CDATA[如何创建一个物体、着色、加入纹理，给它们一些细节的表现，但因为它们都还是静态的物体，仍是不够有趣。我们可以尝试着在每一帧改变物体的顶点并且重配置缓冲区从而使它们移动，但这太繁琐了，而且会消耗很多的处理时间。我们现在有一个更好的解决方案，使用（多个）矩阵(Matrix)对象可以更好的变换(Transform)一个物体。 向量向量最基本的定义就是一个方向。或者更正式的说，向量有一个方向(Direction)和大小(Magnitude，也叫做强度或长度)。你可以把向量想像成一个藏宝图上的指示：“向左走10步，向北走3步，然后向右走5步”；“左”就是方向，“10步”就是向量的长度。那么这个藏宝图的指示一共有3个向量。向量可以在任意维度(Dimension)上，但是我们通常只使用2至4维。如果一个向量有2个维度，它表示一个平面的方向(想象一下2D的图像)，当它有3个维度的时候它可以表达一个3D世界的方向。 下面你会看到3个向量，每个向量在2D图像中都用一个箭头(x, y)表示。我们在2D图片中展示这些向量，因为这样子会更直观一点。你可以把这些2D向量当做z坐标为0的3D向量。由于向量表示的是方向，起始于何处并不会改变它的值。下图我们可以看到向量v¯和w¯是相等的，尽管他们的起始点不同： 数学家喜欢在字母上面加一横表示向量，比如说v¯。当用在公式中时它们通常是这样的：由于向量是一个方向，所以有些时候会很难形象地将它们用位置(Position)表示出来。为了让其更为直观，我们通常设定这个方向的原点为(0, 0, 0)，然后指向一个方向，对应一个点，使其变为位置向量(Position Vector)（你也可以把起点设置为其他的点，然后说：这个向量从这个点起始指向另一个点）。比如说位置向量(3, 5)在图像中的起点会是(0, 0)，并会指向(3, 5)。我们可以使用向量在2D或3D空间中表示方向与位置. 和普通数字一样，我们也可以用向量进行多种运算（其中一些你可能已经看到过了）。 向量与标量运算标量(Scalar)只是一个数字（或者说是仅有一个分量的向量）。当把一个向量加/减/乘/除一个标量，我们可以简单的把向量的每个分量分别进行该运算。对于加法来说会像这样: 其中的+可以是+，-，·或÷，其中·是乘号。注意－和÷运算时不能颠倒（标量-/÷向量），因为颠倒的运算是没有定义的。 向量取反对一个向量取反(Negate)会将其方向逆转。一个指向东北的向量取反后就指向西南方向了。我们在一个向量的每个分量前加负号就可以实现取反了（或者说用-1数乘该向量）: 向量加减向量的加法可以被定义为是分量的(Component-wise)相加，即将一个向量中的每一个分量加上另一个向量的对应分量： 向量v = (4, 2)和k = (1, 2)可以直观地表示为： 就像普通数字的加减一样，向量的减法等于加上第二个向量的相反向量： 两个向量的相减会得到这两个向量指向位置的差。这在我们想要获取两点的差会非常有用。 长度我们使用勾股定理(Pythagoras Theorem)来获取向量的长度(Length)/大小(Magnitude)。如果你把向量的x与y分量画出来，该向量会和x与y分量为边形成一个三角形: 因为两条边（x和y）是已知的，如果希望知道斜边v¯的长度，我们可以直接通过勾股定理来计算： ||v¯||表示向量v¯的长度，我们也可以加上z2把这个公式拓展到三维空间。 例子中向量(4, 2)的长度等于： 结果是4.47。 有一个特殊类型的向量叫做单位向量(Unit Vector)。单位向量有一个特别的性质——它的长度是1。我们可以用任意向量的每个分量除以向量的长度得到它的单位向量n̂ ： 我们把这种方法叫做一个向量的标准化(Normalizing)。单位向量头上有一个^样子的记号。通常单位向量会变得很有用，特别是在我们只关心方向不关心长度的时候（如果改变向量的长度，它的方向并不会改变）。 向量相乘两个向量相乘是一种很奇怪的情况。普通的乘法在向量上是没有定义的，因为它在视觉上是没有意义的。但是在相乘的时候我们有两种特定情况可以选择：一个是点乘(Dot Product)，记作v¯⋅k¯，另一个是叉乘(Cross Product)，记作v¯×k¯。 点乘两个向量的点乘等于它们的数乘结果乘以两个向量之间夹角的余弦值。可能听起来有点费解，我们来看一下公式： 它们之间的夹角记作θ。为什么这很有用？想象如果v¯和k¯都是单位向量，它们的长度会等于1。这样公式会有效简化成： 现在点积只定义了两个向量的夹角。你也许记得90度的余弦值是0，0度的余弦值是1。使用点乘可以很容易测试两个向量是否正交(Orthogonal)或平行（正交意味着两个向量互为直角）。 所以，我们该如何计算点乘呢？点乘是通过将对应分量逐个相乘，然后再把所得积相加来计算的。两个单位向量的（你可以验证它们的长度都为1）点乘会像是这样： 点乘会在计算光照的时候非常有用。 叉乘叉乘只在3D空间中有定义，它需要两个不平行向量作为输入，生成一个正交于两个输入向量的第三个向量。如果输入的两个向量也是正交的，那么叉乘之后将会产生3个互相正交的向量。接下来的教程中这会非常有用。下面的图片展示了3D空间中叉乘的样子： 下面你会看到两个正交向量A和B叉积： 矩阵现在我们已经讨论了向量的全部内容，是时候看看矩阵了！简单来说矩阵就是一个矩形的数字、符号或表达式数组。矩阵中每一项叫做矩阵的元素(Element)。下面是一个2×3矩阵的例子： 矩阵可以通过(i, j)进行索引，i是行，j是列，这就是上面的矩阵叫做2×3矩阵的原因（3列2行，也叫做矩阵的维度(Dimension)）。这与你在索引2D图像时的(x, y)相反，获取4的索引是(2, 1)（第二行，第一列）（译注：如果是图像索引应该是(1, 2)，先算列，再算行）。 矩阵基本也就是这些了，它就是一个矩形的数学表达式阵列。和向量一样，矩阵也有非常漂亮的数学属性。矩阵有几个运算，分别是：矩阵加法、减法和乘法。 矩阵的加减矩阵与标量之间的加减定义如下： 标量值要加到矩阵的每一个元素上。矩阵与标量的减法也相似： 矩阵与矩阵之间的加减就是两个矩阵对应元素的加减运算，所以总体的规则和与标量运算是差不多的，只不过在相同索引下的元素才能进行运算。这也就是说加法和减法只对同维度的矩阵才是有定义的。一个3×2矩阵和一个2×3矩阵（或一个3×3矩阵与4×4矩阵）是不能进行加减的。我们看看两个2×2矩阵是怎样相加的： 同样的法则也适用于减法： 矩阵的数乘和矩阵与标量的加减一样，矩阵与标量之间的乘法也是矩阵的每一个元素分别乘以该标量。下面的例子展示了乘法的过程： 现在我们也就能明白为什么这些单独的数字要叫做标量(Scalar)了。简单来说，标量就是用它的值缩放(Scale)矩阵的所有元素（译注：注意Scalar是由Scale + -ar演变过来的）。前面那个例子中，所有的元素都被放大了2倍。 矩阵相乘矩阵之间的乘法不见得有多复杂，但的确很难让人适应。矩阵乘法基本上意味着遵照规定好的法则进行相乘。当然，相乘还有一些限制： 只有当左侧矩阵的列数与右侧矩阵的行数相等，两个矩阵才能相乘。 矩阵相乘不遵守交换律(Commutative)，也就是说A⋅B≠B⋅A。我们先看一个两个2×2矩阵相乘的例子： 结果矩阵的维度是(n, m)，n等于左侧矩阵的行数，m等于右侧矩阵的列数。 矩阵与向量相乘我们用向量来表示位置，表示颜色，甚至是纹理坐标。向量和矩阵一样都是一个数字序列，但它只有1列。那么，这个新的定义对我们有什么帮助呢？如果我们有一个M×N矩阵，我们可以用这个矩阵乘以我们的N×1向量，因为这个矩阵的列数等于向量的行数，所以它们就能相乘。 很多有趣的2D/3D变换都可以放在一个矩阵中，用这个矩阵乘以我们的向量将变换(Transform)这个向量。 单位矩阵在OpenGL中，由于某些原因我们通常使用4×4的变换矩阵，而其中最重要的原因就是大部分的向量都是4分量的。我们能想到的最简单的变换矩阵就是单位矩阵(Identity Matrix)。单位矩阵是一个除了对角线以外都是0的N×N矩阵。在下式中可以看到，这种变换矩阵使一个向量完全不变： 向量看起来完全没变。从乘法法则来看就很容易理解来：第一个结果元素是矩阵的第一行的每个元素乘以向量的每个对应元素。因为每行的元素除了第一个都是0，可得：1⋅1+0⋅2+0⋅3+0⋅4=1，向量的其他3个元素同理。 缩放对一个向量进行缩放(Scaling)就是对向量的长度进行缩放，而保持它的方向不变。由于我们进行的是2维或3维操作，我们可以分别定义一个有2或3个缩放变量的向量，每个变量缩放一个轴(x、y或z)。 我们先来尝试缩放向量v¯=(3,2)。我们可以把向量沿着x轴缩放0.5，使它的宽度缩小为原来的二分之一；我们将沿着y轴把向量的高度缩放为原来的两倍。我们看看把向量缩放(0.5, 2)倍所获得的s¯是什么样的： 记住，OpenGL通常是在3D空间进行操作的，对于2D的情况我们可以把z轴缩放1倍，这样z轴的值就不变了。我们刚刚的缩放操作是不均匀(Non-uniform)缩放，因为每个轴的缩放因子(Scaling Factor)都不一样。如果每个轴的缩放因子都一样那么就叫均匀缩放(Uniform Scale)。 我们下面会构造一个变换矩阵来为我们提供缩放功能。我们从单位矩阵了解到，每个对角线元素会分别与向量的对应元素相乘。如果我们把1变为3会怎样？这样子的话，我们就把向量的每个元素乘以3了，这事实上就把向量缩放3倍。如果我们把缩放变量表示为(S1,S2,S3)我们可以为任意向量(x,y,z)定义一个缩放矩阵： 注意，第四个缩放向量仍然是1，因为在3D空间中缩放w分量是无意义的。w分量另有其他用途，在后面我们会看到。 位移位移(Translation)是在原始向量的基础上加上另一个向量从而获得一个在不同位置的新向量的过程，从而在位移向量基础上移动了原始向量。我们已经讨论了向量加法，所以这应该不会太陌生。 和缩放矩阵一样，在4×4矩阵上有几个特别的位置用来执行特定的操作，对于位移来说它们是第四列最上面的3个值。如果我们把位移向量表示为(Tx,Ty,Tz)，我们就能把位移矩阵定义为： 这样是能工作的，因为所有的位移值都要乘以向量的w行，所以位移值会加到向量的原始值上（想想矩阵乘法法则）。而如果你用3x3矩阵我们的位移值就没地方放也没地方乘了，所以是不行的。 齐次坐标(Homogeneous Coordinates)向量的w分量也叫齐次坐标。想要从齐次向量得到3D向量，我们可以把x、y和z坐标分别除以w坐标。我们通常不会注意这个问题，因为w分量通常是1.0。使用齐次坐标有几点好处：它允许我们在3D向量上进行位移（如果没有w分量我们是不能位移向量的），而且下一章我们会用w值创建3D视觉效果。 如果一个向量的齐次坐标是0，这个坐标就是方向向量(Direction Vector)，因为w坐标是0，这个向量就不能位移（译注：这也就是我们说的不能位移一个方向）。 有了位移矩阵我们就可以在3个方向(x、y、z)上移动物体，它是我们的变换工具箱中非常有用的一个变换矩阵。 旋转上面几个的变换内容相对容易理解，在2D或3D空间中也容易表示出来，但旋转(Rotation)稍复杂些。如果你想知道旋转矩阵是如何构造出来的，我推荐你去看可汗学院线性代数的视频。 首先我们来定义一个向量的旋转到底是什么。2D或3D空间中的旋转用角(Angle)来表示。角可以是角度制或弧度制的，周角是360角度或2 PI弧度。我个人更喜欢用角度，因为它们看起来更直观。 弧度转角度：角度 = 弧度 * (180.0f / PI) 角度转弧度：弧度 = 角度 * (PI / 180.0f) PI约等于3.14159265359。 转半圈会旋转360/2 = 180度，向右旋转1/5圈表示向右旋转360/5 = 72度。下图中展示的2D向量v¯是由k¯向右旋转72度所得的： 在3D空间中旋转需要定义一个角和一个旋转轴(Rotation Axis)。物体会沿着给定的旋转轴旋转特定角度。如果你想要更形象化的感受，可以试试向下看着一个特定的旋转轴，同时将你的头部旋转一定角度。当2D向量在3D空间中旋转时，我们把旋转轴设为z轴（尝试想象这种情况）。 使用三角学，给定一个角度，可以把一个向量变换为一个经过旋转的新向量。这通常是使用一系列正弦和余弦函数（一般简称sin和cos）各种巧妙的组合得到的。当然，讨论如何生成变换矩阵超出了这个教程的范围。 旋转矩阵在3D空间中每个单位轴都有不同定义，旋转角度用θ表示： 沿x轴旋转： 沿y轴旋转： 沿z轴旋转： 利用旋转矩阵我们可以把任意位置向量沿一个单位旋转轴进行旋转。也可以将多个矩阵复合，比如先沿着x轴旋转再沿着y轴旋转。但是这会很快导致一个问题——万向节死锁（Gimbal Lock，可以看看这个视频（优酷）来了解）。在这里我们不会讨论它的细节，但是对于3D空间中的旋转，一个更好的模型是沿着任意的一个轴，比如单位向量$(0.662, 0.2, 0.7222)$旋转，而不是对一系列旋转矩阵进行复合。这样的一个（超级麻烦的）矩阵是存在的，见下面这个公式，其中(Rx,Ry,Rz)代表任意旋转轴： 在数学上讨论如何生成这样的矩阵仍然超出了本节内容。但是记住，即使这样一个矩阵也不能完全解决万向节死锁问题（尽管会极大地避免）。避免万向节死锁的真正解决方案是使用四元数(Quaternion)，它不仅更安全，而且计算会更有效率。 矩阵的组合使用矩阵进行变换的真正力量在于，根据矩阵之间的乘法，我们可以把多个变换组合到一个矩阵中。让我们看看我们是否能生成一个变换矩阵，让它组合多个变换。假设我们有一个顶点(x, y, z)，我们希望将其缩放2倍，然后位移(1, 2, 3)个单位。我们需要一个位移和缩放矩阵来完成这些变换。结果的变换矩阵看起来像这样： 注意，当矩阵相乘时我们先写位移再写缩放变换的。矩阵乘法是不遵守交换律的，这意味着它们的顺序很重要。当矩阵相乘时，在最右边的矩阵是第一个与向量相乘的，所以你应该从右向左读这个乘法。建议您在组合矩阵时，先进行缩放操作，然后是旋转，最后才是位移，否则它们会（消极地）互相影响。比如，如果你先位移再缩放，位移的向量也会同样被缩放（译注：比如向某方向移动2米，2米也许会被缩放成1米）！ 用最终的变换矩阵左乘我们的向量会得到以下结果： 不错！向量先缩放2倍，然后位移了(1, 2, 3)个单位。 实践OpenGL没有自带任何的矩阵和向量知识，所以我们必须定义自己的数学类和函数。在教程中我们更希望抽象所有的数学细节，使用已经做好了的数学库。幸运的是，有个易于使用，专门为OpenGL量身定做的数学库，那就是GLM。]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl GLSL]]></title>
    <url>%2F2019%2F01%2F01%2FopenglGLSL%2F</url>
    <content type="text"><![CDATA[GLSL着色器是使用一种叫GLSL的类C语言写成的。GLSL是为图形计算量身定制的，它包含一些针对向量和矩阵操作的有用特性。 着色器的开头总是要声明版本，接着是输入和输出变量、uniform和main函数。每个着色器的入口点都是main函数，在这个函数中我们处理所有的输入变量，并将结果输出到输出变量中。 一个典型的着色器有下面的结构： #version version_number in type in_variable_name; in type in_variable_name; out type out_variable_name; uniform type uniform_name; int main() { // 处理输入并进行一些图形操作 ... // 输出处理过的结果到输出变量 out_variable_name = weird_stuff_we_processed; } 谈论到顶点着色器的时候，每个输入变量也叫顶点属性(Vertex Attribute)。我们能声明的顶点属性是有上限的，它一般由硬件来决定。OpenGL确保至少有16个包含4分量的顶点属性可用，但是有些硬件或许允许更多的顶点属性，你可以查询GL_MAX_VERTEX_ATTRIBS来获取具体的上限： int nrAttributes; glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &amp;nrAttributes); 通常情况下它至少会返回16个，大部分情况下是够用了。 数据类型和其他编程语言一样，GLSL有数据类型可以来指定变量的种类。GLSL中包含C等其它语言大部分的默认基础数据类型：int、float、double、uint和bool。GLSL也有两种容器类型，它们会在这个教程中使用很多，分别是向量(Vector)和矩阵(Matrix). 向量GLSL中的向量是一个可以包含有1、2、3或者4个分量的容器，分量的类型可以是前面默认基础类型的任意一个。它们可以是下面的形式（n代表分量的数量）： 类型 含义vecn 包含n个float分量的默认向量bvecn 包含n个bool分量的向量ivecn 包含n个int分量的向量uvecn 包含n个unsigned int分量的向量dvecn 包含n个double分量的向量大多数时候我们使用vecn，因为float足够满足大多数要求了。 一个向量的分量可以通过vec.x这种方式获取，这里x是指这个向量的第一个分量。你可以分别使用.x、.y、.z和.w来获取它们的第1、2、3、4个分量。GLSL也允许你对颜色使用rgba，或是对纹理坐标使用stpq访问相同的分量。 向量这一数据类型也允许一些有趣而灵活的分量选择方式，叫做重组(Swizzling)。重组允许这样的语法： vec2 someVec; vec4 differentVec = someVec.xyxx; vec3 anotherVec = differentVec.zyw; vec4 otherVec = someVec.xxxx + anotherVec.yxzy; 你可以使用上面4个字母任意组合来创建一个和原来向量一样长的（同类型）新向量，只要原来向量有那些分量即可；然而，你不允许在一个vec2向量中去获取.z元素。我们也可以把一个向量作为一个参数传给不同的向量构造函数，以减少需求参数的数量： vec2 vect = vec2(0.5, 0.7); vec4 result = vec4(vect, 0.0, 0.0); vec4 otherResult = vec4(result.xyz, 1.0); 向量是一种灵活的数据类型，我们可以把用在各种输入和输出上。 输入与输出虽然着色器是各自独立的小程序，但是它们都是一个整体的一部分，出于这样的原因，我们希望每个着色器都有输入和输出，这样才能进行数据交流和传递。GLSL定义了in和out关键字专门来实现这个目的。每个着色器使用这两个关键字设定输入和输出，只要一个输出变量与下一个着色器阶段的输入匹配，它就会传递下去。但在顶点和片段着色器中会有点不同。 顶点着色器应该接收的是一种特殊形式的输入，否则就会效率低下。顶点着色器的输入特殊在，它从顶点数据中直接接收输入。为了定义顶点数据该如何管理，我们使用location这一元数据指定输入变量，这样我们才可以在CPU上配置顶点属性。我们已经在前面的教程看过这个了，layout (location = 0)。顶点着色器需要为它的输入提供一个额外的layout标识，这样我们才能把它链接到顶点数据。 你也可以忽略layout (location = 0)标识符，通过在OpenGL代码中使用glGetAttribLocation查询属性位置值(Location)，但是我更喜欢在着色器中设置它们，这样会更容易理解而且节省你（和OpenGL）的工作量。 另一个例外是片段着色器，它需要一个vec4颜色输出变量，因为片段着色器需要生成一个最终输出的颜色。如果你在片段着色器没有定义输出颜色，OpenGL会把你的物体渲染为黑色（或白色）。 所以，如果我们打算从一个着色器向另一个着色器发送数据，我们必须在发送方着色器中声明一个输出，在接收方着色器中声明一个类似的输入。当类型和名字都一样的时候，OpenGL就会把两个变量链接到一起，它们之间就能发送数据了（这是在链接程序对象时完成的）。为了展示这是如何工作的，我们会稍微改动一下之前教程里的那个着色器，让顶点着色器为片段着色器决定颜色。 顶点着色器 #version 330 core layout (location = 0) in vec3 aPos; // 位置变量的属性位置值为0 out vec4 vertexColor; // 为片段着色器指定一个颜色输出 void main() { gl_Position = vec4(aPos, 1.0); // 注意我们如何把一个vec3作为vec4的构造器的参数 vertexColor = vec4(0.5, 0.0, 0.0, 1.0); // 把输出变量设置为暗红色 } 片段着色器 #version 330 core out vec4 FragColor; in vec4 vertexColor; // 从顶点着色器传来的输入变量（名称相同、类型相同） void main() { FragColor = vertexColor; } 你可以看到我们在顶点着色器中声明了一个vertexColor变量作为vec4输出，并在片段着色器中声明了一个类似的vertexColor。由于它们名字相同且类型相同，片段着色器中的vertexColor就和顶点着色器中的vertexColor链接了。由于我们在顶点着色器中将颜色设置为深红色，最终的片段也是深红色的。 UniformUniform是一种从CPU中的应用向GPU中的着色器发送数据的方式，但uniform和顶点属性有些不同。 uniform是全局的(Global)。全局意味着uniform变量必须在每个着色器程序对象中都是独一无二的，而且它可以被着色器程序的任意着色器在任意阶段访问。 无论你把uniform值设置成什么，uniform会一直保存它们的数据，直到它们被重置或更新。 我们可以在一个着色器中添加uniform关键字至类型和变量名前来声明一个GLSL的uniform。从此处开始我们就可以在着色器中使用新声明的uniform了。我们来看看这次是否能通过uniform设置三角形的颜色： #version 330 core out vec4 FragColor; uniform vec4 ourColor; // 在OpenGL程序代码中设定这个变量 void main() { FragColor = ourColor; } 我们在片段着色器中声明了一个uniform vec4的ourColor，并把片段着色器的输出颜色设置为uniform值的内容。因为uniform是全局变量，我们可以在任何着色器中定义它们，而无需通过顶点着色器作为中介。顶点着色器中不需要这个uniform，所以我们不用在那里定义它。 如果你声明了一个uniform却在GLSL代码中没用过，编译器会静默移除这个变量，导致最后编译出的版本中并不会包含它，这可能导致几个非常麻烦的错误. 这个uniform现在还是空的；我们还没有给它添加任何数据，所以下面我们就做这件事。我们首先需要找到着色器中uniform属性的索引/位置值。当我们得到uniform的索引/位置值后，我们就可以更新它的值了 int vertexColorLocation = glGetUniformLocation(shaderProgram, &quot;ourColor&quot;); glUseProgram(shaderProgram); glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f); 接着，我们用glGetUniformLocation查询uniform ourColor的位置值。我们为查询函数提供着色器程序和uniform的名字（这是我们希望获得的位置值的来源）。如果glGetUniformLocation返回-1就代表没有找到这个位置值。最后，我们可以通过glUniform4f函数设置uniform值。注意，查询uniform地址不要求你之前使用过着色器程序，但是更新一个uniform之前你必须先使用程序（调用glUseProgram)，因为它是在当前激活的着色器程序中设置uniform的。 因为OpenGL在其核心是一个C库，所以它不支持类型重载，在函数参数不同的时候就要为其定义新的函数；glUniform是一个典型例子。这个函数有一个特定的后缀，标识设定的uniform的类型。可能的后缀有： 后缀 含义f 函数需要一个float作为它的值i 函数需要一个int作为它的值ui 函数需要一个unsigned int作为它的值3f 函数需要3个float作为它的值fv 函数需要一个float向量/数组作为它的值每当你打算配置一个OpenGL的选项时就可以简单地根据这些规则选择适合你的数据类型的重载函数。在我们的例子里，我们希望分别设定uniform的4个float值，所以我们通过glUniform4f传递我们的数据(注意，我们也可以使用fv版本)。 while(!glfwWindowShouldClose(window)){​ // 输入​ processInput(window); // 渲染 // 清除颜色缓冲 glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); // 记得激活着色器 glUseProgram(shaderProgram); // 更新uniform颜色 float timeValue = glfwGetTime(); float greenValue = sin(timeValue) / 2.0f + 0.5f; int vertexColorLocation = glGetUniformLocation(shaderProgram, &quot;ourColor&quot;); glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f); // 绘制三角形 glBindVertexArray(VAO); glDrawArrays(GL_TRIANGLES, 0, 3); // 交换缓冲并查询IO事件 glfwSwapBuffers(window); glfwPollEvents(); } 可以看到，uniform对于设置一个在渲染迭代中会改变的属性是一个非常有用的工具，它也是一个在程序和着色器间数据交互的很好工具，但假如我们打算为每个顶点设置一个颜色的时候该怎么办？这种情况下，我们就不得不声明和顶点数目一样多的uniform了。在这一问题上更好的解决方案是在顶点属性中包含更多的数据，这是我们接下来要做的事情。 更多属性了解了如何填充VBO、配置顶点属性指针以及如何把它们都储存到一个VAO里。这次，我们同样打算把颜色数据加进顶点数据中。我们将把颜色数据添加为3个float值至vertices数组。我们将把三角形的三个角分别指定为红色、绿色和蓝色： float vertices[] = { // 位置 // 颜色 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f, // 右下 -0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, // 左下 0.0f, 0.5f, 0.0f, 0.0f, 0.0f, 1.0f // 顶部 }; 由于现在有更多的数据要发送到顶点着色器，我们有必要去调整一下顶点着色器，使它能够接收颜色值作为一个顶点属性输入。需要注意的是我们用layout标识符来把aColor属性的位置值设置为1： #version 330 core layout (location = 0) in vec3 aPos; // 位置变量的属性位置值为 0 layout (location = 1) in vec3 aColor; // 颜色变量的属性位置值为 1 out vec3 ourColor; // 向片段着色器输出一个颜色 void main() { gl_Position = vec4(aPos, 1.0); ourColor = aColor; // 将ourColor设置为从顶点数据那里得到的输入颜色 } 由于我们不再使用uniform来传递片段的颜色了，现在使用ourColor输出变量，我们必须再修改一下片段着色器： #version 330 core out vec4 FragColor; in vec3 ourColor; void main() { FragColor = vec4(ourColor, 1.0); } 因为我们添加了另一个顶点属性，并且更新了VBO的内存，我们就必须重新配置顶点属性指针。更新后的VBO内存中的数据现在看起来像这样： 知道了现在使用的布局，我们就可以使用glVertexAttribPointer函数更新顶点格式， // 位置属性 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); // 颜色属性 glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)(3* sizeof(float))); glEnableVertexAttribArray(1); glVertexAttribPointer函数的前几个参数比较明了。这次我们配置属性位置值为1的顶点属性。颜色值有3个float那么大，我们不去标准化这些值。 由于我们现在有了两个顶点属性，我们不得不重新计算步长值。为获得数据队列中下一个属性值（比如位置向量的下个x分量）我们必须向右移动6个float，其中3个是位置值，另外3个是颜色值。这使我们的步长值为6乘以float的字节数（=24字节）。同样，这次我们必须指定一个偏移量。对于每个顶点来说，位置顶点属性在前，所以它的偏移量是0。颜色属性紧随位置数据之后，所以偏移量就是3 * sizeof(float)，用字节来计算就是12字节。 在片段着色器中进行的所谓片段插值(Fragment Interpolation)。当渲染一个三角形时，光栅化(Rasterization)阶段通常会造成比原指定顶点更多的片段。光栅会根据每个片段在三角形形状上所处相对位置决定这些片段的位置。基于这些位置，它会插值(Interpolate)所有片段着色器的输入变量。比如说，我们有一个线段，上面的端点是绿色的，下面的端点是蓝色的。如果一个片段着色器在线段的70%的位置运行，它的颜色输入属性就会是一个绿色和蓝色的线性结合；更精确地说就是30%蓝 + 70%绿。 这正是在这个三角形中发生了什么。我们有3个顶点，和相应的3个颜色，从这个三角形的像素来看它可能包含50000左右的片段，片段着色器为这些像素进行插值颜色。如果你仔细看这些颜色就应该能明白了：红首先变成到紫再变为蓝色。片段插值会被应用到片段着色器的所有输入属性上。]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c++对象模型]]></title>
    <url>%2F2018%2F12%2F31%2Fc-%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[关于对象加上封装后的布局成本c语言中如下声明一个结构体 typedef struct point3d{ float x; float y; float z;}Point3d; struct point3d 转化为class Point3d之后 class Point3d { public: Point3d(float x = 0.0f, float y = 0.0f; float z = 0.0f) :_x(x),_y(y),_z(z){} private: float _x,_y,_y; } 封装带来的布局成本增加了多少？实际是没有增加布局成本的。3个数据成员直接在class object内，member function在classs声明却不出现在class object中，所谓布局的成本主要由virtual引起的。 virtual function 机制用以支持运行时绑定（运行时多态） virtual base class 机制支持多次出现在集成体系中的base class有一个单一的被共享的实例。 基本c++对象模型nostatic data members 被配置在class object之内，static data member存放在class object之外. static 和nostatic function memners放在class object之外 virtual function的处理步骤： 每个class产生出一堆指向virtual functions的指针，放在表格中，这个表格称为虚表virtual table 每个class object 安插一个虚表指针vptr指向虚表（virtual table）. vptr的设定和重置都由每个class的构造函数、拷贝赋值运算符、析构函数自动完成，每个class所关联的type_info object (用以支持runtime type identification, RTTI)也经由virtual table被指出，通常放在virtual table的第一个slot. 声明一个class Point然后查看其对象模型 class Point { public: Point(float x); virtual ~Point(); float x() const; static int PointCount(); protected: virtual ostream&amp; print(ostream&amp; os) const; float _x; static int _point_count; } 加上继承c++支持单一继承和多重继承.base class subobject的data members直接被放置在derived class object,也就是说子类对象中包含基类子对象.基类成员的改变都会导致继承类重新编译.对于虚基类则是扩展子类自己的vittual table维护virtual base class的位置。 class istream : virtual public ios{...}; class ostream : virtual public ios{...}; class iostream : public istream, public ostream{...}; 在虚拟继承的情况下base class 不管在继承链中被派生多少次，永远只有一个实例存在即一个subobject.iostream之中只有virtual ios base class的一个实例. NRV优化函数返回基本是数据类型或者指针类型是通过eax寄存器进行传递的，返回对象对象则会进行命名返回值优化.以外部引用传参的形式去掉函数内部的局部对象构造。 X foo(){ X xx X* px = new X(); xx.foo(); //func是一个虚函数 px-&gt;foo() delete px; rerurn xx } 如上函数有可能内部转化为如下代码： void foo(X &amp;result){ _result.X::X(); px = _new(sizeof(X)); if(px != 0){ px-&gt;X::X(); } func(&amp;_result);//这里涉及到成员函数的语义 (*px-&gt;vtbl[2])(px) //使用virtual机制扩展px-&gt;func() if(px != 0) { (*px-&gt;[1])(px); //扩展delete px _delete(p) } return; } 指针类型 指针类型会指导编译器如何解释某个特定地址中内容及其大小 void*的指针只能够持有一个地址，而不能够通过他操作他所指向的object cast是一种编译指令它不改变一个指针的内容，只影响被指出的大小和其内容的解释方式 c++通过引用或者指针的方式支持多态，是因为他们不会引发任何与类型有关的内存委托， 当一个基类对象直接被初始化为一个子类对象是，子类对象会被切割以放入base type的内存中 构造函数语义学默认构造函数被合成出来执行编译器的所需操作如果类class A含有一个以上的类成员对象，编译器会扩张构造函数，在构造函数中安插代码，以成员类的声明顺序调用每个成员类的默认构造函数，这些代码被安插在用户代码之前. 有四种情况会造成编译器为未声明构造函数的类合成一个默认的构造函数，接着调用member object或者base class的默认构造函数，完成虚函数和虚基类机制。 带有默认构造函数的成员类对象 带有默认构造函数的基类 带有virtual function的类，用来初始化vptr 带有virtual base class的类，用来初始化vptr 拷贝构造函数类中没有任何member或者base class object带有拷贝构造函数，也没有任何的虚函数和虚基类，默认情况下 对象的初始化会展示按位拷贝，这样效率很高且安全. 当对一个object做显示初始化或者object被当做参数交给函数时以及函数返回一个object时（传参、返回值、初始化）构造函数会被调用。 copy 构造函数不展现按位逐次拷贝的时候有编译器产生出来，有四种情况不展现： 当成员类中生命有copy constructor 当基类中存在copy constructor 类中含有virtual function 类有virtual base class 1、2中编译器讲member或者bass class的拷贝构造哈数的调用安插到合成的拷贝构造函数中；3，4是为了对vptr重新初始化. 在构造函数中调用memset或者memcopy会使vptr设置为0class Shape{ public: Shape(){ memset(this, 0, sizeof(Shape);)} virtual ~Shape(); } 编译器扩充构造函数的内容如下： //扩充后的构造函数 Shape::Shape(){ //vptr在用户代码之前被设定 __vptr__Shape = __vtbl__Shape; //memset 会使vptr清0 memset(this, 0, sizeof(Shape)); } 初始化成员列表编译器会操作初始化列表，以成员的声明顺序子构造函数内部在用户代码之前安插初始化代码.当类含有一下四种情况的时候会需要使用成员初始化列表： 初始化一个引用成员 初始化一个constchengyuan 基类构造函数拥有参数 成员类构造函数拥有参数 Data语义学数据成员的布局class X{};一个空类它隐藏1byte的大小，他是被编译器安插进去的一个char,这使得这一class的两个object在内存中配置有独一无二的地址. 非静态的数据成员直接存放在每一个类对象中，对于继承而来的费静态成员也是如此。静态数据成员则放在程序的全局数据段，且只存在一份数据实例. 对成员函数的分析，会在整个class声明完成之后才会出现. 在同一个访问段中member的排列要符合较晚出现的成员在对象中有较高的地址，多个访问段中的数据成员是自由排列的. 数据成员的访问 静态数据成员只有一个实例放在程序的数据段，编译器会对每一个静态数据成员进行编码以获得一个独一无二的识别码 非静态数据成员，会使用隐式类对象机制访问数据（this指针）成员函数的参数中隐藏了一个隐式对象指针. 指向数据成员的指针，其offset值总是被加上1，这样可以使编译系统区分出“一个指向数据成员的指针，用以指出第一个成员”和“一个指向数据成员的指针，没有指出任何成员”. 单一继承无virtual function下的内存布局单一继承下无布局情况下class和struct的布局是一样的. 单一继承有virtaual function下的内存布局 Point3d中含有基类的子对象Point2d subobject，子类数据成员放置在基类子对象之后。 多重继承下的数据布局类体系如下 class Point2d { public: virtual ~Point2d(){}; protected: float _x,_y; }; class Point3d : public Point2d { public: //... protected: float _z; }; class Vertex { public: virtual ~Vertex(){}; protected: Vertex *next; } class Vertex3d: public Point3d, public Vertex { public: //... protected: float mumble; } 要存取第二个基类中的数据成员，将会是怎样的情况需要付出额外的成本吗？不 ，成员的位置在编译期就时就固定了，因此存取数据成员知识一个简单的offset操作，就像单一继承一样简单–不管是经由一个指针或者引用或者是一个对象来存取. 虚拟继承对于虚拟继承主要的问题是如何存取class的共享部分,虚拟继承使用两种策略来实现：指针策略和offset策略. 指针策略为了指出共享类对象每个子类对象安插一些指针，每个指针指向虚基类。 进一步的优化策略的实现：每一个class object如果有一个或者多个virtual base classes，就会由编译器安插一个指针指向virtual base class table.真正的虚基类指针放在虚基类表中. offset策略在虚函数表中放置虚基类的offset. Function语义学虚函数基类的指针或者引用寻址出一个子类对象，虚函数分配表格索引，vptr指向virtual table, virtual table中存放虚函数指针. inline函数inline是一个请求，编译器解说就必须认为它用一个表达式合理的将这个函数扩展开来，扩展期间使用实参代替形参，局部变量在封装的区域内名字唯一. 函数的调用方式 非静态成员函数 改函数签名安插this指针，变为一个非成员函数，可以使类对象调用. 调用对非静态成员的存取有this指针完成 通过name-maping 改为一个外部函数 float Point3d::getX()const{...} extern getX_Point3dFv(const Point3d* this) obj.getX() 等价于 getX_Point3dFv(&amp;obj) ptr-&gt;getX() 等价于 getX_Point3dFv(ptr) 静态成员函数被转为非成员函数，不能访问非静态成员没有this指针 虚成员函数(*ptr-&gt;vptr[1])(ptr) 通过拿到徐表中虚函数地址传入this指针来调用 构造、拷贝、析构语义学构造函数的扩充顺序： 先父类后成员最后自己的调用方式. vptr的初始化在所有base 类构造之后，初始化列表之前（程序代码） 虚基类的构造函数被调用从左到右从深到浅 基类的构造函数被调用，按照基类的生命顺序 设置vptr的指针初值，初始化虚函数表 成员函数的初始化列表被放在构造偶函数内部以成员类的声明顺序,么有构造函数则调用合成的默认的构造函数 构造自己，执行user code 析构函数按照上面相反的顺序调用先自己析构然后类成员对象析构然后重置vptr然后基类析构然后虚基类析构 拷贝构造拷贝构造函数和拷贝复制运算符]]></content>
      <categories>
        <category>c++</category>
      </categories>
      <tags>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl绘制三角形]]></title>
    <url>%2F2018%2F12%2F28%2Fopengl%E7%BB%98%E5%88%B6%E4%B8%89%E8%A7%92%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[顶点数组对象：Vertex Array Object，VAO 顶点缓冲对象：Vertex Buffer Object，VBO 索引缓冲对象：Element Buffer Object，EBO或Index Buffer Object，IBO 渲染管线在OpenGL中，任何事物都在3D空间中，而屏幕和窗口却是2D像素数组，这导致OpenGL的大部分工作都是关于把3D坐标转变为适应你屏幕的2D像素。3D坐标转为2D坐标的处理过程是由OpenGL的图形渲染管线管理的。图形渲染管线可以被划分为两个主要部分：第一部分把你的3D坐标转换为2D坐标，第二部分是把2D坐标转变为实际的有颜色的像素。 2D坐标和像素也是不同的，2D坐标精确表示一个点在2D空间中的位置，而2D像素是这个点的近似值，2D像素受到你的屏幕/窗口分辨率的限制。 图形渲染管线接受一组3D坐标，然后把它们转变为你屏幕上的有色2D像素输出。图形渲染管线可以被划分为几个阶段，每个阶段将会把前一个阶段的输出作为输入。所有这些阶段都是高度专门化的（它们都有一个特定的函数），并且并行执行。GPU上为每一个（渲染管线）阶段运行各自的小程序，从而在图形渲染管线中快速处理你的数据。这些小程序叫做着色器(Shader)。 OpenGL着色器是用OpenGL着色器语言(OpenGL Shading Language, GLSL)写成的。 下面，你会看到一个图形渲染管线的每个阶段的抽象展示。蓝色部分代表的是可以注入自定义的着色器的部分。 图形渲染管线包含很多部分，每个部分都将在转换顶点数据到最终像素这一过程中处理各自特定的阶段。概括性地解释一下渲染管线的每个部分。 顶点数据首先，我们以数组的形式传递3个3D坐标作为图形渲染管线的输入，用来表示一个三角形，这个数组叫做顶点数据(Vertex Data)；顶点数据是一系列顶点的集合。一个顶点(Vertex)是一个3D坐标的数据的集合。而顶点数据是用顶点属性(Vertex Attribute)表示的，它可以包含任何我们想用的数据，但是简单起见，我们还是假定每个顶点只由一个3D位置和一些颜色值组成的吧。 为了让OpenGL知道我们的坐标和颜色值构成的到底是什么，OpenGL需要你去指定这些数据所表示的渲染类型。我们是希望把这些数据渲染成一系列的点？一系列的三角形？还是仅仅是一个长长的线？做出的这些提示叫做图元(Primitive)，任何一个绘制指令的调用都将把图元传递给OpenGL。这是其中的几个：GL_POINTS、GL_TRIANGLES、GL_LINE_STRIP。 顶点着色器图形渲染管线的第一个部分是顶点着色器(Vertex Shader)，它把一个单独的顶点作为输入。顶点着色器主要的目的是把3D坐标转为另一种3D坐标，同时顶点着色器允许我们对顶点属性进行一些基本处理。 图元组装图元装配(Primitive Assembly)阶段将顶点着色器输出的所有顶点作为输入（如果是GL_POINTS，那么就是一个顶点），并所有的点装配成指定图元的形状。 几何着色器图元装配阶段的输出会传递给几何着色器(Geometry Shader)。几何着色器把图元形式的一系列顶点的集合作为输入，它可以通过产生新顶点构造出新的（或是其它的）图元来生成其他形状。例子中，它生成了另一个三角形。 光栅化几何着色器的输出会被传入光栅化阶段(Rasterization Stage)，这里它会把图元映射为最终屏幕上相应的像素，生成供片段着色器(Fragment Shader)使用的片段(Fragment)。在片段着色器运行之前会执行裁切(Clipping)。裁切会丢弃超出你的视图以外的所有像素，用来提升执行效率。 片段着色器OpenGL中的一个片段是OpenGL渲染一个像素所需的所有数据。片段着色器的主要目的是计算一个像素的最终颜色，这也是所有OpenGL高级效果产生的地方。通常，片段着色器包含3D场景的数据（比如光照、阴影、光的颜色等等），这些数据可以被用来计算最终像素的颜色。 测试混合在所有对应颜色值确定以后，最终的对象将会被传到最后一个阶段，我们叫做Alpha测试和混合(Blending)阶段。这个阶段检测片段的对应的深度（和模板(Stencil)）值（后面会讲），用它们来判断这个像素是其它物体的前面还是后面，决定是否应该丢弃。这个阶段也会检查alpha值（alpha值定义了一个物体的透明度）并对物体进行混合(Blend)。所以，即使在片段着色器中计算出来了一个像素输出的颜色，在渲染多个三角形的时候最后的像素颜色也可能完全不同。 顶点输入开始绘制图形之前，我们必须先给OpenGL输入一些顶点数据。OpenGL是一个3D图形库，所以我们在OpenGL中指定的所有坐标都是3D坐标（x、y和z）。OpenGL不是简单地把所有的3D坐标变换为屏幕上的2D像素；OpenGL仅当3D坐标在3个轴（x、y和z）上都为-1.0到1.0的范围内时才处理它。所有在所谓的标准化设备坐标(Normalized Device Coordinates)范围内的坐标才会最终呈现在屏幕上（在这个范围以外的坐标都不会显示）。 由于我们希望渲染一个三角形，我们一共要指定三个顶点，每个顶点都有一个3D位置。我们会将它们以标准化设备坐标的形式（OpenGL的可见区域）定义为一个float数组。 float vertices[] = { -0.5f, -0.5f, 0.0f, 0.5f, -0.5f, 0.0f, 0.0f, 0.5f, 0.0f }; 由于OpenGL是在3D空间中工作的，而我们渲染的是一个2D三角形，我们将它顶点的z坐标设置为0.0。 标准化设备坐标(Normalized Device Coordinates, NDC) 一旦你的顶点坐标已经在顶点着色器中处理过，它们就应该是标准化设备坐标了，标准化设备坐标是一个x、y和z值在-1.0到1.0的一小段空间。任何落在范围外的坐标都会被丢弃/裁剪，不会显示在你的屏幕上。下面你会看到我们定义的在标准化设备坐标中的三角形(忽略z轴)： 与通常的屏幕坐标不同，y轴正方向为向上，(0, 0)坐标是这个图像的中心，而不是左上角。最终你希望所有(变换过的)坐标都在这个坐标空间中，否则它们就不可见了。 你的标准化设备坐标接着会变换为屏幕空间坐标(Screen-space Coordinates)，这是使用你通过glViewport函数提供的数据，进行视口变换(Viewport Transform)完成的。所得的屏幕空间坐标又会被变换为片段输入到片段着色器中。 定义这样的顶点数据以后，我们会把它作为输入发送给图形渲染管线的第一个处理阶段：顶点着色器。它会在GPU上创建内存用于储存我们的顶点数据，还要配置OpenGL如何解释这些内存，并且指定其如何发送给显卡。顶点着色器接着会处理我们在内存中指定数量的顶点。 通过顶点缓冲对象(Vertex Buffer Objects, VBO)管理这个内存，它会在GPU内存（通常被称为显存）中储存大量顶点。使用这些缓冲对象的好处是我们可以一次性的发送一大批数据到显卡上，而不是每个顶点发送一次。从CPU把数据发送到显卡相对较慢，所以只要可能我们都要尝试尽量一次性发送尽可能多的数据。当数据发送至显卡的内存中后，顶点着色器几乎能立即访问顶点，这是个非常快的过程。 顶点缓冲对象是OpenGL对象。就像OpenGL中的其它对象一样，这个缓冲有一个独一无二的ID，所以我们可以使用glGenBuffers函数和一个缓冲ID生成一个VBO对象： unsigned int VBO; glGenBuffers(1, &amp;VBO); OpenGL有很多缓冲对象类型，顶点缓冲对象的缓冲类型是GL_ARRAY_BUFFER。OpenGL允许我们同时绑定多个缓冲，只要它们是不同的缓冲类型。我们可以使用glBindBuffer函数把新创建的缓冲(VBO)绑定到GL_ARRAY_BUFFER目标上： glBindBuffer(GL_ARRAY_BUFFER, VBO); 从这一刻起，我们使用的任何（在GL_ARRAY_BUFFER目标上的）缓冲调用都会用来配置当前绑定的缓冲(VBO)。然后我们可以调用glBufferData函数，它会把之前定义的顶点数据复制到缓冲的内存中： glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); glBufferData是一个专门用来把用户定义的数据复制到当前绑定缓冲的函数。它的第一个参数是目标缓冲的类型：顶点缓冲对象当前绑定到GL_ARRAY_BUFFER目标上。第二个参数指定传输数据的大小(以字节为单位)；用一个简单的sizeof计算出顶点数据大小就行。第三个参数是我们希望发送的实际数据。 第四个参数指定了我们希望显卡如何管理给定的数据。它有三种形式： GL_STATIC_DRAW ：数据不会或几乎不会改变。 GL_DYNAMIC_DRAW：数据会被改变很多。 GL_STREAM_DRAW ：数据每次绘制时都会改变。 三角形的位置数据不会改变，每次渲染调用时都保持原样，所以它的使用类型最好是GL_STATIC_DRAW。如果，比如说一个缓冲中的数据将频繁被改变，那么使用的类型就是GL_DYNAMIC_DRAW或GL_STREAM_DRAW，这样就能确保显卡把数据放在能够高速写入的内存部分。 现在我们已经把顶点数据储存在显卡的内存中，用VBO这个顶点缓冲对象管理。下面我们会创建一个顶点和片段着色器来真正处理这些数据。 顶点着色器顶点着色器(Vertex Shader)是几个可编程着色器中的一个。我们使用着色器以及配置两个非常简单的着色器来绘制我们第一个三角形。 我们需要做的第一件事是用着色器语言GLSL(OpenGL Shading Language)编写顶点着色器，然后编译这个着色器，这样我们就可以在程序中使用它了。下面你会看到一个非常基础的GLSL顶点着色器的源代码： #version 330 core layout (location = 0) in vec3 aPos; void main() { gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0); } 可以看到，GLSL看起来很像C语言。每个着色器都起始于一个版本声明。 下一步，使用in关键字，在顶点着色器中声明所有的输入顶点属性(Input Vertex Attribute)。现在我们只关心位置(Position)数据，所以我们只需要一个顶点属性。GLSL有一个向量数据类型，它包含1到4个float分量，包含的数量可以从它的后缀数字看出来。由于每个顶点都有一个3D坐标，我们就创建一个vec3输入变量aPos。我们同样也通过layout (location = 0)设定了输入变量的位置值(Location)你后面会看到为什么我们会需要这个位置值。 为了设置顶点着色器的输出，我们必须把位置数据赋值给预定义的gl_Position变量，它在幕后是vec4类型的。在main函数的最后，我们将gl_Position设置的值会成为该顶点着色器的输出。由于我们的输入是一个3分量的向量，我们必须把它转换为4分量的。我们可以把vec3的数据作为vec4构造器的参数，同时把w分量设置为1.0f（我们会在后面解释为什么）来完成这一任务。 当前这个顶点着色器可能是我们能想到的最简单的顶点着色器了，因为我们对输入数据什么都没有处理就把它传到着色器的输出了。在真实的程序里输入数据通常都不是标准化设备坐标，所以我们首先必须先把它们转换至OpenGL的可视区域内。 编译着色器我们已经写了一个顶点着色器源码（储存在一个C的字符串中），但是为了能够让OpenGL使用它，我们必须在运行时动态编译它的源码。 我们首先要做的是创建一个着色器对象，注意还是用ID来引用的。所以我们储存这个顶点着色器为unsigned int，然后用glCreateShader创建这个着色器： unsigned int vertexShader; vertexShader = glCreateShader(GL_VERTEX_SHADER); 我们把需要创建的着色器类型以参数形式提供给glCreateShader。由于我们正在创建一个顶点着色器，传递的参数是GL_VERTEX_SHADER。 下一步我们把这个着色器源码附加到着色器对象上，然后编译它： glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL); glCompileShader(vertexShader); glShaderSource函数把要编译的着色器对象作为第一个参数。第二参数指定了传递的源码字符串数量，这里只有一个。第三个参数是顶点着色器真正的源码，第四个参数我们先设置为NULL。 你可能会希望检测在调用glCompileShader后编译是否成功了，如果没成功的话，你还会希望知道错误是什么，这样你才能修复它们。检测编译时错误可以通过以下代码来实现： int success; char infoLog[512]; glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &amp;success); 首先我们定义一个整型变量来表示是否成功编译，还定义了一个储存错误消息（如果有的话）的容器。然后我们用glGetShaderiv检查是否编译成功。如果编译失败，我们会用glGetShaderInfoLog获取错误消息，然后打印它。 if(!success) { glGetShaderInfoLog(vertexShader, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::VERTEX::COMPILATION_FAILED\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; } 如果编译的时候没有检测到任何错误，顶点着色器就被编译成功了。 片段着色器片段着色器所做的是计算像素最后的颜色输出。 在计算机图形中颜色被表示为有4个元素的数组：红色、绿色、蓝色和alpha(透明度)分量，通常缩写为RGBA。当在OpenGL或GLSL中定义一个颜色的时候，我们把颜色每个分量的强度设置在0.0到1.0之间。比如说我们设置红为1.0f，绿为1.0f，我们会得到两个颜色的混合色，即黄色。这三种颜色分量的不同调配可以生成超过1600万种不同的颜色！ #version 330 core out vec4 FragColor; void main() { FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f); } 片段着色器只需要一个输出变量，这个变量是一个4分量向量，它表示的是最终的输出颜色，我们应该自己将其计算出来。我们可以用out关键字声明输出变量，这里我们命名为FragColor。下面，我们将一个alpha值为1.0(1.0代表完全不透明)的橘黄色的vec4赋值给颜色输出。 编译片段着色器的过程与顶点着色器类似，只不过我们使用GL_FRAGMENT_SHADER常量作为着色器类型： unsigned int fragmentShader; fragmentShader = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL); glCompileShader(fragmentShader); 两个着色器现在都编译了，剩下的事情是把两个着色器对象链接到一个用来渲染的着色器程序(Shader Program)中。 着色器程序着色器程序对象(Shader Program Object)是多个着色器合并之后并最终链接完成的版本。如果要使用刚才编译的着色器我们必须把它们链接(Link)为一个着色器程序对象，然后在渲染对象的时候激活这个着色器程序。已激活着色器程序的着色器将在我们发送渲染调用的时候被使用。 当链接着色器至一个程序的时候，它会把每个着色器的输出链接到下个着色器的输入。当输出和输入不匹配的时候，你会得到一个连接错误。 创建一个程序对象很简单： unsigned int shaderProgram; shaderProgram = glCreateProgram(); glCreateProgram函数创建一个程序，并返回新创建程序对象的ID引用。现在我们需要把之前编译的着色器附加到程序对象上，然后用glLinkProgram链接它们： glAttachShader(shaderProgram, vertexShader); glAttachShader(shaderProgram, fragmentShader); glLinkProgram(shaderProgram); 代码应该很清楚，我们把着色器附加到了程序上，然后用glLinkProgram链接。 就像着色器的编译一样，我们也可以检测链接着色器程序是否失败，并获取相应的日志。与上面不同，我们不会调用glGetShaderiv和glGetShaderInfoLog，现在我们使用： glGetProgramiv(shaderProgram, GL_LINK_STATUS, &amp;success); if(!success) { glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog); ... } 得到的结果就是一个程序对象，我们可以调用glUseProgram函数，用刚创建的程序对象作为它的参数，以激活这个程序对象： glUseProgram(shaderProgram); 在glUseProgram函数调用之后，每个着色器调用和渲染调用都会使用这个程序对象（也就是之前写的着色器)了。 对了，在把着色器对象链接到程序对象以后，记得删除着色器对象，我们不再需要它们了： glDeleteShader(vertexShader); glDeleteShader(fragmentShader); 现在，我们已经把输入顶点数据发送给了GPU，并指示了GPU如何在顶点和片段着色器中处理它。OpenGL还不知道它该如何解释内存中的顶点数据，以及它该如何将顶点数据链接到顶点着色器的属性上。 链接顶点属性顶点着色器允许我们指定任何以顶点属性为形式的输入。我们必须手动指定输入数据的哪一个部分对应顶点着色器的哪一个顶点属性。所以，我们必须在渲染前指定OpenGL该如何解释顶点数据。 我们的顶点缓冲数据会被解析为下面这样子： 位置数据被储存为32位浮点值。 每个位置包含3个这样的值。 在这3个值之间没有空隙。这几个值在数组中紧密排列(Tightly Packed)。 数据中第一个值在缓冲开始的位置。 有了这些信息我们就可以使用glVertexAttribPointer函数告诉OpenGL该如何解析顶点数据（应用到逐个顶点属性上）了： //解析顶点数据即解析顶点数据给着色器中的顶点属性 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); //启用顶点属性 glEnableVertexAttribArray(0); glVertexAttribPointer函数的参数非常多，所以我会逐一介绍它们： 第一个参数指定我们要配置的顶点属性。还记得我们在顶点着色器中使用layout(location = 0)定义了position顶点属性的位置值(Location)吗？它可以把顶点属性的位置值设置为0。因为我们希望把数据传递到这一个顶点属性中，所以这里我们传入0。在着色器中的位置索引。 第二个参数指定顶点属性的大小。顶点属性是一个vec3，它由3个值组成，所以大小是3。 第三个参数指定数据的类型，这里是GL_FLOAT(GLSL中vec*都是由浮点数值组成的)。 第四个参数是否希望数据被标准化(Normalize)。如果我们设置为GL_TRUE，所有数据都会被映射到0（对于有符号型signed数据是-1）到1之间。 第五个参数叫做步长(Stride)，它告诉我们在连续的顶点属性组之间的间隔。由于下个组位置数据在3个float之后，我们把步长设置为3 * sizeof(float)。 最后一个参数的类型是void*，需进行这个奇怪的强制类型转换。它表示位置数据在缓冲（vbo）中起始位置的偏移量(Offset)。由于位置数据在数组的开头，所以这里是0。 每个顶点属性从一个VBO管理的内存中获得它的数据，而具体是从哪个VBO获取则是通过在调用glVetexAttribPointer时绑定到GL_ARRAY_BUFFER的VBO决定的。由于在调用glVetexAttribPointer之前绑定的是先前定义的VBO对象，顶点属性0现在会链接到它的顶点数据。 现在我们已经定义了OpenGL该如何解释顶点数据，我们现在应该使用glEnableVertexAttribArray，以顶点属性位置值作为参数，启用顶点属性；顶点属性默认是禁用的。我们使用一个顶点缓冲对象将顶点数据初始化至缓冲中，建立了一个顶点和一个片段着色器，并告诉了OpenGL如何把顶点数据链接到顶点着色器的顶点属性上。在OpenGL中绘制一个物体，代码会像是这样： //创建顶点缓冲区对象（vbo） unsigned int VBO; glGenBuffers(1, &amp;VBO); //绑定vbo到GL_ARRAY_BUFFER目标(GL_ARRAY_BUFFER是顶点缓冲区的类型) glBindBuffer(GL_ARRAY_BUFFER, VBO); //复制顶点数组到缓冲中供OpenGL使用 glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); //设置顶点属性指针,告诉opengl如何解析顶点数据到顶点属性 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); //启用顶点属性 glEnableVertexAttribArray(0); //当我们渲染一个物体时要使用着色器程序 glUseProgram(shaderProgram); //绘制物体 someOpenGLFunctionThatDrawsOurTriangle(); 当多存多个物体，每个物体有多个顶点的时候，绑定正确的缓冲对象，为每个物体配置所有顶点属性很快就变成一件麻烦事。有没有一些方法可以使我们把所有这些状态配置储存在一个对象中，并且可以通过绑定这个对象来恢复状态呢？ 顶点数组对象顶点数组对象(Vertex Array Object, VAO)可以像顶点缓冲对象那样被绑定，任何随后的顶点属性调用都会储存在这个VAO中。这样的好处就是，当配置顶点属性指针时，你只需要将那些调用执行一次，之后再绘制物体的时候只需要绑定相应的VAO就行了。这使在不同顶点数据和属性配置之间切换变得非常简单，只需要绑定不同的VAO就行了。刚刚设置的所有状态都将存储在VAO中 一个顶点数组对象会储存以下这些内容： glEnableVertexAttribArray和glDisableVertexAttribArray的调用。 通过glVertexAttribPointer设置的顶点属性配置。 通过glVertexAttribPointer调用与顶点属性关联的顶点缓冲对象。 创建一个VAO和创建一个VBO很类似： unsigned int VAO; glGenVertexArrays(1, &amp;VAO); 要想使用VAO，要做的只是使用glBindVertexArray绑定VAO。从绑定之后起，我们应该绑定和配置对应的VBO和属性指针，之后解绑VAO供之后使用。当我们打算绘制一个物体的时候，我们只要在绘制物体前简单地把VAO绑定到希望使用的设定上就行了。这段代码应该看起来像这样： //初始化代码（只运行一次 (除非你的物体频繁改变)） :: .. //绑定VAO glBindVertexArray(VAO); //把顶点数组复制到缓冲中供OpenGL使用 glBindBuffer(GL_ARRAY_BUFFER, VAO); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); //设置顶点属性指针 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); [...] // ..:: 绘制代码（渲染循环中） :: .. // 4. 绘制物体 glUseProgram(shaderProgram); glBindVertexArray(VAO); 设置的顶点属性配置 someOpenGLFunctionThatDrawsOurTriangle(); 一个储存了顶点属性配置和应使用的VBO的顶点数组对象。一般当你打算绘制多个物体时，你首先要生成/配置所有的VAO（和必须的VBO及属性指针)，然后储存它们供后面使用。当我们打算绘制物体的时候就拿出相应的VAO，绑定它，绘制完物体后，再解绑VAO。 绘制三角形要想绘制我们想要的物体，OpenGL给我们提供了glDrawArrays函数，它使用当前激活的着色器，之前定义的顶点属性配置，和VBO的顶点数据（通过VAO间接绑定）来绘制图元。 glUseProgram(shaderProgram); //使用着色器 glBindVertexArray(VAO); //设置的顶点属性配置 glDrawArrays(GL_TRIANGLES, 0, 3); glDrawArrays函数第一个参数是我们打算绘制的OpenGL图元的类型。由于我们在一开始时说过，我们希望绘制的是一个三角形，这里传递GL_TRIANGLES给它。第二个参数指定了顶点数组的起始索引，我们这里填0。最后一个参数指定我们打算绘制多少个顶点，这里是3 索引缓冲对象索引缓冲对象(Element Buffer Object，EBO，也叫Index Buffer Object，IBO)。要解释索引缓冲对象的工作方式最好还是举个例子：假设我们不再绘制一个三角形而是绘制一个矩形。我们可以绘制两个三角形来组成一个矩形（OpenGL主要处理三角形）。这会生成下面的顶点的集合： float vertices[] = { // 第一个三角形 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, 0.5f, 0.0f, // 左上角 // 第二个三角形 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f // 左上角 }; 可以看到，有几个顶点叠加了。我们指定了右下角和左上角两次！一个矩形只有4个而不是6个顶点，这样就产生50%的额外开销。当我们有包括上千个三角形的模型之后这个问题会更糟糕，这会产生一大堆浪费。更好的解决方案是只储存不同的顶点，并设定绘制这些顶点的顺序。这样子我们只要储存4个顶点就能绘制矩形了，之后只要指定绘制的顺序就行了。 索引缓冲对象的工作方式正是这样的。和顶点缓冲对象一样，EBO也是一个缓冲，它专门储存索引，OpenGL调用这些顶点的索引来决定该绘制哪个顶点。所谓的索引绘制(Indexed Drawing)正是我们问题的解决方案。 首先，我们先要定义（不重复的）顶点，和绘制出矩形所需的索引： float vertices[] = { 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f // 左上角 }; unsigned int indices[] = { // 注意索引从0开始! 0, 1, 3, // 第一个三角形 1, 2, 3 // 第二个三角形 }; 你可以看到，当时用索引的时候，我们只定义了4个顶点，而不是6个。 下一步我们需要创建索引缓冲对象： unsigned int EBO; glGenBuffers(1, &amp;EBO); 与VBO类似，我们先绑定EBO然后用glBufferData把索引复制到缓冲里。同样，和VBO类似，我们会把这些函数调用放在绑定和解绑函数调用之间，只不过这次我们把缓冲的类型定义为GL_ELEMENT_ARRAY_BUFFER。 glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); 要注意的是，我们传递了GL_ELEMENT_ARRAY_BUFFER当作缓冲目标。 最后一件要做的事是用glDrawElements来替换glDrawArrays函数，来指明我们从索引缓冲渲染。 使用glDrawElements时，我们会使用当前绑定的索引缓冲对象中的索引进行绘制： glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 第一个参数指定了我们绘制的模式，这个和glDrawArrays的一样。第二个参数是我们打算绘制顶点的个数，这里填6，也就是说我们一共需要绘制6个顶点。第三个参数是索引的类型，这里是GL_UNSIGNED_INT。最后一个参数里我们可以指定EBO中的偏移量（或者传递一个索引数组，但是这是当你不在使用索引缓冲对象的时候），但是我们会在这里填写0。 glDrawElements函数从当前绑定到GL_ELEMENT_ARRAY_BUFFER目标的EBO中获取索引。这意味着我们必须在每次要用索引渲染一个物体时绑定相应的EBO，这还是有点麻烦。不过顶点数组对象同样可以保存索引缓冲对象的绑定状态。VAO绑定时正在绑定的索引缓冲对象会被保存为VAO的元素缓冲对象。**绑定VAO的同时也会自动绑定EBO。** 当目标是GL_ELEMENT_ARRAY_BUFFER的时候，VAO会储存glBindBuffer的函数调用。这也意味着它也会储存解绑调用，所以确保你没有在解绑VAO之前解绑索引数组缓冲，否则它就没有这个EBO配置了。 最后的初始化和绘制代码现在看起来像这样： // ..:: 初始化代码 :: .. // 1. 绑定顶点数组对象 glBindVertexArray(VAO); // 2. 把我们的顶点数组复制到一个顶点缓冲中，供OpenGL使用 glBindBuffer(GL_ARRAY_BUFFER, VBO); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); // 3. 复制我们的索引数组到一个索引缓冲中，供OpenGL使用 glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); // 4. 设定顶点属性指针 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); [...] // ..:: 绘制代码（渲染循环中） :: .. glUseProgram(shaderProgram); glBindVertexArray(VAO); glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0) glBindVertexArray(0); 运行程序会获得下面这样的图片的结果。左侧图片看应该起来很熟悉，而右侧的则是使用线框模式(Wireframe Mode)绘制的。线框矩形可以显示出矩形的确是由两个三角形组成的。 绘制三角形的代码#include &lt;glad/glad.h&gt; #include &lt;GLFW/glfw3.h&gt; #include &lt;iostream&gt; void framebuffer_size_callback(GLFWwindow* window, int width, int height); void processInput(GLFWwindow *window); // settings const unsigned int SCR_WIDTH = 800; const unsigned int SCR_HEIGHT = 600; const char *vertexShaderSource = &quot;#version 330 core\n&quot; &quot;layout (location = 0) in vec3 aPos;\n&quot; &quot;void main()\n&quot; &quot;{\n&quot; &quot; gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);\n&quot; &quot;}\0&quot;; const char *fragmentShaderSource = &quot;#version 330 core\n&quot; &quot;out vec4 FragColor;\n&quot; &quot;void main()\n&quot; &quot;{\n&quot; &quot; FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);\n&quot; &quot;}\n\0&quot;; int main() { //glfw初始化和设置 glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //创建glfw窗口设置当前上下文设置窗口大小变化回调 GLFWwindow* window = glfwCreateWindow(SCR_WIDTH, SCR_HEIGHT, &quot;LearnOpenGL&quot;, NULL, NULL); if (window == NULL) { std::cout &lt;&lt; &quot;Failed to create GLFW window&quot; &lt;&lt; std::endl; glfwTerminate(); return -1; } glfwMakeContextCurrent(window); glfwSetFramebufferSizeCallback(window, framebuffer_size_callback); // glad: load all OpenGL function pointers if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress)) { std::cout &lt;&lt; &quot;Failed to initialize GLAD&quot; &lt;&lt; std::endl; return -1; } // build and compile our shader program // 创建编译顶点着色器 int vertexShader = glCreateShader(GL_VERTEX_SHADER); glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL); glCompileShader(vertexShader); // check for shader compile errors int success; char infoLog[512]; glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &amp;success); if (!success) { glGetShaderInfoLog(vertexShader, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::VERTEX::COMPILATION_FAILED\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; } //创建编译片段着色器 int fragmentShader = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL); glCompileShader(fragmentShader); // check for shader compile errors glGetShaderiv(fragmentShader, GL_COMPILE_STATUS, &amp;success); if (!success) { glGetShaderInfoLog(fragmentShader, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::FRAGMENT::COMPILATION_FAILED\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; } //创建shader程序 连接顶点片段着色器 连接shader程序 int shaderProgram = glCreateProgram(); glAttachShader(shaderProgram, vertexShader); glAttachShader(shaderProgram, fragmentShader); glLinkProgram(shaderProgram); // check for linking errors glGetProgramiv(shaderProgram, GL_LINK_STATUS, &amp;success); if (!success) { glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::PROGRAM::LINKING_FAILED\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; } //链接完成着shader程序之后删除着色器程序 glDeleteShader(vertexShader); glDeleteShader(fragmentShader); // set up vertex data (and buffer(s)) and configure vertex attributes //顶点数组 float vertices[] = { 0.5f, 0.5f, 0.0f, // top right 0.5f, -0.5f, 0.0f, // bottom right -0.5f, -0.5f, 0.0f, // bottom left -0.5f, 0.5f, 0.0f // top left }; //索引数组 unsigned int indices[] = { // note that we start from 0! 0, 1, 3, // first Triangle 1, 2, 3 // second Triangle }; //创建顶点缓冲对象 顶点数组对象 索引缓冲对象 unsigned int VBO, VAO, EBO; glGenVertexArrays(1, &amp;VAO); glGenBuffers(1, &amp;VBO); glGenBuffers(1, &amp;EBO); // bind the Vertex Array Object first, then bind and set vertex buffer(s), and then configure vertex attributes(s). glBindVertexArray(VAO); //绑定顶点缓冲区 copy顶点数据到顶点缓冲区对象 glBindBuffer(GL_ARRAY_BUFFER, VBO); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); //绑定顶点索引缓冲区 copy顶点索引数据到顶点索引缓冲区 glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); //设置顶点属性指针 解释顶点数据 顶点索引获取顶点数据 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); // note that this is allowed, the call to glVertexAttribPointer registered VBO as the vertex attribute&#39;s bound vertex buffer object so afterwards we can safely unbind glBindBuffer(GL_ARRAY_BUFFER, 0); // remember: do NOT unbind the EBO while a VAO is active as the bound element buffer object IS stored in the VAO; keep the EBO bound. //glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0); // You can unbind the VAO afterwards so other VAO calls won&#39;t accidentally modify this VAO, but this rarely happens. Modifying other // VAOs requires a call to glBindVertexArray anyways so we generally don&#39;t unbind VAOs (nor VBOs) when it&#39;s not directly necessary. glBindVertexArray(0); // uncomment this call to draw in wireframe polygons. //glPolygonMode(GL_FRONT_AND_BACK, GL_LINE); // render loop // ----------- while (!glfwWindowShouldClose(window)) { // input // ----- processInput(window); // render // ------ glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); // draw our first triangle glUseProgram(shaderProgram); glBindVertexArray(VAO); // seeing as we only have a single VAO there&#39;s no need to bind it every time, but we&#39;ll do so to keep things a bit more organized //glDrawArrays(GL_TRIANGLES, 0, 6); //需要绑定顶点数据 glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); //需要绑定顶点索引数据 // glBindVertexArray(0); // no need to unbind it every time // glfw: swap buffers and poll IO events (keys pressed/released, mouse moved etc.) // ------------------------------------------------------------------------------- glfwSwapBuffers(window); glfwPollEvents(); } // optional: de-allocate all resources once they&#39;ve outlived their purpose: // ------------------------------------------------------------------------ glDeleteVertexArrays(1, &amp;VAO); glDeleteBuffers(1, &amp;VBO); glDeleteBuffers(1, &amp;EBO); // glfw: terminate, clearing all previously allocated GLFW resources. // ------------------------------------------------------------------ glfwTerminate(); return 0; } // process all input: query GLFW whether relevant keys are pressed/released this frame and react accordingly // --------------------------------------------------------------------------------------------------------- void processInput(GLFWwindow *window) { if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true); } // glfw: whenever the window size changed (by OS or user resize) this callback function executes // --------------------------------------------------------------------------------------------- void framebuffer_size_callback(GLFWwindow* window, int width, int height) { // make sure the viewport matches the new window dimensions; note that width and // height will be significantly larger than specified on retina displays. glViewport(0, 0, width, height); }]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl纹理]]></title>
    <url>%2F2018%2F12%2F27%2Fopengl%E7%BA%B9%E7%90%86%2F</url>
    <content type="text"><![CDATA[关于纹理可以为每个顶点添加颜色来增加图形的细节，从而创建出丰富的图像。想让图形看起来更真实，我们就必须有足够多的顶点，从而指定足够多的颜色。这将会产生很多额外开销.纹理是一个2D图片，它可以用来添加物体的细节，这样就可以让物体非常精细而不用指定额外的顶点。 为了能够把纹理映射(Map)到三角形上，我们需要指定三角形的每个顶点各自对应纹理的哪个部分。这样每个顶点就会关联着一个纹理坐标(Texture Coordinate)，用来标明该从纹理图像的哪个部分采样。之后在图形的其它片段上进行片段插值(Fragment Interpolation)。 纹理坐标在x和y轴上，范围为0到1之间（注意我们使用的是2D纹理图像）。使用纹理坐标获取纹理颜色叫做采样(Sampling)。纹理坐标起始于(0, 0)，也就是纹理图片的左下角，终始于(1, 1)，即纹理图片的右上角。下面的图片展示了我们是如何把纹理坐标映射到三角形上的。 我们为三角形指定了3个纹理坐标点。如上图所示，我们希望三角形的左下角对应纹理的左下角，因此我们把三角形左下角顶点的纹理坐标设置为(0, 0)；三角形的上顶点对应于图片的上中位置所以我们把它的纹理坐标设置为(0.5, 1.0)；同理右下方的顶点设置为(1, 0)。我们只要给顶点着色器传递这三个纹理坐标就行了，接下来它们会被传片段着色器中，它会为每个片段进行纹理坐标的插值 纹理坐标看起来就像这样： float texCoords[] = { 0.0f, 0.0f, // 左下角 1.0f, 0.0f, // 右下角 0.5f, 1.0f // 上中 }; 纹理环绕方式纹理坐标的范围通常是从(0, 0)到(1, 1)，那如果我们把纹理坐标设置在范围之外会发生什么？OpenGL默认的行为是重复这个纹理图像，其他的环绕方式 环绕方式 描述 GL_REPEAT 对纹理的默认行为。重复纹理图像。 GL_MIRRORED_REPEAT 和GL_REPEAT一样，但每次重复图片是镜像放置的。 GL_CLAMP_TO_EDGE 纹理坐标会被约束在0到1之间，超出的部分会重复纹理坐标的边缘，产生一种边缘被拉伸的效果。 GL_CLAMP_TO_BORDER 超出的坐标为用户指定的边缘颜色。 纹理选项都可以使用glTexParameter*函数对单独的一个坐标轴设置（s、t、r）它们和x、y、z是等价的）： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT); 第一个参数指定了纹理目标；我们使用的是2D纹理，因此纹理目标是GL_TEXTURE_2D。第二个参数需要我们指定设置的选项与应用的纹理轴。我们打算配置的是WRAP选项，并且指定S和T轴。最后一个参数需要我们传递一个环绕方式(Wrapping)，在这个例子中OpenGL会给当前激活的纹理设定纹理环绕方式为GL_MIRRORED_REPEAT。 如果我们选择GL_CLAMP_TO_BORDER选项，我们还需要指定一个边缘的颜色。这需要使用glTexParameter函数的fv后缀形式，用GL_TEXTURE_BORDER_COLOR作为它的选项，并且传递一个float数组作为边缘的颜色值： float borderColor[] = { 1.0f, 1.0f, 0.0f, 1.0f }; glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, borderColor); 纹理过滤纹理坐标不依赖于分辨率(Resolution)，它可以是任意浮点值，所以OpenGL需要知道怎样将纹理像素(Texture Pixel)映射到纹理坐标。当你有一个很大的物体但是纹理的分辨率很低的时候这就变得很重要了。OpenGL也有对于纹理过滤(Texture Filtering)的选项。纹理过滤有很多个选项，但是现在我们只讨论最重要的两种：GL_NEAREST和GL_LINEAR。 GL_NEAREST（也叫邻近过滤，Nearest Neighbor Filtering）是OpenGL默认的纹理过滤方式。当设置为GL_NEAREST的时候，OpenGL会选择中心点最接近纹理坐标的那个像素。下图中你可以看到四个像素，加号代表纹理坐标。左上角那个纹理像素的中心距离纹理坐标最近，所以它会被选择为样本颜色： GL_LINEAR（也叫线性过滤，(Bi)linear Filtering）它会基于纹理坐标附近的纹理像素，计算出一个插值，近似出这些纹理像素之间的颜色。一个纹理像素的中心距离纹理坐标越近，那么这个纹理像素的颜色对最终的样本颜色的贡献越大。下图中你可以看到返回的颜色是邻近像素的混合色： 那么这两种纹理过滤方式有怎样的视觉效果呢？让我们看看在一个很大的物体上应用一张低分辨率的纹理会发生什么吧（纹理被放大了，每个纹理像素都能看到）： GL_NEAREST产生了颗粒状的图案，我们能够清晰看到组成纹理的像素，而GL_LINEAR能够产生更平滑的图案，很难看出单个的纹理像素。GL_LINEAR可以产生更真实的输出，但有些开发者更喜欢8-bit风格，所以他们会用GL_NEAREST选项。 当进行放大(Magnify)和缩小(Minify)操作的时候可以设置纹理过滤的选项，比如你可以在纹理被缩小的时候使用邻近过滤，被放大时使用线性过滤。我们需要使用glTexParameter*函数为放大和缩小指定过滤方式。这段代码看起来会和纹理环绕方式的设置很相似： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 多级纹理再提个大场景中，每个物体上都有纹理。有些物体会很远，但其纹理会拥有与近处物体同样高的分辨率。由于远处的物体可能只产生很少的片段，OpenGL从高分辨率纹理中为这些片段获取正确的颜色值就很困难，因为它需要对一个跨过纹理很大部分的片段只拾取一个纹理颜色。在小物体上这会产生不真实的感觉，对它们使用高分辨率纹理浪费内存。 OpenGL使用一种叫做多级渐远纹理(Mipmap)的概念来解决这个问题，它简单来说就是一系列的纹理图像，后一个纹理图像是前一个的二分之一。多级渐远纹理背后的理念很简单：距观察者的距离超过一定的阈值，OpenGL会使用不同的多级渐远纹理，即最适合物体的距离的那个。由于距离远，解析度不高也不会被用户注意到。同时，多级渐远纹理另一加分之处是它的性能非常好。让我们看一下多级渐远纹理是什么样子的： 手工为每个纹理图像创建一系列多级渐远纹理很麻烦，幸好OpenGL有一个glGenerateMipmaps函数，在创建完一个纹理后调用它OpenGL就会承担接下来的所有工作了。后面的教程中你会看到该如何使用它。 在渲染中切换多级渐远纹理级别(Level)时，OpenGL在两个不同级别的多级渐远纹理层之间会产生不真实的生硬边界。就像普通的纹理过滤一样，切换多级渐远纹理级别时你也可以在两个不同多级渐远纹理级别之间使用NEAREST和LINEAR过滤。为了指定不同多级渐远纹理级别之间的过滤方式，你可以使用下面四个选项中的一个代替原有的过滤方式： 过滤方式 描述 GL_NEAREST_MIPMAP_NEAREST 使用最邻近的多级渐远纹理来匹配像素大小，并使用邻近插值进行纹理采样 GL_LINEAR_MIPMAP_NEAREST 使用最邻近的多级渐远纹理级别，并使用线性插值进行采样 GL_NEAREST_MIPMAP_LINEAR 在两个最匹配像素大小的多级渐远纹理之间进行线性插值，使用邻近插值进行采样 GL_LINEAR_MIPMAP_LINEAR 在两个邻近的多级渐远纹理之间使用线性插值，并使用线性插值进行采样 就像纹理过滤一样，我们可以使用glTexParameteri将过滤方式设置为前面四种提到的方法之一： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 一个常见的错误是，将放大过滤的选项设置为多级渐远纹理过滤选项之一。这样没有任何效果，因为多级渐远纹理主要是使用在纹理被缩小的情况下的：纹理放大不会使用多级渐远纹理，为放大过滤设置多级渐远纹理的选项会产生一个GL_INVALID_ENUM错误代码。 生成纹理创建纹理对象，使用id类记录对象 unsigned int texture; glGenTextures(1, &amp;texture); glGenTextures函数首先需要输入生成纹理的数量，然后把它们储存在第二个参数的unsigned int数组中（我们的例子中只是单独的一个unsigned int）， 绑定对象，让之后任何的纹理指令都可以配置当前绑定的纹理： glBindTexture(GL_TEXTURE_2D, texture); 使用图片数据生成一个纹理了： glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data); glGenerateMipmap(GL_TEXTURE_2D); 函数很长，参数也不少，所以我们一个一个地讲解： 第一个参数指定了纹理目标(Target)。设置为GL_TEXTURE_2D意味着会生成与当前绑定的纹理对象在同一个目标上的纹理（任何绑定到GL_TEXTURE_1D和GL_TEXTURE_3D的纹理不会受到影响）。 第二个参数为纹理指定多级渐远纹理的级别，如果你希望单独手动设置每个多级渐远纹理的级别的话。这里我们填0，也就是基本级别。 第三个参数告诉OpenGL我们希望把纹理储存为何种格式。我们的图像只有RGB值，因此我们也把纹理储存为RGB值。 第四个和第五个参数设置最终的纹理的宽度和高度。我们之前加载图像的时候储存了它们，所以我们使用对应的变量。 下个参数应该总是被设为0（历史遗留的问题）。 第七第八个参数定义了源图的格式和数据类型。我们使用RGB值加载这个图像，并把它们储存为char(byte)数组，我们将会传入对应值。 最后一个参数是真正的图像数据。 当调用glTexImage2D时，当前绑定的纹理对象就会被附加上纹理图像。然而，目前只有基本级别(Base-level)的纹理图像被加载了，如果要使用多级渐远纹理，我们必须手动设置所有不同的图像（不断递增第二个参数）。或者，直接在生成纹理之后调用glGenerateMipmap。这会为当前绑定的纹理自动生成所有需要的多级渐远纹理。 生成一个纹理的过程应该看起来像这样： unsigned int texture; //生成并且绑定纹理对象 glGenTextures(1, &amp;texture); glBindTexture(GL_TEXTURE_2D, texture); //为当前绑定的纹理对象设置环绕方式 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT); //多级纹理过滤方式 glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); // 加载并生成纹理 int width, height, nrChannels; unsigned char *data = stbi_load(&quot;container.jpg&quot;, &amp;width, &amp;height, &amp;nrChannels, 0); if (data) { glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data); glGenerateMipmap(GL_TEXTURE_2D); } else { std::cout &lt;&lt; &quot;Failed to load texture&quot; &lt;&lt; std::endl; } 应用纹理使用glDrawElements绘制,我们需要告知OpenGL如何采样纹理，所以我们必须使用纹理坐标更新顶点数据： float vertices[] = { // ---- 位置 ---- ---- 颜色 ---- - 纹理坐标 - 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 1.0f, 1.0f, // 右上 0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, // 右下 -0.5f, -0.5f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, // 左下 -0.5f, 0.5f, 0.0f, 1.0f, 1.0f, 0.0f, 0.0f, 1.0f // 左上 }; 由于我们添加了一个额外的顶点属性，我们必须告诉OpenGL我们新的顶点格式： glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(6 * sizeof(float))); glEnableVertexAttribArray(2); 注意，我们同样需要调整前面两个顶点属性的步长参数为8 * sizeof(float)。 接着我们需要调整顶点着色器使其能够接受顶点坐标为一个顶点属性，并把坐标传给片段着色器： #version 330 core layout (location = 0) in vec3 aPos; layout (location = 1) in vec3 aColor; layout (location = 2) in vec2 aTexCoord; out vec3 ourColor; out vec2 TexCoord; void main() { gl_Position = vec4(aPos, 1.0); ourColor = aColor; TexCoord = aTexCoord; } 片段着色器应该接下来会把输出变量TexCoord作为输入变量。 片段着色器也应该能访问纹理对象，但是我们怎样能把纹理对象传给片段着色器呢？GLSL有一个供纹理对象使用的内建数据类型，叫做采样器(Sampler)，它以纹理类型作为后缀，比如sampler1D、sampler3D，或在我们的例子中的sampler2D。我们可以简单声明一个uniform sampler2D把一个纹理添加到片段着色器中，稍后我们会把纹理赋值给这个uniform。 #version 330 core out vec4 FragColor; in vec3 ourColor; in vec2 TexCoord; uniform sampler2D ourTexture; void main() { FragColor = texture(ourTexture, TexCoord); } 我们使用GLSL内建的texture函数来采样纹理的颜色，它第一个参数是纹理采样器，第二个参数是对应的纹理坐标。texture函数会使用之前设置的纹理参数对相应的颜色值进行采样。这个片段着色器的输出就是纹理的（插值）纹理坐标上的(过滤后的)颜色 现在只剩下在调用glDrawElements之前绑定纹理了，它会自动把纹理赋值给片段着色器的采样器： //glBindTexture中textture是纹理对象的id glBindTexture(GL_TEXTURE_2D, texture); glBindVertexArray(VAO); glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 完成之后你会看到下面的图像： 我们还可以把得到的纹理颜色与顶点颜色混合，来获得更有趣的效果。我们只需把纹理颜色与顶点颜色在片段着色器中相乘来混合二者的颜色： FragColor = texture(ourTexture, TexCoord) * vec4(ourColor, 1.0); 最终的效果应该是顶点颜色和纹理颜色的混合色： 我猜你会说我们的箱子喜欢跳70年代的迪斯科。 纹理单元你可能会奇怪为什么sampler2D变量是个uniform，我们却不用glUniform给它赋值。使用glUniform1i，我们可以给纹理采样器分配一个位置值，这样的话我们能够在一个片段着色器中设置多个纹理。一个纹理的位置值通常称为一个纹理单元(Texture Unit)。一个纹理的默认纹理单元是0，它是默认的激活纹理单元，所以教程前面部分我们没有分配一个位置值。 纹理单元的主要目的是让我们在着色器中可以使用多于一个的纹理。通过把纹理单元赋值给采样器，我们可以一次绑定多个纹理，只要我们首先激活对应的纹理单元。就像glBindTexture一样，我们可以使用glActiveTexture激活纹理单元，传入我们需要使用的纹理单元： glActiveTexture(GL_TEXTURE0); // 在绑定纹理之前先激活纹理单元 glBindTexture(GL_TEXTURE_2D, texture); 激活纹理单元之后，接下来的glBindTexture函数调用会绑定这个纹理到当前激活的纹理单元，纹理单元GL_TEXTURE0默认总是被激活，所以我们在前面的例子里当我们使用glBindTexture的时候，无需激活任何纹理单元。 OpenGL至少保证有16个纹理单元供你使用，也就是说你可以激活从GL_TEXTURE0到GL_TEXTRUE15。它们都是按顺序定义的，所以我们也可以通过GL_TEXTURE0 + 8的方式获得GL_TEXTURE8，这在当我们需要循环一些纹理单元的时候会很有用。 我们仍然需要编辑片段着色器来接收另一个采样器。这应该相对来说非常直接了： #version 330 core ... uniform sampler2D texture1; uniform sampler2D texture2; void main() { FragColor = mix(texture(texture1, TexCoord), texture(texture2, TexCoord), 0.2); } 最终输出颜色现在是两个纹理的结合。GLSL内建的mix函数需要接受两个值作为参数，并对它们根据第三个参数进行线性插值。如果第三个值是0.0，它会返回第一个输入；如果是1.0，会返回第二个输入值。0.2会返回80%的第一个输入颜色和20%的第二个输入颜色，即返回两个纹理的混合色。 我们现在需要载入并创建另一个纹理；你应该对这些步骤很熟悉了。记得创建另一个纹理对象，载入图片，使用glTexImage2D生成最终纹理。 为了使用第二个纹理（以及第一个），我们必须改变一点渲染流程，先绑定两个纹理到对应的纹理单元，然后定义哪个uniform采样器对应哪个纹理单元： glActiveTexture(GL_TEXTURE0); glBindTexture(GL_TEXTURE_2D, texture1); glActiveTexture(GL_TEXTURE1); glBindTexture(GL_TEXTURE_2D, texture2); glBindVertexArray(VAO); glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 我们还要通过使用glUniform1i设置每个采样器的方式告诉OpenGL每个着色器采样器属于哪个纹理单元。我们只需要设置一次即可，所以这个会放在渲染循环的前面： ourShader.use(); // 别忘记在激活着色器前先设置uniform！ glUniform1i(glGetUniformLocation(ourShader.ID, &quot;texture1&quot;), 0); // 手动设置 ourShader.setInt(&quot;texture2&quot;, 1); // 或者使用着色器类设置 while(...) { [...] } 通过使用glUniform1i设置采样器，我们保证了每个uniform采样器对应着正确的纹理单元。你应该能得到下面的结果： 你可能注意到纹理上下颠倒了！这是因为OpenGL要求y轴0.0坐标是在图片的底部的，但是图片的y轴0.0坐标通常在顶部。在图像加载时帮助我们翻转y轴。]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cocos2dx批处理渲染]]></title>
    <url>%2F2018%2F12%2F27%2Fcocos2dx%E6%89%B9%E5%A4%84%E7%90%86%E6%B8%B2%E6%9F%93%2F</url>
    <content type="text"></content>
      <categories>
        <category>cocos2dx</category>
      </categories>
      <tags>
        <tag>cocos2dx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opengl基础]]></title>
    <url>%2F2018%2F12%2F27%2Fopengl%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[openglopengl是一个由Khronos组织制定并维护的规范(Specification) 。是一系列的图形软件编程接口，和gdi类似。opengl有很多封装的库最有名的GLFW库。接下来很多东西以GLFW 为例子来说明一些api的使用问题，但这并不影响opengl本身的逻辑表述。 状态机OpenGL自身是一个巨大的状态机(State Machine)：一系列的变量描述OpenGL此刻应当如何运行。OpenGL的状态通常被称为OpenGL上下文(Context)。我们通常使用如下途径去更改OpenGL状态：设置选项，操作缓冲。最后，我们使用当前OpenGL上下文来渲染。 假设当我们想告诉OpenGL去画线段而不是三角形的时候，我们通过改变一些上下文变量来改变OpenGL状态，从而告诉OpenGL如何去绘图。一旦我们改变了OpenGL的状态为绘制线段，下一个绘制命令就会画出线段而不是三角形。 当使用OpenGL的时候，我们会遇到一些状态设置函数(State-changing Function)，这类函数将会改变上下文。以及状态使用函数(State-using Function)，这类函数会根据当前OpenGL的状态执行一些操作。只要你记住OpenGL本质上是个大状态机，就能更容易理解它的大部分特性。 对象在OpenGL中一个对象是指一些选项的集合，它代表OpenGL状态的一个子集 。 当我们使用一个对象时，通常看起来像如下一样： // OpenGL的状态 struct OpenGL_Context { ... object* object_Window_Target; ... }; // 创建对象 unsigned int objectId = 0; glGenObject(1, &amp;objectId); // 绑定对象至上下文 glBindObject(GL_WINDOW_TARGET, objectId); // 设置当前绑定到 GL_WINDOW_TARGET 的对象的一些选项 glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800); glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600); // 将上下文对象设回默认 glBindObject(GL_WINDOW_TARGET, 0); 这一段代码展现了使用OpenGL时常见的工作流。我们首先创建一个对象，然后用一个id保存它的引用（实际数据被储存在后台）。然后我们将对象绑定至上下文的目标位置（例子中窗口对象目标的位置被定义成GL_WINDOW_TARGET）。接下来我们设置窗口的选项。最后我们将目标位置的对象id设回0，解绑这个对象。设置的选项将被保存在objectId所引用的对象中，一旦我们重新绑定这个对象到GL_WINDOW_TARGET位置，这些选项就会重新生效。 程序结构我们要开始一个图形渲染程序，首要是要选择gl库，因为要使用api.然后创建窗口、设置视口、设置窗口大小调整后的回调在回调中要处理视口、接着是渲染循环、还要处理处输入等。 实例化配置glfwint main() { glfwInit(); //初始化glfw glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); //配置glfw glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); return 0; } 首先，我们在main函数中调用glfwInit函数来初始化GLFW，然后我们可以使用glfwWindowHint函数来配置GLFW。glfwWindowHint函数的第一个参数代表选项的名称，我们可以从很多以GLFW_开头的枚举值中选择；第二个参数接受一个整形，用来设置这个选项的值 创建窗口接下来我们创建一个窗口对象，这个窗口对象存放了所有和窗口相关的数据，而且会被GLFW的其他函数频繁地用到。 GLFWwindow* window = glfwCreateWindow(800, 600, &quot;LearnOpenGL&quot;, NULL, NULL); if (window == NULL) { glfwTerminate(); return -1; } glfwMakeContextCurrent(window); glfwCreateWindow函数需要窗口的宽和高作为它的前两个参数。第三个参数表示这个窗口的名称（标题），。这个函数将会返回一个GLFWwindow对象，创建完窗口我们就可以通知GLFW将我们窗口的上下文设置为当前线程的主上下文了。 视口必须告诉OpenGL渲染窗口的尺寸大小，即视口(Viewport)，这样OpenGL才只能知道怎样根据窗口大小显示数据和坐标。我们可以通过调用glViewport函数来设置窗口的维度(Dimension)： glViewport(0, 0, 800, 600); glViewport函数前两个参数控制窗口左下角的位置。第三个和第四个参数控制渲染窗口的宽度和高度（像素）。 OpenGL幕后使用glViewport中定义的位置和宽高进行2D坐标的转换，将OpenGL中的位置坐标转换为你的屏幕坐标，处理过的OpenGL坐标范围只为-1到1。 当窗口大小发生变换的时候需要设置视口的大小： glfwSetFramebufferSizeCallback(window, [](GLFWwindow* window, int width, int height){ glViewport(0, 0, width, height); }); 处理输入我们同样也希望能够在GLFW中实现一些输入控制，这可以通过使用GLFW的几个输入函数来完成。我们将会使用GLFW的glfwGetKey函数，它需要一个窗口以及一个按键作为输入。这个函数将会返回这个按键是否正在被按下。我们将创建一个processInput函数来让所有的输入代码保持整洁。 void processInput(GLFWwindow *window) { if(glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true); } 渲染循环需要在程序中添加一个while循环，我们可以把它称之为渲染循环(Render Loop)，它能在我们让GLFW退出前一直保持运行。下面几行的代码就实现了一个简单的渲染循环： // 渲染循环 while(!glfwWindowShouldClose(window)) { // 输入 processInput(window); // 渲染指令 ... glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); // 检查并调用事件，交换缓冲 glfwPollEvents(); glfwSwapBuffers(window); } glfwTerminate(); glfwWindowShouldClose函数在我们每次循环的开始前检查一次GLFW是否被要求退出，如果是的话该函数返回true然后渲染循环便结束了，之后为我们就可以关闭应用程序了。 glfwPollEvents函数检查有没有触发什么事件（比如键盘输入、鼠标移动等）、更新窗口状态，并调用对应的回调函数（可以通过回调方法手动设置）。 glfwSwapBuffers函数会交换颜色缓冲（它是一个储存着GLFW窗口每一个像素颜色值的大缓冲），它在这一迭代中被用来绘制，并且将会作为输出显示在屏幕上。 glClear函数来清空屏幕的颜色缓冲，它接受一个缓冲位(Buffer Bit)来指定要清空的缓冲，可能的缓冲位有GL_COLOR_BUFFER_BIT，GL_DEPTH_BUFFER_BIT和GL_STENCIL_BUFFER_BIT。 调用了glClearColor来设置清空屏幕所用的颜色 glClearColor函数是一个状态设置函数，而glClear函数则是一个状态使用的函数，它使用了当前的状态来获取应该清除为的颜色。 glfwTerminate(); 释放所有申请的资源 双缓冲(Double Buffer)应用程序使用单缓冲绘图时可能会存在图像闪烁的问题。 这是因为生成的图像不是一下子被绘制出来的，而是按照从左到右，由上而下逐像素地绘制而成的。最终图像不是在瞬间显示给用户，而是通过一步一步生成的，这会导致渲染的结果很不真实。为了规避这些问题，我们应用双缓冲渲染窗口应用程序。前缓冲保存着最终输出的图像，它会在屏幕上显示；而所有的的渲染指令都会在后缓冲上绘制。当所有的渲染指令执行完毕后，我们交换(Swap)前缓冲和后缓冲，这样图像就立即呈显出来，之前提到的不真实感就消除了。 最终的程序结构#include &lt;glad/glad.h&gt; #include &lt;GLFW/glfw3.h&gt; #include &lt;iostream&gt; void framebuffer_size_callback(GLFWwindow* window, int width, int height); void processInput(GLFWwindow *window); // settings const unsigned int SCR_WIDTH = 800; const unsigned int SCR_HEIGHT = 600; int main() { //glfw初始化和设置 glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //创建窗口配置窗口 GLFWwindow* window = glfwCreateWindow(SCR_WIDTH, SCR_HEIGHT, &quot;LearnOpenGL&quot;, NULL, NULL); if (window == NULL) { glfwTerminate(); return -1; } //设置问当前窗口上下文 glfwMakeContextCurrent(window); //设置窗口大小改变的回调 处理视口变化 glfwSetFramebufferSizeCallback(window, framebuffer_size_callback); // render loop while (!glfwWindowShouldClose(window)) { // input processInput(window); // render glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); // glfw: swap buffers and poll IO events (keys pressed/released, mouse moved etc.) // ------------------------------------------------------------------------------- glfwSwapBuffers(window); glfwPollEvents(); } // glfw: terminate, clearing all previously allocated GLFW resources. glfwTerminate(); return 0; } void processInput(GLFWwindow *window) { if(glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true); } void framebuffer_size_callback(GLFWwindow* window, int width, int height) { glViewport(0, 0, width, height); }]]></content>
      <categories>
        <category>opengl</category>
      </categories>
      <tags>
        <tag>opengl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cocos2dx是如何绘制图片的]]></title>
    <url>%2F2018%2F12%2F18%2Fcocos2dx%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%98%E5%88%B6%E5%9B%BE%E7%89%87%E7%9A%84%2F</url>
    <content type="text"><![CDATA[cocos2dx绘制单个图片的渲染命令是QUAD_COMMAND,通过分析这个命令可以学习opengl es是如何处理图片渲染的. 关于VAO和VBO顶点数组对象（Vertex Array Object 即VAO）是一个包含多个顶点缓冲区对象（Vertex Buffer Object， 即 VBO）的对象，一般存储一个可渲染物体的顶点信息. 顶点缓冲区对象（ VBO）是你显卡内存中的一块高速内存缓冲区，用来存储顶点的所有信息。 顶点数组指定的顶点数据保存在客户内存中,在进行glDrawArray或者glDrawElements等绘图调用时，这些数据必须同客户内存复制到图形内存中,没必要每次绘图时都复制顶点数据，而是在图形内存中缓存这些数据，这样可以显著改善渲染性能，也可以降低内存带宽和电力消耗需求,这就是顶点缓冲区对象发挥作用的地方.在OpenGL3.0中，出现了更进一步的VAO，VBO通过绘制上下文获得绘制状态，VAO可以拥有多个VBO，它记录所有绘制状态，它的代码更简洁，效率更高. void Renderer::setupBuffer() { if(Configuration::getInstance()-&gt;supportsShareableVAO()) { //初始化VBO和VAO setupVBOAndVAO(); } else { //不支持VAO，只初始化VBO setupVBO(); } } void Renderer::setupVBOAndVAO() { //一个VAO glGenVertexArrays(1, &amp;_quadVAO); //绑定VAO GL::bindVAO(_quadVAO); //创建生成两个VBO glGenBuffers(2, &amp;_buffersVBO[0]); //顶点Buffer glBindBuffer(GL_ARRAY_BUFFER, _buffersVBO[0]); glBufferData(GL_ARRAY_BUFFER, sizeof(_quads[0]) * VBO_SIZE, _quads, GL_DYNAMIC_DRAW); //这里就是VAO和VBO的区别，VAO把这些放到初始化中，无论后面绘制多少次，只要他不被改变，这段代码只会被调用一次，而VBO中，这个功能的代码会在每次被绘制时调用，这样就节约了效率 //位置 glEnableVertexAttribArray(GLProgram::VERTEX_ATTRIB_POSITION); glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_POSITION, 3, GL_FLOAT, GL_FALSE, sizeof(V3F_C4B_T2F), (GLvoid*) offsetof( V3F_C4B_T2F, vertices)); //颜色 glEnableVertexAttribArray(GLProgram::VERTEX_ATTRIB_COLOR); glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_COLOR, 4, GL_UNSIGNED_BYTE, GL_TRUE, sizeof(V3F_C4B_T2F), (GLvoid*) offsetof( V3F_C4B_T2F, colors)); //纹理坐标数据 glEnableVertexAttribArray(GLProgram::VERTEX_ATTRIB_TEX_COORDS); glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_TEX_COORDS, 2, GL_FLOAT, GL_FALSE, sizeof(V3F_C4B_T2F), (GLvoid*) offsetof( V3F_C4B_T2F, texCoords)); //索引Buffer glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, _buffersVBO[1]); glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(_indices[0]) * VBO_SIZE * 6, _indices, GL_STATIC_DRAW); //取消VAO GL::bindVAO(0); glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0); glBindBuffer(GL_ARRAY_BUFFER, 0); CHECK_GL_ERROR_DEBUG(); } void Renderer::setupVBO() { //创建生成两个VBO glGenBuffers(2, &amp;_buffersVBO[0]); //调用函数绑定buffer mapBuffers(); } void Renderer::mapBuffers() { //GL_ARRAY_BUFFER 表示顶点数据 //GL_ELEMENT_ARRAY_BUFFER 表示索引数据 //避免改变buffer元素 GL::bindVAO(0); //绑定id 顶点数据 glBindBuffer(GL_ARRAY_BUFFER, _buffersVBO[0]); //为改id制定一段内存区域 glBufferData(GL_ARRAY_BUFFER, sizeof(_quads[0]) * VBO_SIZE, _quads, GL_DYNAMIC_DRAW); glBindBuffer(GL_ARRAY_BUFFER, 0); //第二个VBO 索引数据 glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, _buffersVBO[1]); glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(_indices[0]) * VBO_SIZE * 6, _indices, GL_STATIC_DRAW); glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0); CHECK_GL_ERROR_DEBUG(); } 0l;需要介绍的两个关键的函数 glBindBuffer：它绑定缓冲区对象表示选择未来的操作将影响哪个缓冲区对象。如果应用程序有多个缓冲区对象，就需要多次调用glBindBuffer()函数：一次用于初始化缓冲区对象以及它的数据，以后的调用要么选择用于渲染的缓冲区对象，要么对缓冲区对象的数据进行更新。 当传入的第二个参数第一次使用一个非零无符号整数时，创建一个新的缓冲区对象；当第二个参数是之前使用过的，这个缓冲区对象成为活动缓冲区对象；如果第二个参数值为0时，停止使用缓冲区对象 glBufferData：保留空间存储数据，他分配一定大小的（第二个参数）的openGL服务端内存，用于存储顶点数据或索引。这个被绑定的对象之前相关联的数据都会被清除。 glBufferData参数介绍 参数1，目标GL_ARRAY_BUFFER或者GL_ELEMENT_ARRAY_BUFFER 参数2，内存容量 参数3，用于初始化缓冲区对象，可以使一个指针，也可以是空 参数4，如何读写，可以选择如下几种 GL_DYNAMIC_DRAW:多次指定，多次作为绘图和图像指定函数的源数据，缓冲区对象的数据不仅常常需要进行更新，而且使用频率也非常高 GL_STATIC_DRAW:数据只指定一次，多次作为绘图和图像指定函数的源数据，缓冲区对象的数据只指定1次，但是这些数据被使用的频率很高 GL_STREAM_DRAW:数据只指定一次，最多只有几次作为绘图和图像指定函数的源数据，缓冲区对象中的数据常常需要更新，但是在绘图或其他操作中使用这些数据的次数较少 从初始化的代码上，为什么VAO反倒复杂了呢？因为他只是把绘制时需要做的一些事情提前放到初始化函数中，来看一下绘制流程。 //当前的openGL是否支持VAO if (Configuration::getInstance()-&gt;supportsShareableVAO()) { //绑定顶点数组 glBindBuffer(GL_ARRAY_BUFFER, _buffersVBO[0]); //向缓冲区申请空间并指定数据传输方式 glBufferData(GL_ARRAY_BUFFER, sizeof(_quads[0]) * (_numQuads), nullptr, GL_DYNAMIC_DRAW); //提供缓冲区对象包含整个数据集合的更新 void *buf = glMapBuffer(GL_ARRAY_BUFFER, GL_WRITE_ONLY); memcpy(buf, _quads, sizeof(_quads[0])* (_numQuads)); //缓冲区对象的更新完成 glUnmapBuffer(GL_ARRAY_BUFFER); //为了禁用缓冲区对象，可以用0作为缓冲区对象的标识符来调用glBindBuffer()函数。这将把OpenGL切换为默认的不使用缓冲区对象的模式。 glBindBuffer(GL_ARRAY_BUFFER, 0); //Bind VAO GL::bindVAO(_quadVAO); } else { #define kQuadSize sizeof(_quads[0].bl) glBindBuffer(GL_ARRAY_BUFFER, _buffersVBO[0]); glBufferData(GL_ARRAY_BUFFER, sizeof(_quads[0]) _numQuads , _quads, GL_DYNAMIC_DRAW); //激活顶点颜色纹理坐标的属性 GL::enableVertexAttribs(GL::VERTEX_ATTRIB_FLAG_POS_COLOR_TEX); //顶点 glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_POSITION, 3, GL_FLOAT, GL_FALSE, kQuadSize, (GLvoid) offsetof(V3F_C4B_T2F, vertices)); //颜色 glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_COLOR, 4, GL_UNSIGNED_BYTE, GL_TRUE, kQuadSize, (GLvoid) offsetof(V3F_C4B_T2F, colors)); //纹理坐标 glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_TEX_COORDS, 2, GL_FLOAT, GL_FALSE, kQuadSize, (GLvoid) offsetof(V3F_C4B_T2F, texCoords)); glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, _buffersVBO[1]); } 可以看到，这些设置属性的函数放在了绘制函数里，虽然看似是一样的，但是绘制函数会被调用的更频繁，所以把这些函数放到初始化函数中可以大幅提高程序的效率。 这里介绍VAO的两个函数： glMapBuffer函数返回一个指针，指向与第一个参数相关联的当前绑定缓冲区对象的数据存储。第一个参数与glBufferData的第一个参数一致。第二个参数是GL_READ_ONLY、GL_WRITE_ONLY或GL_READ_WRITE之一，表示可以对数据进行的操作。 glUnmapBuffer表示对当前绑定缓冲区对象的更新已经完成，并且这个缓冲区可以释放。 enableVertexAttribs激活相关属性，激活的属性可以调用glVertexAttribPointer指定数据源，可选的有VERTEX_ATTRIB_FLAG_POSITION，VERTEX_ATTRIB_FLAG_COLOR和VERTEX_ATTRIB_FLAG_TEX_COORDS，这里这个参数是激活这三个。 glVertexAttribPointer指定了渲染时第一个参数代表的索引值的顶点属性数组的数据格式和位置。 第一个参数指定要修改的顶点属性的索引值，包括VERTEX_ATTRIB_POSITION（位置），VERTEX_ATTRIB_COLOR（颜色），VERTEX_ATTRIB_TEX_COORDS（纹理坐标）。 第二个参数指定每个属性值的组件数量且必须为1、2、3、4之一。 第三个参数指定数组中每个组件的数据类型。可用的符号常量有GL_BYTE, GL_UNSIGNED_BYTE, GL_SHORT,GL_UNSIGNED_SHORT,GL_FIXED, 和 GL_FLOAT，初始值为GL_FLOAT。 第四个参数指定当被访问时，固定点数据值是否应该被归一化（GL_TRUE，意味着整数型的值会被映射至区间-1,1，或者区间[0,1]（无符号整数））或者直接转换为固定点值（GL_FALSE）。 第五个参数指定了一个属性到下一个属性之间的步长（这就允许属性值被存储在单一数组或者不同的数组中）。也就是连续顶点属性之间的偏移量。如果为0，那么它们是紧密排列在一起的。初始值为0。 第六个参数指定一个指针，指向数组中第一个顶点属性的第一个组件。初始值为0。 最后需要调用绘制元素函数，绘制这些信息 glDrawElements(GL_TRIANGLES, (GLsizei) quadsToDraw6, GL_UNSIGNED_SHORT, (GLvoid) (startQuad6sizeof(_indices[0])) );它根据索引绘图(注意：顶点数据和索引各自使用不同的缓冲区) 需要注意的是在Renderer的析构函数中要调用glDeleteBuffers来释放它的资源，并使它的标识可以其他缓冲区对象使用。 QUAD_COMMAND的绘制函数QUAD_COMMAND命令回调用drawBatchedQuads调用绘制函数 else if ( RenderCommand::Type::QUAD_COMMAND == commandType ) { flush3D(); if(_filledIndex &gt; 0) { drawBatchedTriangles(); _lastMaterialID = 0; } auto cmd = static_cast&lt;QuadCommand*&gt;(command); //Batch quads if( (_numberQuads + cmd-&gt;getQuadCount()) * 4 &gt; VBO_SIZE ) { drawBatchedQuads(); } _batchQuadCommands.push_back(cmd); fillQuads(cmd); } void Renderer::flush() { //绘制 drawBatchedQuads(); //清空 _lastMaterialID = 0; } 这个处理主要是把命令存入_batchedQuadCommands中，如果如果Quad数据量超过VBO的大小，那么调用绘制，将缓存的命令全部绘制.如果一直没有超过VBO的大小，drawBatchedQuads绘制函数将在flush被调用时调用]]></content>
      <categories>
        <category>cocos2dx</category>
      </categories>
      <tags>
        <tag>cocos2dx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cocos2dx渲染架构]]></title>
    <url>%2F2018%2F12%2F17%2Fcocos2dx%E6%B8%B2%E6%9F%93%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[2dx的时代UI树便利和渲染是没有分开的，遍历UI树的时候就渲染.3dx版本为了分离了ui树的遍历和渲染，先遍历生成渲染命令发到渲染队列，之后遍历渲染命令队列开始渲染.这样做的好处是渲染命令可以重用，单独的渲染可以做优化例如自动批绘制.本篇首先介绍cocos2D-X 3.x版本的渲染结构，之后会深入opengl es. mainLoopvoid DisplayLinkDirector::mainLoop() { if (_purgeDirectorInNextLoop) { //只有一种情况会调用到这里来，就是导演类调用end函数 _purgeDirectorInNextLoop = false; //清除导演类 purgeDirector(); } else if (! _invalid) { //绘制 drawScene(); //清除内存 PoolManager::getInstance()-&gt;getCurrentPool()-&gt;clear(); } } 分析的起点是mainLoop函数，这是在主线程里面会调用的循环，其中drawScene函数进行绘制。那么就进一步来看drawScene函数。mainLoop实在opengl的ondrawframe调用过来的即平台每帧渲染会调用. drawScenevoid Director::drawScene() { //计算间隔时间 calculateDeltaTime(); //如果间隔时间过小会被忽略 if(_deltaTime &lt; FLT_EPSILON){ return;} //空函数，也许之后会有作用 if (_openGLView) { _openGLView-&gt;pollInputEvents(); } //非暂停状态 if (! _paused) { //scheduler更新 会使actionmanager更新和相关的schedule更新 引擎物理模拟都是在绘制之前做的 _scheduler-&gt;update(_deltaTime); _eventDispatcher-&gt;dispatchEvent(_eventAfterUpdate); } glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); //切换下一场景，必须放在逻辑后绘制前，否则会出bug if (_nextScene) { setNextScene(); } kmGLPushMatrix(); //创建单位矩阵 kmMat4 identity; kmMat4Identity(&amp;identity); //绘制场景 if (_runningScene) { //递归的遍历scene中的每个node的visit生成渲染命令放入渲染队列 _runningScene-&gt;visit(_renderer, identity, false); _eventDispatcher-&gt;dispatchEvent(_eventAfterVisit); } //绘制观察节点，如果你需要在场景中设立观察节点，请调用摄像机的setNotificationNode函数 if (_notificationNode) { _notificationNode-&gt;visit(_renderer, identity, false);//这是一个常驻节点 } //绘制屏幕左下角的状态 if (_displayStats) { showStats(); } //渲染 _renderer-&gt;render(); //渲染后 _eventDispatcher-&gt;dispatchEvent(_eventAfterDraw); kmGLPopMatrix(); _totalFrames++; if (_openGLView) { _openGLView-&gt;swapBuffers(); //交换缓冲区 } //计算绘制时间 if (_displayStats) { calculateMPF(); } } 其中和绘制相关的是visit的调用和render的调用，其中visit函数会调用节点的draw函数，在3.x之前的版本中draw函数就会直接调用绘制代码，3.x版本是在draw函数中生成将绘制命令放入到renderer队列中，然后renderer函数去进行真正的绘制，首先来看sprite的draw函数. 渲染命令void Sprite::draw(Renderer *renderer, const kmMat4 &amp;transform, bool transformUpdated) { //检查是否超出边界，自动裁剪 _insideBounds = transformUpdated ? renderer-&gt;checkVisibility(transform, _contentSize) : _insideBounds; if(_insideBounds) { //初始化 _quadCommand.init(_globalZOrder, _texture-&gt;getName(), _shaderProgram, _blendFunc, &amp;_quad, 1, transform); renderer-&gt;addCommand(&amp;_quadCommand); //物理引擎相关绘制边界 if CC_SPRITE_DEBUG_DRAW _customDebugDrawCommand.init(_globalZOrder); //自定义函数 _customDebugDrawCommand.func = CC_CALLBACK_0(Sprite::drawDebugData, this); renderer-&gt;addCommand(&amp;_customDebugDrawCommand); endif } } 这里面用了两种不同的绘制命令quadCommand初始化后就可以加入到绘制命令中，customDebugDrawCommand传入了一个回调函数，具体的命令种类会在后面介绍。其中自定义的customDebugDrawCommand命令在初始化的时候只传入了全局z轴坐标，因为它的绘制函数全部都在传入的回调函数里面，_quadCommand则需要传入全局z轴坐标，贴图名称，shader，混合，坐标点集合，坐标点集个数，变换。 Rendervoid Renderer::render() { _isRendering = true; if (_glViewAssigned) { //清除 _drawnBatches = _drawnVertices = 0; //排序 for (auto &amp;renderqueue : _renderGroups) { renderqueue.sort(); } //绘制 visitRenderQueue(_renderGroups[0]); flush(); } clean(); _isRendering = false; } Render类中的render函数进行真正的绘制，首先排序，再进行绘制，从列表中的第一个组开始绘制。在visitRenderQueue函数中可以看到五种不同类型的绘制命令类型，分别对应五个类，这五个类都继承自RenderCommand。 绘制命令 QUAD_COMMAND： QuadCommand类绘制精灵等。所有绘制图片的命令都会调用到这里，处理这个类型命令的代码就是绘制贴图的openGL代码， CUSTOM_COMMAND： 自定义绘制，自己定义绘制函数，在调用绘制时只需调用已经传进来的回调函数就可以，裁剪节点，绘制图形节点都采用这个绘制，把绘制函数定义在自己的类里。这种类型的绘制命令不会在处理命令的时候调用任何一句openGL代码，而是调用你写好并设置给func的绘制函数，并自己实现一个自定义的绘制。 BATCH_COMMAND： 批处理绘制，批处理精灵和粒子,其实它类似于自定义绘制，也不会再render函数中出现任何一句openGL函数，它调用一个固定的函数。 GROUP_COMMAND： 绘制组，一个节点包括两个以上绘制命令的时候，把这个绘制命令存储到另外一个renderGroups中的元素中，并把这个元素的指针作为一个节点存储到renderGroups[0]中。 render流程void Renderer::addCommand(RenderCommand* command) { //获得栈顶的索引 int renderQueue =_commandGroupStack.top(); //调用真正的addCommand addCommand(command, renderQueue); } void Renderer::addCommand(RenderCommand* command, int renderQueue) { //将命令加入到数组中 _renderGroups[renderQueue].push_back(command); } addCommand它是获得需要把命令加入到renderGroups位置中的索引，这个索引是从commandGroupStack获得的，commandGroupStack是个栈，当我们创建一个GROUP_COMMAND时，需要调用pushGroup函数，它是把当前这个命令在_renderGroups的索引位置压到栈顶，当addCommand时，调用top，获得这个位置 groupCommand.init(globalZOrder); renderer-&gt;addCommand(&amp;_groupCommand); renderer-&gt;pushGroup(_groupCommand.getRenderQueueID()); GROUP_COMMAND一般用于绘制的节点有一个以上的绘制命 令，把这些命令组织在一起，无需排定它们之间的顺序，他们作为一个整体被调用，所以一定要记住，栈是push，pop对应的，关于这个节点的所有的绘制命令被添加完成后，请调用pop，将这个值从栈顶弹出，否则后面的命令也会被添加到这里。 为什么调用的起始只需调用为什么只是0，其他的呢？ visitRenderQueue(_renderGroups[0]); 它们会在处理GROUP_COMMAND被调用 else if(RenderCommand::Type::GROUP_COMMAND == commandType) { flush(); int renderQueueID = ((GroupCommand*) command)-&gt;getRenderQueueID(); visitRenderQueue(_renderGroups[renderQueueID]); }]]></content>
      <categories>
        <category>cocos2dx</category>
      </categories>
      <tags>
        <tag>cocos2dx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tolua原理]]></title>
    <url>%2F2018%2F12%2F17%2Ftolua%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[tolua++如何将c++对象导入到lua里？lua如何能够访问c++对象成员？创建一个 userdata ，存放 C/C++ 对象指针，然后给 userdata 添加元表，用index 和newindex 元方法映射 C/C++ 中的对象方法。 c++层新建一个元表作为类型（通过tolua_usertype）放在注册表中（_R[mt] = name），并且设置这些类型的继承关系(通过_R.tolua_super). 创建一个类表(newtable)，并且设置_R中的原型表为元表（通过tolua_usertype），这个类表是放在全局表中的. 在注册类型的时候metatable里新建了.get和.set表。 ​ 成员变量：在.set和.get表里存储以变量名为键一读取设置c函数为值的键值对。 ​ 变量的读取赋值会在在metatable的index和newindex里，以变量名为键，从.get和.set表里取得读取设置函数并调用。 ​ 成员函数：只需要以函数名为键，函数为值存储在metatable里。 因为c++类型已经在注册表里，所以可以直接访问。 ​ lua里调用c++创建一个对象之后，c++需要返回这个对象： ​ 新建userdata,将c++指针放入userdata;以对象地址为key，userdata为值放入tolua_ubox表里；设置此类型对象的元表为userdata的元表。 经过上面4个步骤，就可以在lua里面调用类表。 传入c++对象的tolua++函数是tolua_pushusertype。一般情况下，第一次使用这个函数将一个c++对象push到lua堆栈上时，才会新建userdata。tolua++会以c++对象地址为键，userdata为值，将键值对存储在tolua_ubox表里。下次推入同样的c++对象时，从这个表里取出userdata推入堆栈即可。 tolua++如何处理类型的继承父类的metatable,是子类metatable的metatable。这样调用父类方法时，就会去父类的metatable里查找了。 tolua++还维护了一个tolua_super表，这个表以c++类型的metatable为键，以一个表格为值。这个值表格以类型名称为键，以true为值，记录了metatable对应c++类型的父类有哪些。这个表格可以用来帮助判断对象是否是某一个类型。 tolua++如何管理对象的生命周期一般情况下，当lua里对c++对象的引用变量可以被垃圾回收时，tolua++只是简单的释放userdata占用的4字节指针地址内存。但是也可以通过绑定或者代码指定的方式，让tolua++真正释放对象所占内存。 绑定的方式，是指在将c++类型构造函数使用tolua++导出到lua里时，tolua++会自动生成new_local方法。如果在lua代码里，用这个方法新建对象时，tolua++会调用tolua_register_gc方法，指明回收对象时回收对象内存。 在c++代码里，使用tolua_pushusertype_and_takeownership；在lua代码里，使用tolua.takeownership，都可以达到同样的目的。 对于这些指定由tolua++回收内存的对象，如果其类型的析构函数也通过tolua++导出了，则在回收内存时，会通过delete运算符，调用对象的析构函数。否则只会使用free方法回收。 tolua_register_gc方法，做的事情，是以对象指针为键，以对象metatable为值，将键值对存储在tolua_gc表里。在对象类型的metatable表的__gc方法里，tolua++会检查tolua_gc表是否包含以这个地址为键的表项。包含的话才会进行上述的内存回收工作。 实现有的时候，在lua里取得一个c++对象后，我们想赋给它一些只在lua环境下有意义的属性。或者，我们想在lua里扩展一个c++类。tolua++也提供了实现这种需求的机制。 tolua++在LUA_REGISTRY里维护了一张tolua_peers表。这张表以表示c++对象的userdata为键，以一张表格t为值。t里面就记录了这个对象在lua里扩展的属性。 原理C++在进行函数调用的时候是this指针+函数地址, Lua提供用户自定义的userdata. 一般lua中持有c++对象是使用userdata来实现的(userdata 类型用来将任意 C 数据保存在 Lua 变量中. 这个类型相当于一块原生的内存, 除了赋值和相同性判断, Lua 没有为之预定义任何操作.通过使用 metatable （元表）, 可以为 userdata 自定义一组操作. metatable 中还可以定义一个函数gc让 userdata 作垃圾收集时调用它。 ​ 因此，metatable可以用来模拟C++里面的函数，通过替换它来实现函数，类成员的查找。Userdata可以很方便的获取到转换成C++里面this指针。通过this指针+类的函数地址即可调用C++里面的类成员函数。 过程tolua_open()创建很多用于管理的内部变量， 如记录所有基类； tolua_usertype() 创建两个表分别问type和 const type类型， const type 继承自 type; tolua_cclass()注册类设置元表建立父子类关系； tolua_beginmodule（）注册一个模块 tolua_function()函数绑定到lua表中 tolua_beginmodule（）结束模块注册。 tolua_open是入口点，它创建很多用于管理的内部变量，以下用_G指代全局表，_R指定registry table：1、_R.TOLUA_VALUE_ROOT={}， 这个表是cocos2dx自己加的，它把所有传入lua的cppobj/userdata都塞到这个表里，而且这还不是一个弱表，也就意味着cocos2dx创建的cpp obj，永远都不会被gc！只有在c++层面被delete时，才会去这个表里删除自己。因此，每一个cocos2dx cpp obj，是不可能依赖lua gc来释放的，必须纯手动管理（retain/release）。当然，根据cocos2dx自身的设计，每个obj在new出来refcount为1，并且会添加autorelease pool里去，因此只要它不在场景树上，下一帧就会被自动删除掉。通常情况下，lua代码是不会干涉其生命期的。但是有些时候我们会把某些节点从场景树上摘下，过一段时间又挂上去，这时就必须先调一下它的retain，如果之后忘记调release，那么它就永远不会销毁了。 2、_R.tolua_peers={}，这是个弱表，用来缓存所有cppobj的ptr-&gt;peer table，所谓peer table，就是给每个cpp obj userdata关联的一个lua table，用来提供lua层面的额外的kv存储。tolua++把每个userdata的peer table设成该userdata的env，目的当然是为了方便找到它。因为在lua实现里，userdata的env是没有内定用途的，于是tolua++就拿来存peer table了。 3、_R.tolua_ubox={}，也是个弱表，用来缓存所有cppobj的ptr-&gt;userdata映射，userdata里面存放的值其实就是ptr。这个表的用途是记录所有已经push到lua里的cppobj，每个cppobj第一次进入lua时，会去做创建userdata、关联metatable、设置peertable(env)等等一大堆操作，然后把ptr-&gt;userdata的映射关系记到这个表里，下次再被返回进lua时，就从这表里去查找，查到的话就直接拿已创建好的userdata用了。但是有一种特殊情况，就是第二次push时的类型是上一次的子类，也就是一个“特化类型”，那么需要改设metatable，以使子类的新函数能被访问到。 4、_R.tolua_super={}，用来记录每个类型的所有基类，key是子类的mt，value则是个map，其中每个kv都是一个pair&lt;基类名,1&gt;。通过这个表可以快速知道两个类之间有无继承关系。 5、_R.tolua_gc={} 6、_R.tolua_gc_event = closure{ func:class_gc_event, upvalue:上述两个表格 }， 这是挂在每个类对应的metatable上的__gc方法。 7、_G.tolua={}，里面存放tolua自己的一些工具函数 类的注册。1、对每个用户类，首先要用tolua_usertype声明这是个用户类型： ​ tolua_usertype(tolua_S, “WebSocket”) 它里面的做事情很简单，就是分别为type和const type“两个类”建表（这个表也就是其实例userdata的元表），然后设置type继承const type，从数据的角度来看也就是： //先用tolua_newmetatable分别创建创建两个元表，其内又调用tolua_classevents挂上各种属性 _R[“WebSocket”]={ __index = cfunc:class_index_event, __newindex = cfunc:class_newindex_event, __gc=_R.tolua_gc_event //上面之&lt;一.6&gt; //其它各种add/sub/lt/eq等方法…… } _R[“const WebSocket”]= ……同上 //mapsuper(L,type,ctype) 设置两者的继承关系 _R.tolua_super[_R[“WebSocket”]] ={ “const WebSocket” = 1,} //上面之&lt;一.4&gt; //这个过程会递归执行，即把基类的所有基类都添到子类里 for k,v in pairs(_R.tolua_super[_R[“const WebSocket”]]) do _R.tolua_super[_R[“WebSocket”]][k] = v end //在这一步里，mapsuper只是设置type-&gt;const type，但是在后续步骤里会添加大量type-&gt;base type，因此递归下来，每个type的_R.tolua_super[type]表还是有很多内容的。 2、然后用tolua_cclass来注册类。 ​ tolua_cclass主要做两件事，一是把基类和父类（以及各const变种）之间的关系建立起来，二是注册类的析构函数（构造函数由普通的create静态函数替代了）。 关于继承关系，总共四对： mapinheritance(L,name,base); mapinheritance(L,cname,name); mapsuper(L,cname,cbase); mapsuper(L,name,base); 其中c指const。除了上面提到的mapsuper，又来了个mapinheritance， 再次对比说明下： mapsuper是：在_R.tolua_super记录每个类(k)有哪些父类(v)，所有父类以v[类名]=1的形式记录着。 mapinheritance是：把父类元表表设成子类元表表的元表，同时给基类表上挂一个用以记录该类objptr-&gt;userdata映射的弱表，大致是： setmetatable( _R.type, _R.base_type )， _R.type.tolua_ubox = _R.base_type.tolua_ubox or weak({}) 其中第二句与前述之&lt;一.3&gt;有点相似，只是那是放在_R上的一个总表，而这里是为每个类单独建表，但子类与基类是共用的，也就是每次调用tolua_cclass注册一个类，就有“3个类”的表中的tolua_ubox字段指向了同一个表，这3个类从上到下是：base type -&gt; type -&gt; const type，至于const base type，那是在之前注册基类时处理的了。 不过这里还有个另外的问题！注意和第2条里的对比： mapinheritance(L,cname,name) //tolua_cclass里 mapsuper(L,type,ctype) //tolua_usertype里 到底type和const type谁是“基类”呢？这主要看不同场合里“基类”这个概念是用于解决什么问题了： 对mapsuper而言：在c++里一个声明为const的参数，实际是对函数本身的约束而不是对实参的约束：它只是强调函数内部不会去修改这个参数，至于传进来的实参本身是不是const的根本不重要，因为反正函数已经承诺不会去修改它了。所以要把一个类型为type的obj传给某个带有const type参数的函数，是没有问题的，但反过来，一个const type对象要传给接受type参数的函数是不行的，因为不知道它到底会不会修改（没有承诺不修改就意味着会修改）。再加上tolua++在生成胶水代码时，对每个参数都要做类型匹配检测（也就是在生成代码中大量的lua_isusertype调用），一个usertype变量是否合格，就是检查它所在位置的参数类型，是否是它可以“扮演”的角色，这些角色一是它的所有父类，二就是它以及所有父类的const变种了，而这些可以扮演的类型，恰好就是mapsuper所建立的_R.tolua_super体系中记录的内容了。 对mapinheritance而言：它将基类表设成子类表的元表，这是为了在子类表里可以找到基类的函数（在class_index_event函数里，有一个while循环，通过这里建立的链条不断向上级查找）。就这个目的而言，type和const type谁做基类是一样的。但是，type还有真正的基类base，按照base-&gt;type-&gt;const type的继承顺序是恰好满足的： classA -&gt; const classA ​ -&gt; classB -&gt; const classB ​ -&gt; classC -&gt; const classC ​ -&gt; classD -&gt; const classD 也就是说const类型在当前层次的链上是一个叶，下一层次不是从它继承，而是与它并级。 而如果按照base-&gt;const type-&gt;type-&gt;const subtype-&gt;sub type，那么问题就麻烦了，因为在注册函数时，所有函数都是挂在不带const的类表上的，如CCNode的函数都在_R[“CCNode”]里，这也符合脚本里创建类实例时的习惯：直接以“纯粹的”（不带const的）类名来操作，比如CCNode:create，而不会写作const_CCNode:create()。那么在后者的继承链上，每一个const type实际成了断点，没有得到这个type自身的函数！ 3.tolua_beginmodule（） tolua_endmodule() tolua_function() tolua_beginmodule(m_pState, “CTest”);是只注册一个模块，比如，我们管CTest叫做”CTest”，保持和C++的名称一样。这样在Lua的对象库中就会多了一个CTest的对象描述，等同于string,number等等基本类型，同tolua_beginmodule()和tolua_endmodule()对象必须成对出现，如果出现不成对的，你注册的C++类型将会失败。 tolua_function(m_pState, “SetData”, tolua_SetData_CTest);指的是将Lua里面CTest对象的”SetData”绑定到你的tolua_SetData_CTest()函数中去。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua闭包]]></title>
    <url>%2F2018%2F12%2F15%2Flua%E9%97%AD%E5%8C%85%2F</url>
    <content type="text"><![CDATA[lua中有两种闭包, c闭包和lua闭包两种闭包的公共部分: #define ClosureHeader CommonHeader;\ lu_byte isC; \ 是否c闭包 lua_byte nupvalues; \ upvalue的个数 GCObject* gclist; \ struct Table env 闭包的环境 C闭包的结构 struct CClosure{ ClosureHeader; lua_CFunction f; TValue upvalue[1]; } 结构比较简单, f是一个满足 int lua_func(lua_State*) 类型的c函数 upvalue是创建C闭包时压入的upvalue, 类型是TValue, 可以得知, upvalue可以是任意的lua类型 Lua闭包结构 struct LClosure{ ClosureHeader; strcut Proto* p; UpVal* upvals[1]; } Proto的结构比较复杂, 这里先不做分析 统一的闭包结构, 一个联合体, 说明一个闭包要么是C闭包, 要么是lua闭包, 这个是用isC表识出来的. union Closure{ CClosure c; LClosure l; } 闭包 == {功能抽象, upvalue, env} 向lua中注册c函数的过程是通过lua_pushcclosure(L, f, n)函数实现的流程: 创建一个 sizeof(CClosure) + (n - 1) * sizeof(TValue)大小的内存, 这段内存是 CClosure + TValue[n],, isC= 1 标示其是一个C闭包. c-&gt;f = f绑定c函数. ——— 闭包.功能抽象 = f env = 当前闭包的env. ———- 闭包.env = env 把栈上的n个元素赋值到c-&gt;upvalue[]数组中, 顺序是越先入栈的值放在upvalue数组的越开始位置, c-&gt;nupvalues指定改闭包upvalue的个数. ———- 闭包.upvalue = upvalue 弹出栈上n个元素, 并压入新建的Closure到栈顶. 整个流程是: 分配内存, 填写属性, 链入gc监控, 绑定c函数, 绑定upvalue, 绑定env一个C闭包就ok了 C闭包被调用的过程lua 闭包调用信息结构: struct CallInfo{ StkId base; ----闭包调用的栈基 StkId func; ----要调用的闭包在栈上的位置 StkId top; ----闭包的栈使用限制 const Instruction *savedpc; ----如果在本闭包中再次调用别的闭包, 那么该值就保存下一条指令以便在返回时继续执行 int nresults; ----闭包要返回的值个数 int tailcalls;----尾递归用, 暂时不管 } 这个结构是比较简单的, 它的作用就是维护一个函数调用的有关信息, 其实和c函数调用的栈帧是一样的, 重要的信息base –&gt; ebp, func –&gt; 要调用的函数的栈index, savedpc –&gt; eip, top, nresults和tailcalls没有明显的对应. 在lua初始化的时候, 分配了一个CallInfo数组, 并用L-&gt;base_ci指向该数组第一个元素, 用L-&gt;end_ci指向该数组最后一个指针, 用L-&gt;size_ci记录数组当前的大小, L-&gt;ci记录的是当前被调用的闭包的调用信息. 下面讲解一个c闭包的调用的过程:情景: c 函数 int lua_test(lua_State* L){ int a = lua_tonumber(L, 1); int b = lua_tonumber(L, 2); a = a + b; lua_pushnumber(L, a); } 已经注册到了lua 中, 形成了一个C闭包, 起名为”test”, 下面去调用它luaL_dostring(L, &quot;c = test(3, 4)&quot;) 调用过程堆栈变化情况如下： 1.初始栈 2.压入了函数和参数的堆栈 lua_getglobal(L, “test”) lua_pushnumber(L, 3) lua_pushnumber(L, 4) 3.调用lua_test开始时的堆栈 lua_call(L,3, 4) 4.调用结束的堆栈 取出结果的栈 lua_setglobal(L, “c”) lua_call函数的过程 lua具有很强一致性, 不管是dostring, 还是dofile, 都会形成一个闭包, 也就是说, 闭包是lua中用来组织结构的基本构件, 这个特点使得lua中的结构具有一致性, 是一种简明而强大的概念. 根据1， a = test(3, 4)其实是被组织成为一个闭包放在lua栈顶[方便期间, 给这个lua闭包起名为bb], 也就说dostring真正调用的是bb闭包, 然后bb闭包执行时才调用的是test[保存当前信息到当前函数的CallInfo中] 在调用test的时刻, L-&gt;ci记载着bb闭包的调用信息, 所以, 先把下一个要执行的指令放在L-&gt;ci-&gt;savedpc中, 以供从test返回后继续执行. 取栈上的test C闭包 cl, 用 cl-&gt;isC == 1断定它的确是一个C闭包[进入一个新的CallInfo, 布置堆栈] 从L中新分配一个CallInfo ci来记录test的调用信息, 并把它的值设置到L-&gt;ci, 这表明一个新的函数调用开始了, 这里还要指定test在栈中的位置, L-&gt;base = ci-&gt;base = ci-&gt;func+1, 注意, 这几个赋值很重要, 导致的堆栈状态由图2转化到图3, 从图中可以看出, L-&gt;base指向了第一个参数, ci-&gt;base也指向了第一个参数, 所以在test中, 我们调用lua_gettop函数返回的值就是2， 因为在调用它的时候, 它的栈帧上只有2个元素, 实现了lua向c语言中传参数.[调用实际的函数] 安排好堆栈, 下面就是根据L-&gt;ci-&gt;func指向的栈上的闭包(及test的C闭包), 找到对应的cl-&gt;c-&gt;f, 并调用, 就进入了c函数lua_test [获取返回值调整堆栈, 返回原来的CallInfo] 根据lua_test的返回值, 把test闭包和参数弹出栈, 并把返回值压入并调整L-&gt;top 恢复 L-&gt;base, L-&gt;ci 和 L-&gt;savedpc, 继续执行. 调用一个新的闭包时： 保存当前信息到当前函数的CallInfo中 （CallInfo函数调用的状态信息） 进入一个新的CallInfo, 布置堆栈 调用实际的函数 获取返回值调整堆栈, 返回原来的CallInfo]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua模块注册]]></title>
    <url>%2F2018%2F12%2F15%2Flua%E6%A8%A1%E5%9D%97%E6%B3%A8%E5%86%8C%2F</url>
    <content type="text"><![CDATA[Lua自带的模块并不多,好处就是Lua足够的小,毕竟它的设计目标是定位成一个嵌入式的轻量级语言的. 相关的函数index2adrstatic TValue *index2adr (lua_State *L, int idx) { if (idx &gt; 0) { TValue *o = L-&gt;base + (idx - 1); api_check(L, idx &lt;= L-&gt;ci-&gt;top - L-&gt;base); if (o &gt;= L-&gt;top) return cast(TValue *, luaO_nilobject); else return o; } else if (idx &gt; LUA_REGISTRYINDEX) { api_check(L, idx != 0 &amp;&amp; -idx &lt;= L-&gt;top - L-&gt;base); return L-&gt;top + idx; } else switch (idx) { /* pseudo-indices */ case LUA_REGISTRYINDEX: return registry(L); case LUA_ENVIRONINDEX: { Closure *func = curr_func(L); sethvalue(L, &amp;L-&gt;env, func-&gt;c.env); return &amp;L-&gt;env; } case LUA_GLOBALSINDEX: return gt(L); default: { Closure *func = curr_func(L); idx = LUA_GLOBALSINDEX - idx; return (idx &lt;= func-&gt;c.nupvalues) ? &amp;func-&gt;c.upvalue[idx-1] : cast(TValue *, luaO_nilobject); } } } 一个Lua函数栈由两个指针base和top来指定,base指向函数栈底,top则指向栈顶.回到index2addr函数中,几种情况: 如果索引为正,则从函数栈底为起始位置向上查找数据 如果索引为负,则从函数栈顶为起始位置向下查找数据 紧跟着是几种特殊的索引值,都定义了非常大的数据,由于Lua栈限定了函数的栈尺寸,所以不会有那么大的索引,大可放心使用. 索引值为LUA_REGISTRYINDEX时,则返回的是全局数据global_state的l_registry表;如果索引值为LUA_GLOBALSINDEX,则返回该Lua_State的l_gt表. lua模块注册Lua内部所有模块的注册都在linit.c的函数luaL_openlibs中提供.可以看到的是,它依次访问一个数组,数组中定义了每个模块的模块名及相应的模块注册函数,依次调用函数就完成了模块的注册. static const luaL_Reg lualibs[] = { {&quot;&quot;, luaopen_base}, {LUA_LOADLIBNAME, luaopen_package}, {LUA_TABLIBNAME, luaopen_table}, {LUA_IOLIBNAME, luaopen_io}, {LUA_OSLIBNAME, luaopen_os}, {LUA_STRLIBNAME, luaopen_string}, {LUA_MATHLIBNAME, luaopen_math}, {LUA_DBLIBNAME, luaopen_debug}, {NULL, NULL} }; LUALIB_API void luaL_openlibs (lua_State *L) { const luaL_Reg *lib = lualibs; for (; lib-&gt;func; lib++) { lua_pushcfunction(L, lib-&gt;func); lua_pushstring(L, lib-&gt;name); lua_call(L, 1, 0); } } 我没有详细的查看每个模块的注册函数,不过还是以最简单的例子来讲解,就是最常用的print函数. 由于这个函数没有前缀,因此的它所在的模块是””,也就是一个空字符串,因此它是在base模块中注册的,调用的注册函数是luaopen_base. 紧跟着继续看luaopen_base内部调用的第一个函数base_open: static void base_open (lua_State *L) { /* set global _G */ lua_pushvalue(L, LUA_GLOBALSINDEX); lua_setglobal(L, &quot;_G&quot;); /* open lib into global table */ luaL_register(L, &quot;_G&quot;, base_funcs); // .... } 首先来看最前面的两句: /* set global _G */ lua_pushvalue(L, LUA_GLOBALSINDEX); lua_setglobal(L, &quot;_G&quot;); 这两句首先将LUA_GLOBALSINDEX对应的值压入栈中,其次调用”lua_setglobal(L, “_G”);”,这句代码的意思是在Lua_state的l_gt表中,当查找”_G”时,查找到的是索引值为LUA_GLOBALSINDEX的表.如果觉得有点绕,可以简单这个理解,在Lua中的G表,也就是全局表,满足这个等式”_G = _G[“_G”]“,也就是这个叫”_G”的表,内部有一个key为”_G”的表是指向自己的.怀疑这个结论的,可以在Lua命令行中执行print(_G)和print(_G[“_G”])看看输出结果是不是一致的. Lua中要这么处理的理由是:为了让G表和处理其它表使用同样的机制.查找一个变量时,最终会一直查到G表中,这是很自然的事情;所以为了也能按照这个机制顺利的查找到自己,于是在G表中有一个同名成员指向自己. 好了,前面两句的作用已经分析完毕.其结果有两个: _G = _G[“_G”] _G表的值压入函数栈中方便了下面的调用. 继续看下面的语句:luaL_register(L, “_G”, base_funcs);它最终会将base_funcs中的函数注册到G表中,但是里面还有些细节需要看看的. LUALIB_API void luaI_openlib (lua_State *L, const char *libname, const luaL_Reg *l, int nup) { if (libname) { int size = libsize(l); /* check whether lib already exists */ luaL_findtable(L, LUA_REGISTRYINDEX, &quot;_LOADED&quot;, 1); lua_getfield(L, -1, libname); /* get _LOADED[libname] */ if (!lua_istable(L, -1)) { /* not found? */ lua_pop(L, 1); /* remove previous result */ /* try global variable (and create one if it does not exist) */ if (luaL_findtable(L, LUA_GLOBALSINDEX, libname, size) != NULL) luaL_error(L, &quot;name conflict for module &quot; LUA_QS, libname); lua_pushvalue(L, -1); lua_setfield(L, -3, libname); /* _LOADED[libname] = new table */ } lua_remove(L, -2); /* remove _LOADED table */ lua_insert(L, -(nup+1)); /* move library table to below upvalues */ } // ... } 注册这些函数之前,首先会到l_registry表的成员_LOADED表中查找该库,如果不存在则再在G表中查找这个库,不存在则创建一个表.因此,不管是lua中内部的库或者是外部使用require引用的库,都会走这个流程并最终在G表和l_registry[“_LOADED”]中存放该库的表.最后,再遍历传进来的函数指针数组,完成库函数的注册. 比如,注册os.print时,首先将print函数绑定在一个函数指针上,再去l_registry[“_LOADED”]和G表中查询该名为”os”的库是否存在,不存在则创建一个表,即:G[“os”] = {} 紧跟着注册print函数,即: G[“os”][“print”] = 待注册的函数指针.这样,在调用lua代码os.print(1)时,首先根据”os”到G表中查找对应的表,再在这个表中查找”print”成员得到函数指针,最后完成函数的调用. 注册外部模块luaL_newlibtable 它仅仅是创建了一个table,然后把数组里的函数放进去而已 luaL_setfuncs它把数组l中的所有函数注册入栈顶的table，并给所有函数绑上nup个upvalue define luaL_newlibtable(L, l) lua_createtble(L, 0, sizeof(l)/sizeof((l)[0]) - 1) define luaL_newlib(L, l) (luaL_newlibtable(L,l), luaL_setfuncs(L,l,0) LUALIB_API void luaL_setfuncs(lua_State *L, const luaL_Reg *l, int nup){ luaL_checkversion(L); luaL_checkstack(L, nup, &quot;too_many_upvalue&quot;); for(; l-&gt;name != NULL; i++){/* fill the table with given functions*/ int i; for(i = 0; i &lt; nup; i++)/copy upvalues to the top/ lua_pushvalue(L, -nup); lua_pushclosure(L, l-&gt;func, nup);/closure with those upvalues/ lua_setfield(L, -(nup + 2), l-&gt;name); } lua_pop(L, nup);/remove upvalues/ }]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua协程]]></title>
    <url>%2F2018%2F12%2F15%2Flua%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[协程是个很好的东西，它能做的事情与线程相似，区别在于：协程是使用者可控的，有API给使用者来暂停和继续执行，而线程由操作系统内核控制；另外，协程也更加轻量级。这样，在遇到某些可能阻塞的操作时，可以使用暂停协程让出CPU；而当条件满足时，可以继续执行这个协程。目前在网络服务器领域，使用Lua协程最好的范例就是ngx_lua了 来看看Lua协程内部是如何实现的。 本质上，每个Lua协程其实也是对应一个LuaState指针，所以其实它内部也是一个完整的Lua虚拟机—有完整的Lua堆栈结构，函数调用栈等等等等，绝大部分之前对Lua虚拟机的分析都可以直接套用到Lua协程中。于是，由Lua虚拟机管理着这些隶属于它的协程，当需要暂停当前运行协程的时候，就保存它的运行环境，切换到别的协程继续执行。很简单的实现。 来看看相关的API。 lua_newthread 创建一个Lua协程，最终会调用的API是luaE_newthread，Lua协程在Lua中也是一个独立的Lua类型数据，它的类型是LUA_TTHREAD，创建完毕之后会照例初始化Lua的栈等结构，有一点需要注意的是，调用preinit_state初始化Lua协程的时候，传入的global表指针是来自于Lua虚拟机，换句话说，任何在Lua协程修改的全局变量，也会影响到其他的Lua协程包括Lua虚拟机本身。 加载一个Lua文件并且执行 对于一般的Lua虚拟机，大可以直接调用luaL_dofile即可，它其实是一个宏： #define luaL_dofile(L, fn) \ (luaL_loadfile(L, fn) || lua_pcall(L, 0, LUA_MULTRET, 0)) 展开来也就是当调用luaL_loadfile函数完成对该Lua文件的解析，并且没有错误时，调用lua_pcall函数执行这个Lua脚本。 但是对于Lua协程而言，却不能这么做，需要调用luaL_loadfile然后再调用lua_resume函数。所以两者的区别在于lua_pcall函数和lua_resume函数。来看看lua_resume函数的实现。这个函数做的几件事情：首先查看当前Lua协程的状态对不对，然后修改计数器： L-&gt;baseCcalls = ++L-&gt;nCcalls; 其次调用status = luaD_rawrunprotected(L, resume, L-&gt;top – nargs);，可以看到这个保护Lua函数堆栈的调用luaD_rawrunprotected最终调用了函数resume: static void resume (lua_State *L, void *ud) { StkId firstArg = cast(StkId, ud); CallInfo *ci = L-&gt;ci; if (L-&gt;status == 0) { /* start coroutine? */ lua_assert(ci == L-&gt;base_ci &amp;&amp; firstArg &gt; L-&gt;base); if (luaD_precall(L, firstArg - 1, LUA_MULTRET) != PCRLUA) return; } else { /* resuming from previous yield */ lua_assert(L-&gt;status == LUA_YIELD); L-&gt;status = 0; if (!f_isLua(ci)) { /* `common&#39; yield? */ /* finish interrupted execution of `OP_CALL&#39; */ lua_assert(GET_OPCODE(*((ci-1)-&gt;savedpc - 1)) == OP_CALL || GET_OPCODE(*((ci-1)-&gt;savedpc - 1)) == OP_TAILCALL); if (luaD_poscall(L, firstArg)) /* complete it... */ L-&gt;top = L-&gt;ci-&gt;top; /* and correct top if not multiple results */ } else /* yielded inside a hook: just continue its execution */ L-&gt;base = L-&gt;ci-&gt;base; } luaV_execute(L, cast_int(L-&gt;ci - L-&gt;base_ci)); } 这个函数将执行Lua代码的流程划分成了几个阶段，如果调用 luaD_precall(L, firstArg - 1, LUA_MULTRET) != PCRLUA 那么说明这次调用返回的结果小于0，可以跟进luaD_precall函数看看什么情况下会出现这样的情况： n = (*curr_func(L)-&gt;c.f)(L); /* do the actual call */ lua_lock(L); if (n &lt; 0) /* yielding? */ return PCRYIELD; else { luaD_poscall(L, L-&gt;top - n); return PCRC; } 继续回到resume函数中，如果之前该Lua协程的状态是YIELD，那么说明之前被中断了，则调用luaD_poscall完成这个函数的调用。然后紧跟着调用luaV_execute继续Lua虚拟机的继续执行。 可以看到，resume函数做的事情其实有那么几件： 如果调用C函数时被YIELD了，则直接返回 如果之前被YIELD了，则调用luaD_poscall完成这个函数的执行，接着调用luaV_execute继续Lua虚拟机的执行。 因此，这个函数对于函数执行中可能出现的YIELD，有充分的准备和判断，因此它不像一般的pcall那样，一股脑的往下执行，而是会在出现YIELD的时候保存现场返回，在继续执行的时候恢复现场。3）同时，由于resume函数是由luaD_rawrunprotected进行保护调用的，即使执行出错，也不会造成整个程序的退出。 这就是Lua协程中，比一般的Lua操作过程做的更多的地方。 最后给出一个Lua协程的例子：co.lua print(&quot;before&quot;) test(&quot;123&quot;) print(&quot;after resume&quot;) co.c #include #include &quot;lua.h&quot; #include &quot;lualib.h&quot; #include &quot;lauxlib.h&quot; static int panic(lua_State *state) { printf(&quot;PANIC: unprotected error in call to Lua API (%s)\n&quot;, lua_tostring(state, -1)); return 0; } static int test(lua_State *state) { printf(&quot;in test\n&quot;); printf(&quot;yielding\n&quot;); return lua_yield(state, 0); } int main(int argc, char *argv[]) { char *name = NULL; name = &quot;co.lua&quot;; lua_State* L1 = NULL; L1 = lua_open(); lua_atpanic(L1, panic); luaL_openlibs( L1 ); lua_register(L1, &quot;test&quot;, test); lua_State* L = lua_newthread(L1); luaL_loadfile(L, name); lua_resume(L, 0); printf(&quot;sleeping\n&quot;); sleep(1); lua_resume(L, 0); printf(&quot;after resume test\n&quot;); return 0; } 你可以使用coroutine.create来创建协程,协程有三种状态：挂起，运行，停止。创建后是挂起状态，即不自动运行。status函数可以查看当前状态。协程真正强大的地方在于他可以通过yield函数将一段正在运行的代码挂起。 lua的resume-yield可以互相交换数据 co = coroutine.create(function (a, b) coroutine.yield(a+b, a-b) end) print(coroutine.resume(co, 3, 8))]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua表类型]]></title>
    <url>%2F2018%2F12%2F15%2Flua%E8%A1%A8%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Lua的表的定义:typedef struct Table { CommonHeader; lu_byte flags; lu_byte lsizenode; /* log2 of size of `node&#39; array */ struct Table *metatable; TValue *array; /* array part */ Node *node; Node *lastfree; /* any free position is before this position */ GCObject *gclist; int sizearray; /* size of `array&#39; array */ } Table; 这里将Table分为了两个部分:数组部分,array指针指向数组部分的首地址,sizearray是数组的尺寸,绝大部分(注意:不是全部)正整数为key的数据都存放在数组部分;node指针指向一个hash桶,对于不能存放在数组部分的数据,都存放在hash中.如下图所示: hash部分需要特别注意的一点是:在物理上,所有hash部分的数据,其实是存放一块连续的内存中的,即node指针指向的数组;但是从逻辑上来看,如果几块数据在同一个hash桶上,那么又是通过next指针串联起来的.以图中的示例来分析,node数组的第一个和第三个元素,在物理上是第一和第三个元素,但是在逻辑上,它们是通过next指针串联起来的. Table查找数据有了以上的了解,从Table中查找一个数据的伪代码就很显而易见了: 如果输入的Key是一个正整数,并且它的值 &gt; 0 &amp;&amp; &lt;= 数组大小 尝试在数组部分查找否则尝试在Hash部分进行查找: 计算出该Key的Hash值(ltable.c中的mainposition函数),根据此Hash值访问node数组得到Hash桶所在位置 遍历该Hash桶下的所有链表元素,直到找到该Key为止以上已经明白了Table的大致结构,来看看Table中如果新加入新的数据会怎么处理.这里有一些内容,要留到后面讲解到Lua虚拟机的时候才触及,这里先讲解一下,当新插入数据时,Table内的数组和Hash部分,做了哪些变化. 这部分中,核心的算法在ltable.c的rehash函数中,这个函数是计算当新添加数据时,数组和hash重新分配之后各自的尺寸是多少,伪代码如下: 首先分配一个位图nums,将其中的所有位置0,这个位图的意义在于:nums数组中第i个元素存放的是key在2^(i-1), 2^i之间的元素数量遍历lua Table中的数组部分,计算在数组部分中的元素数量,更新对应的nums数组元素数量.(numusearray函数)遍历lua Table中的Hash部分,因为其中也可能存放了正整数,也根据这里的正整数数量更新对应的nums数组元素数量.(numusehash函数)此时nums数组已经有了当前这个Table中所有正整数的分配统计,逐个遍历nums数组,如果当前已经有的根据新的数组大小和Hash大小重新分配table的大小(computesizes函数)这里要特别讲解的是computesizes函数,在前面的两个函数调用numusearray函数和numusehash函数之后,此时在nums位图中,已经存放了所有有关整数key的信息,即在[2^(i-1), 2^i]范围内,有多少数据.前面曾经提到过,并不是所有的正整数,都会存放在数组部分的,即使它曾经在,也有可能在之后被分配到hash部分,那么判断的依据是什么?到底怎样的数据,在重新分配之后会从数组部分挪到hash部分?来看computesizes函数的实现: static int computesizes (int nums[], int *narray) { int i; int twotoi; /* 2^i */ int a = 0; /* number of elements smaller than 2^i */ int na = 0; /* number of elements to go to array part */ int n = 0; /* optimal size for array part */ for (i = 0, twotoi = 1; twotoi/2 &lt; *narray; i++, twotoi *= 2) { if (nums[i] &gt; 0) { a += nums[i]; if (a &gt; twotoi/2) { /* more than half elements present? */ n = twotoi; /* optimal size (till now) */ na = a; /* all elements smaller than n will go to array part */ } } if (a == *narray) break; /* all elements already counted */ } *narray = n; lua_assert(*narray/2 &lt;= na &amp;&amp; na &lt;= *narray); return na; } 注意到这样的细节:这个函数在遍历nums位图数组的时候,会将当前数据数量存放在变量a中,如果a &gt; twotoi/2,也就是当前有一半以上的空间被利用上了,那么这部分数据会继续留在数组部分,否则就会在之后挪到hash部分了. 纯粹的使用数组或者hash表性能更高为了证实这里的判断,简单的写一段lua代码做为实验: function print_ipairs(t) print(&quot;in print_ipairs&quot;) for k, v in ipairs(t) do print(k) end end function print_pairs(t) print(&quot;in print_pairs&quot;) for k, v in pairs(t) do print(k) end end a = {} a={1,2,3,4,5,6,7,8,9,10} print_ipairs(a) a[2] = nil a[3] = nil a[4] = nil a[6] = nil a[&quot;k&quot;] = &quot;e&quot; print_ipairs(a) print_pairs(a) 输出为: in print_ipairs 1 2 3 4 5 6 7 8 9 10 in print_ipairs 1 in print_pairs 1 7 8 10 k 5 9 在这里,首先对表a赋值,有1-10共十个元素,通过调用函数print_ipairs可知,这些元素都是存放在数组部分的,这是因为ipairs取的是Table的数组部分元素.在这之后,人为的将其中2,3,4,6元素删除,造成原来数组不满一半元素被利用上的现象,然后再插入一个新key “k”,以让这个Table重新分配空间.再此之后,再次调用ipairs遍历a的数组部分,可以看到只有1被打印出来了,也就是说,在重新分配空间之后,除去已经被删除的2,3,4,6之外,只有1还在数组里面,剩下的5,7,8,9,10已经不在数组部分了.紧接着调用pairs遍历这个表,可以看出这些已经不在数组部分的值又被打印出来了,并且它们的顺序已经被打乱,不再按照数字大小顺序来排列了,它们在这次重新分配中被挪动到了hash部分. 这个实验既验证了我们前面的分析,同时也告诉我们,Table的重新分配,实际上代价是很大的,因此不建议在实际程序中,一个Table即有数组部分,也有Hash部分,纯粹一些,性能上会有提升.]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua通用数据类型]]></title>
    <url>%2F2018%2F12%2F15%2FLUA%E7%9A%84%E9%80%9A%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[TValue结构TValue这个结构体是Lua的通用结构体,,Lua中的所有的数据都可以使用这个结构体来表示.很容易想到,在面向对象中,这个结构体是一个基类,派生出来的都是其他的子类. TValue结构体内部有几个宏, 展开之后就是这样的: typedef struct lua_TValue { union { union GCObject { struct GCheader { GCObject *next; lu_byte tt; lu_byte marked; } gch; union TString ts; union Udata u; union Closure cl; struct Table h; struct Proto p; struct UpVal uv; struct lua_State th; /* thread */ } gc; void *p; lua_Number n; int b; } value; int tt; } TValue; 这个结构体定义,总体来说分为两个部分:tt存放的数据类型,而value域存放的是各种数据.而在其中,又划分为两个部分,可gc的数据类型使用union放在一起,剩下的就是不可gc的数据类型了:void*,lua_Number,int. gc uniongc union的定义,可以看到各种可gc的类型(Tstring,Udata..etc)和一个GCHeader放在 一起,也就是说,当这部分还是数据的时候,数据部分启用,否则就是gc部分了.这里的GCHeader包括了三个部分:next指针将可gc的数据串联成链表,tt表示数据类型,marked存放的gc处理时的颜色值.这是另一种方式的使用C语言实现的面向对象,对外部而言,TValue结构体可以看作是”基类”,真正进行处理时,再根据数据类型决定到底使用value union中的哪个数据部分.可以看到lua源代码中定义了很多宏就是这样操作Tvalue数据指针的,比如: #define hvalue(o) check_exp(ttistable(o), &amp;(o)-&gt;value.gc-&gt;h) 这个宏定义了如何从TValue指针得到Table结构体:首先判断数据类型是Table,然后将value的gc union中Table *h取出. 反之,要从一个具体的类型转换再赋值为相应的TValue,Lua源代码中也提供了相应的宏.因为TValue结构体的中的value域是一个union,所以其实随便强制转换为其中的哪一种类型都可以,不过看上去最舒服的写法还是直接转换为公共类型GCObject了,比如: #define setsvalue(L,obj,x) \ { TValue *i_o=(obj); \ i_o-&gt;value.gc=cast(GCObject *, (x)); i_o-&gt;tt=LUA_TSTRING; \ checkliveness(G(L),i_o); } GCObjectunion GCObject { GCheader gch; union TString ts; union Udata u; union Closure cl; struct Table h; struct Proto p; struct UpVal uv; struct lua_State th; /* thread */ }; 其中的GCheader展开是这样的: typedef struct GCheader { CommonHeader; } GCheader; 而随便抽在GCObject结构体中的数据类型结构体定义,都发现也包含了一个CommonHeader结构体,比如: typedef struct Table { CommonHeader; lu_byte flags; lu_byte lsizenode; /* log2 of size of `node&#39; array */ struct Table *metatable; TValue *array; /* array part */ Node *node; Node *lastfree; /* any free position is before this position */ GCObject *gclist; int sizearray; /* size of `array&#39; array */ } Table; 换言之,在GCObject中,无论是哪个数据结构体,都自己有一份CommonHeader.仔细观察,其实GCObject这个union的内存分布,最开始部分无论如何都是留给CommonHeader的.这样做,就保证了一个存放在TValue结构体中的数据,既可以使用CommonHeader关于GC的部分,也可以使用到自己本身的数据部分了.]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua栈]]></title>
    <url>%2F2018%2F12%2F15%2Flua%E6%A0%88%2F</url>
    <content type="text"><![CDATA[既然Lua虚拟机模拟的是CPU的运作,那么Lua栈模拟的就是内存的角色.在Lua内部,参数的传递是通过Lua栈,同时Lua与C等外部进行交互的时候也是使用的栈.,先关注的是Lua栈的分配,管理和相关的数据结构. lua虚拟机在初始化创建lua_State结构体时,会走到stack_init函数中,这个函数主要就是对Lua栈和CallInfo数组的初始化: static void stack_init (lua_State *L1, lua_State *L) { /* initialize CallInfo array */ L1-&gt;base_ci = luaM_newvector(L, BASIC_CI_SIZE, CallInfo); L1-&gt;ci = L1-&gt;base_ci; L1-&gt;size_ci = BASIC_CI_SIZE; L1-&gt;end_ci = L1-&gt;base_ci + L1-&gt;size_ci - 1; /* initialize stack array */ L1-&gt;stack = luaM_newvector(L, BASIC_STACK_SIZE + EXTRA_STACK, TValue); L1-&gt;stacksize = BASIC_STACK_SIZE + EXTRA_STACK; L1-&gt;top = L1-&gt;stack; L1-&gt;stack_last = L1-&gt;stack+(L1-&gt;stacksize - EXTRA_STACK)-1; /* initialize first ci */ L1-&gt;ci-&gt;func = L1-&gt;top; setnilvalue(L1-&gt;top++); /* `function&#39; entry for this `ci&#39; */ L1-&gt;base = L1-&gt;ci-&gt;base = L1-&gt;top; L1-&gt;ci-&gt;top = L1-&gt;top + LUA_MINSTACK; } 可以看到的是,初始化了两个数组,分别保存Lua栈和CallInfo结构体数组.其中,与Lua栈相关的lua_State结构体成员变量有base,stack,top,lastfree,stack保存的是数组的初始位置,base会根据每次函数调用的情况发生变化,top指针指向的是当前第一个可用的栈位置,每次向栈中增加/删减元素都要对应的增减top指针,lastfee指针指向的书Lua栈的最后位置. CallInfo结构体,是每次有函数调用时都会去初始化的一个结构体,它的成员变量中,也有top,base指针,同样的是指向Lua栈的位置,所不同的是,它关注的仅是函数调用时的相关位置.从代码中可以看出,CallInfo数组是有限制的,换言之,在Lua中的嵌套函数调用层次也是有限制,不能超过一定数量. 首先看f_parser函数: static void f_parser (lua_State *L, void *ud) { int i; Proto *tf; Closure *cl; struct SParser *p = cast(struct SParser *, ud); int c = luaZ_lookahead(p-&gt;z); luaC_checkGC(L); tf = ((c == LUA_SIGNATURE[0]) ? luaU_undump : luaY_parser)(L, p-&gt;z, &amp;p-&gt;buff, p-&gt;name); cl = luaF_newLclosure(L, tf-&gt;nups, hvalue(gt(L))); cl-&gt;l.p = tf; for (i = 0; i &lt; tf-&gt;nups; i++) /* initialize eventual upvalues */ cl-&gt;l.upvals[i] = luaF_newupval(L); setclvalue(L, L-&gt;top, cl); incr_top(L); } f_parser函数的最后两句,将分析完毕之后的结构Closure指针压入了Lua栈. 再来看luaD_precall函数,这里为将代码放入Lua虚拟机中执行准备了相关数据,我们只截取其中的一部分来看: int luaD_precall (lua_State *L, StkId func, int nresults) { …. if (!cl-&gt;isC) { /* Lua function? prepare its call */ CallInfo *ci; StkId st, base; Proto *p = cl-&gt;p; // 1) 根据函数的参数类型,计算出该CallInfo的base指针位置 if (!p-&gt;is_vararg) { /* no varargs? */ base = func + 1; if (L-&gt;top &gt; base + p-&gt;numparams) L-&gt;top = base + p-&gt;numparams; } else { /* vararg function */ int nargs = cast_int(L-&gt;top - func) - 1; base = adjust_varargs(L, p, nargs); func = restorestack(L, funcr); /* previous call may change the stack */ } // 2) 分配一个新的CallInfo结构体,用于保存此次函数调用的相关信息:top,base指针,func函数 ci = inc_ci(L); /* now `enter&#39; new function */ ci-&gt;func = func; L-&gt;base = ci-&gt;base = base; ci-&gt;top = L-&gt;base + p-&gt;maxstacksize; lua_assert(ci-&gt;top &lt;= L-&gt;stack_last); // 3) LuaState的PC指针指向函数原型的代码数组 L-&gt;savedpc = p-&gt;code; /* starting point */ // ….. return PCRLUA; } 到这一步,跟某次具体的Lua代码执行相关的代码(保存在Proto的code数组中)和执行时所需环境(Lua栈),就已经准备完毕了.后面就是进入Lua虚拟机的主循环中解释执行代码了.]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua函数与upavalue]]></title>
    <url>%2F2018%2F12%2F15%2Flua%E5%87%BD%E6%95%B0%E4%B8%8Eupavalue%2F</url>
    <content type="text"><![CDATA[Lua中的所谓upvalue是一类比较特殊的值，可以理解为在某函数内引用外部的数据。 函数定义中用到了pushclosure这个函数用于将函数的定义Proto结构体指针push到父函数的数组中，在这个函数内，还建立了有关upvalue相关的逻辑： static void pushclosure (LexState *ls, FuncState *func, expdesc *v) { FuncState *fs = ls-&gt;fs; Proto *f = fs-&gt;f; int oldsize = f-&gt;sizep; int i; luaM_growvector(ls-&gt;L, f-&gt;p, fs-&gt;np, f-&gt;sizep, Proto *, MAXARG_Bx, &quot;constant table overflow&quot;); while (oldsize &lt; f-&gt;sizep) f-&gt;p[oldsize++] = NULL; f-&gt;p[fs-&gt;np++] = func-&gt;f; luaC_objbarrier(ls-&gt;L, f, func-&gt;f); init_exp(v, VRELOCABLE, luaK_codeABx(fs, OP_CLOSURE, 0, fs-&gt;np-1)); for (i=0; if-&gt;nups; i++) { OpCode o = (func-&gt;upvalues[i].k == VLOCAL) ? OP_MOVE : OP_GETUPVAL; luaK_codeABC(fs, o, 0, func-&gt;upvalues[i].info, 0); } } 注意在这个函数的最后，将遍历upvalue数组，根据该upvalue是否是局部变量，来决定紧跟着的是MOVE指令还是GETUPVAL指令。而这些是如何确定的呢？ Lua的分析器在解析到一个变量时，会调用singlevaraux函数进行查找： static int singlevaraux (FuncState *fs, TString *n, expdesc *var, int base) { if (fs == NULL) { /* no more levels? */ init_exp(var, VGLOBAL, NO_REG); /* default is global variable */ return VGLOBAL; } else { int v = searchvar(fs, n); /* look up at current level */ if (v &gt;= 0) { init_exp(var, VLOCAL, v); if (!base) markupval(fs, v); /* local will be used as an upval */ return VLOCAL; } else { /* not found at current level; try upper one */ if (singlevaraux(fs-&gt;prev, n, var, 0) == VGLOBAL) return VGLOBAL; var-&gt;u.s.info = indexupvalue(fs, n, var); /* else was LOCAL or UPVAL */ var-&gt;k = VUPVAL; /* upvalue in this level */ return VUPVAL; } } } 可以看到，这个函数是一个递归函数，有以下几种情况： 在函数的当前层找到该变量，则认为一个LOCAL变量 在函数的上层找到，则认为一个UPVAL 最后，则认为是一个全局变量。 如何定义函数的“层次”？来看一个例子就知道了: local a = 1 function test1() local b = 100 function test2() print(a) print(b) end end test1() 在这个例子中，函数test2与变量b是同层的，所以在调用函数test2时，singlevaraux查找变量b返回的LOCAL变量；而变量a是更上一层的LOCAL变量，对于函数test2而言，它就是UPVAL。 明白了解析部分是怎么处理upvalue的，来看看在虚拟机中是如何处理的。对应的代码在lvm.c中的这一部分： case OP_CLOSURE: { Proto *p; Closure *ncl; int nup, j; p = cl-&gt;p-&gt;p[GETARG_Bx(i)]; nup = p-&gt;nups; ncl = luaF_newLclosure(L, nup, cl-&gt;env); ncl-&gt;l.p = p; for (j=0; jl.upvals[j] = cl-&gt;upvals[GETARG_B(*pc)]; else { lua_assert(GET_OPCODE(*pc) == OP_MOVE); ncl-&gt;l.upvals[j] = luaF_findupval(L, base + GETARG_B(*pc)); } } setclvalue(L, ra, ncl); Protect(luaC_checkGC(L)); continue; } 当变量是UPVAL时，此时PC指令对应的B参数是函数结构体的upval数组的索引，根据它直接从upval数组中取出值来；否则，PC指令对应的B参数是基于函数基地址base的一个偏移量，根据它得到相应的变量；再调用函数luaF_findupval： UpVal *luaF_findupval (lua_State *L, StkId level) { global_State *g = G(L); GCObject **pp = &amp;L-&gt;openupval; UpVal *p; UpVal *uv; while (*pp != NULL &amp;&amp; (p = ngcotouv(*pp))-&gt;v &gt;= level) { lua_assert(p-&gt;v != &amp;p-&gt;u.value); if (p-&gt;v == level) { /* found a corresponding upvalue? */ if (isdead(g, obj2gco(p))) /* is it dead? */ changewhite(obj2gco(p)); /* ressurect it */ return p; } pp = &amp;p-&gt;next; } uv = luaM_new(L, UpVal); /* not found: create a new one */ uv-&gt;tt = LUA_TUPVAL; uv-&gt;marked = luaC_white(g); uv-&gt;v = level; /* current value lives in the stack */ uv-&gt;next = *pp; /* chain it in the proper position */ *pp = obj2gco(uv); uv-&gt;u.l.prev = &amp;g-&gt;uvhead; /* double link it in `uvhead&#39; list */ uv-&gt;u.l.next = g-&gt;uvhead.u.l.next; uv-&gt;u.l.next-&gt;u.l.prev = uv; g-&gt;uvhead.u.l.next = uv; lua_assert(uv-&gt;u.l.next-&gt;u.l.prev == uv &amp;&amp; uv-&gt;u.l.prev-&gt;u.l.next == uv); return uv; } 注意到，传入这个函数的参数level，其实是前面已经根据base基址定位到的变量。这个函数分为两个部分： 首先，遍历当前的openupval数组，查找这个变量。由于这个变量肯定是前面已经定义过的，所以查找的条件就是（(p = ngcotouv(*pp))-&gt;v &gt;= level）。当查找到这个变量时，如果是准备释放的变量，则将它重新置为不可释放。 如果在openval数组中没有找到，说明之前没有别的地方引用过这个upval。如此则重新分配一个upvalue指向待引用的值。 最后，当函数调用完毕时，有相应的close指令，将upvalue的引用关系去除。具体见函数luaF_close。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua虚拟机概述]]></title>
    <url>%2F2018%2F12%2F15%2Flua%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[何为虚拟机用于模拟计算机运行的程序.是个中间层,它处于脚本语言和硬件之间的一个程序.每一门脚本语言都会有自己定义的opcode(”操作码”),可以理解为这门程序自己定义的”汇编语言”.一般的编译型语言,比如C等,经过编译器编译之后生成的都是与当前硬件环境相匹配的汇编代码;而脚本型的语言,经过前端的处理之后,生成的就是opcode,再将该opcode放在这门语言的虚拟机中执行.虚拟机是作为单独的程序独立存在,而Lua由于是一门嵌入式的语言是附着在宿主环境中的. lua代码到虚拟机执行的流程 在Lua中,Lua代码从词法分析到语法分析再到生成opcode,最后进入虚拟机执行的大体流程是什么样子的呢？ Lua的API中提供了luaL_dofile函数,它实际上是个宏,内部首先调用luaL_loadfile函数,加载Lua代码进行语法,词法分析,生成Lua虚拟机可执行的代码,再调用lua_pcall函数,执行其中的代码: #define luaL_dofile(L, fn) \ (luaL_loadfile(L, fn) || lua_pcall(L, 0, LUA_MULTRET, 0)) 前半部分调用luaL_loadfile函数对Lua代码进行词法和语法分析,后半部分调用lua_pcall将第一步中分析的结果(也就是opcode)到虚拟机中执行. 首先来看luaL_loadfile函数,暂时不深入其中研究它如何分析一个Lua代码文件,先看它最后输出了什么.它最终会调用f_parser函数,这是对一个Lua代码进行分析的入口函数: static void f_parser (lua_State *L, void *ud) { int i; Proto *tf; Closure *cl; struct SParser *p = cast(struct SParser *, ud); int c = luaZ_lookahead(p-&gt;z); luaC_checkGC(L); tf = ((c == LUA_SIGNATURE[0]) ? luaU_undump : luaY_parser)(L, p-&gt;z, &amp;p-&gt;buff, p-&gt;name); cl = luaF_newLclosure(L, tf-&gt;nups, hvalue(gt(L))); cl-&gt;l.p = tf; for (i = 0; i &lt; tf-&gt;nups; i++) /* initialize eventual upvalues */ cl-&gt;l.upvals[i] = luaF_newupval(L); setclvalue(L, L-&gt;top, cl); incr_top(L); } 在完成词法分析之后,返回了Proto类型的指针tf,然后将其绑定在新创建的Closure指针上,初始化UpValue,最后压入Lua栈中. 不难想像,Lua词法分析之后产生的opcode等相关数据都在这个Proto类型的结构体中. 再来看lua_pcall函数是如何将产生的opcode放入虚拟机执行的. lua_pcall函数中,首先获取需要调用的函数指针: c.func = L-&gt;top - (nargs+1); /* function to be called */ 这里的nargs是由函数参数传入的,luaL_dofile中调用lua_pcall时这里传入的参数是0,换句话说,这里得到的函数对象指针就是在f_parser函数中最后放入Lua栈的指针. 继续往下执行,走到luaD_call函数,有这一段代码: if (luaD_precall(L, func, nResults) == PCRLUA) /* is a Lua function? */ luaV_execute(L, 1); /* call it */ 进入luaV_execute函数,这里是虚拟机执行代码的主函数: void luaV_execute (lua_State *L, int nexeccalls) { LClosure *cl; StkId base; TValue *k; const Instruction *pc; reentry: /* entry point */ lua_assert(isLua(L-&gt;ci)); pc = L-&gt;savedpc; cl = &amp;clvalue(L-&gt;ci-&gt;func)-&gt;l; base = L-&gt;base; k = cl-&gt;p-&gt;k; /* main loop of interpreter */ for (;;) { const Instruction i = *pc++; StkId ra; if ((L-&gt;hookmask &amp; (LUA_MASKLINE | LUA_MASKCOUNT)) &amp;&amp; (--L-&gt;hookcount == 0 || L-&gt;hookmask &amp; LUA_MASKLINE)) { traceexec(L, pc); if (L-&gt;status == LUA_YIELD) { /* did hook yield? */ L-&gt;savedpc = pc - 1; return; } base = L-&gt;base; } /* warning!! several calls may realloc the stack and invalidate `ra&#39; */ ra = RA(i); // 以下是各种opcode的情况处理 } 可以看到,这里的pc指针里存放的是虚拟机opcode代码,它最开始从L-&gt;savepc初始化而来,而L-&gt;savepc在luaD_precall中赋值: L-&gt;savedpc = p-&gt;code; /* starting point */ 这里的p就是第一步f_parser中返回的Proto指针. 回顾一下整个流程: 函数f_parser中,对Lua代码文件的分析返回了Proto指针 函数luaD_precall中,将Lua_state的savepc指针指向1中的Proto结构体的code指针 函数luaV_execute中,pc指针指向2中的savepc指针,紧跟着就是一个大的循环体,依次取出其中的opcode进行执行.]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua函数定义]]></title>
    <url>%2F2018%2F12%2F15%2Flua%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89%2F</url>
    <content type="text"><![CDATA[FuncStateproto结构数组保存函数原型信息;prev保存父函数体指针；actvar保存定义的局部变量；upvalues保存upvalue Lua源码中,专门有一个结构体FuncState用来保存函数相关的信息.其实,即使没有创建任何函数,对于Lua而言也有一个最外层的FuncState数据.这个结构体的定义: typedef struct FuncState { Proto *f; /* current function header */ Table *h; /* table to find (and reuse) elements in */ struct FuncState *prev; /* enclosing function */ struct LexState *ls; /* lexical state */ struct lua_State *L; /* copy of the Lua state */ struct BlockCnt *bl; /* chain of current blocks */ int pc; /* next position to code (equivalent to `ncode&#39;) */ int lasttarget; /* `pc&#39; of last `jump target&#39; */ int jpc; /* list of pending jumps to `pc&#39; */ int freereg; /* first free register */ int nk; /* number of elements in `k&#39; */ int np; /* number of elements in `p&#39; */ short nlocvars; /* number of elements in `locvars&#39; */ lu_byte nactvar; /* number of active local variables */ upvaldesc upvalues[LUAI_MAXUPVALUES]; /* upvalues */ unsigned short actvar[LUAI_MAXVARS]; /* declared-variable stack */ } FuncState; 其中的Proto结构体数组用于保存函数原型信息,包括函数体代码(opcode),之所以使用数组,是因为在某个函数内,可能存在多个局部函数.而prev指针就是指向这个函数的”父函数体”的指针. 比如以下代码: function fun() function test() end end 那么,在保存test函数原型的Proto数据就存放在保存fun函数的FuncState结构体的p数组中,反之,保存test函数的FuncState.prev指针就指向保存func函数的FuncState指针. 接着看Funcstate结构体的成员,actvar数组用于保存局部变量,比如函数的参数就是保存在这里.另外还有一个存放upval值的upvalues数组.这里有两种不同的处理.如果这个upval是父函数内的局部变量,则生成的是MOVE指令用于赋值;如果对于父函数而言也是它的upval,则生成GET_UPVAL指令用于赋值. 当开始处理一个函数的定义时,首先调用open_func函数,创建一个新的Proto结构体用于保存函数原型信息,接着将该函数的FuncState的prev指针指向父函数.最后当函数处理完毕时,调用pushclosure函数将这个新的函数的信息push到父函数的Proto数组中. 函数也是第一类值 可以存在变量里最后,由于函数在Lua中是所谓的”first class type”,所以其实以下两段Lua代码是等价的: local function test() -- 可以test end --以上相当于 local test； test = function() ... end local test = function () --不可以调用test 以为第一类之定义完成之后才可以使用 end 也就是说,其实是生成一段代码,用于保存函数test的相关信息,之后再将这些信息赋值给变量test,这里的test可以是local,也可以是global的,这一点跟一般的变量无异. 函数定义词法分析所以在与函数定义相关的词法分析代码中: static void funcstat (LexState *ls, int line) { /* funcstat -&gt; FUNCTION funcname body */ int needself; expdesc v, b; luaX_next(ls); /* skip FUNCTION */ needself = funcname(ls, &amp;v); body(ls, &amp;b, needself, line); luaK_storevar(ls-&gt;fs, &amp;v, &amp;b); luaK_fixline(ls-&gt;fs, line); /* definition `happens&#39; in the first line */ } 上面的变量v首先在funcname函数中获得该函数的函数名,变量b在进入函数body之后可以得到函数体相关的内容.在这之后的luaK_storevar调用,就是把b的值赋值给v,也就是前面提到的函数体赋值给函数名.]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua字符串类型]]></title>
    <url>%2F2018%2F12%2F14%2Flua%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[Lua中字符串结构体的定义是: typedef union TString { L_Umaxalign dummy; /* ensures maximum alignment for strings */ struct { CommonHeader; lu_byte reserved; unsigned int hash; size_t len; } tsv; } TString; 这里TString结构体是一个union, 最开始的L_Umaxalign dummy;起到的是对齐作用.紧跟着是CommonHeader,可以看出TString也是可GC数据类型的一种. 在Lua中,字符串是一个保存在一个全局的地方,在globale_state的strt里面,这是一个hash数组,专门用于存放字符串: typedef struct stringtable { GCObject **hash; lu_int32 nuse; /* number of elements */ int size; } stringtable; 一个字符串TString,首先根据hash算法算出hash值,这就是stringtable中hash的索引值,如果这里已经有元素,则使用链表串接起来. 同时,TString中的字段reserved,表示这个字符串是不是保留字符串,比如Lua的关键字,在最开始赋值的时候是这么处理的: void luaX_init (lua_State *L) { int i; for (i=0; itsv.reserved = cast_byte(i+1); /* reserved word */ } } 这里存放的值,是数组luaX_tokens中的索引: const char *const luaX_tokens [] = { &quot;and&quot;, &quot;break&quot;, &quot;do&quot;, &quot;else&quot;, &quot;elseif&quot;, &quot;end&quot;, &quot;false&quot;, &quot;for&quot;, &quot;function&quot;, &quot;if&quot;, &quot;in&quot;, &quot;local&quot;, &quot;nil&quot;, &quot;not&quot;, &quot;or&quot;, &quot;repeat&quot;, &quot;return&quot;, &quot;then&quot;, &quot;true&quot;, &quot;until&quot;, &quot;while&quot;, &quot;..&quot;, &quot;...&quot;, &quot;==&quot;, &quot;&gt;=&quot;, &quot;&lt;=&quot;, &quot;~=&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, NULL }; 一方面可以迅速定位到是哪个关键字,另方面如果这个reserved字段不为0,则表示该字符串是不可自动回收的,在GC过程中会略过这个字符串的处理. 具体查找字符串时,首先计算出hash值,定位到所在的strt中的hash数组所在,再遍历hash桶所在链表,首先比较长度,如果相同再继续逐字节的比较字符串内容: TString *luaS_newlstr (lua_State *L, const char *str, size_t l) { GCObject *o; unsigned int h = cast(unsigned int, l); /* seed */ size_t step = (l&gt;&gt;5)+1; /* if string is too long, don&#39;t hash all its chars */ size_t l1; for (l1=l; l1&gt;=step; l1-=step) /* compute hash */ h = h ^ ((h&lt;&lt;5)+(h&gt;&gt;2)+cast(unsigned char, str[l1-1])); for (o = G(L)-&gt;strt.hash[lmod(h, G(L)-&gt;strt.size)]; o != NULL; o = o-&gt;gch.next) { TString *ts = rawgco2ts(o); if (ts-&gt;tsv.len == l &amp;&amp; (memcmp(str, getstr(ts), l) == 0)) { /* string may be dead */ if (isdead(G(L), o)) changewhite(o); return ts; } } return newlstr(L, str, l, h); /* not found */ }]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua-pcall的实现]]></title>
    <url>%2F2018%2F12%2F13%2Flua-pcall%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[Lua支持两种形式的函数调用，一种对调用过程的堆栈进行保护，即使中间过程出错，也不至于让进程退出，也就是pcall，一般在使用C调用Lua写的脚本函数时，都采用pcall方式。 对比起一般的函数调用方式，pcall多做了这些事情： 对函数调用前的Lua堆栈进行保护在调用完毕之后恢复，支持传入出错时的函数在调用出错时调用。 来依次看这个过程。 首先看入口函数lua_pcall： LUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) { struct CallS c; int status; ptrdiff_t func; lua_lock(L); api_checknelems(L, nargs+1); checkresults(L, nargs, nresults); if (errfunc == 0) func = 0; else { StkId o = index2adr(L, errfunc); api_checkvalidindex(L, o); func = savestack(L, o); } c.func = L-&gt;top - (nargs+1); /* function to be called */ c.nresults = nresults; status = luaD_pcall(L, f_call, &amp;c, savestack(L, c.func), func); adjustresults(L, nresults); lua_unlock(L); return status; } lua_pcall函数与lua_call相比，多了第四个参数，该函数用于传入错误处理函数在Lua栈中的地址。所以第一步将根据传入的参数得到它的值在函数栈中的地址。然后根据这些参数调用函数luaD_pcall函数。 luaD_pcall的实现 int luaD_pcall (lua_State *L, Pfunc func, void *u, ptrdiff_t old_top, ptrdiff_t ef) { int status; unsigned short oldnCcalls = L-&gt;nCcalls; ptrdiff_t old_ci = saveci(L, L-&gt;ci); lu_byte old_allowhooks = L-&gt;allowhook; ptrdiff_t old_errfunc = L-&gt;errfunc; L-&gt;errfunc = ef; status = luaD_rawrunprotected(L, func, u); if (status != 0) { /* an error occurred? */ StkId oldtop = restorestack(L, old_top); luaF_close(L, oldtop); /* close eventual pending closures */ luaD_seterrorobj(L, status, oldtop); L-&gt;nCcalls = oldnCcalls; L-&gt;ci = restoreci(L, old_ci); L-&gt;base = L-&gt;ci-&gt;base; L-&gt;savedpc = L-&gt;ci-&gt;savedpc; L-&gt;allowhook = old_allowhooks; restore_stack_limit(L); } L-&gt;errfunc = old_errfunc; return status; } 这个函数首先将一些需要保存以便以后进行错误恢复的值保存，然后调用函数luaD_rawrunprotected。 在luaD_rawrunprotected中， int luaD_rawrunprotected (lua_State *L, Pfunc f, void *ud) { struct lua_longjmp lj; lj.status = 0; lj.previous = L-&gt;errorJmp; /* chain new error handler */ L-&gt;errorJmp = &amp;lj; LUAI_TRY(L, &amp;lj, (*f)(L, ud); ); L-&gt;errorJmp = lj.previous; /* restore old error handler */ return lj.status; } 可以看到的是，在Lua中，涉及到这些错误恢复的数据，实际上形成一个链条关系，这个函数首先将之前的错误链保存起来。而LUAI_TRY这个宏，会根据不同的编译器进行实现，比如C++中使用的try…catch，C中使用longjmp等。 再来看看真正出错的时候是如何处理的。 void luaG_errormsg (lua_State *L) { if (L-&gt;errfunc != 0) { /* is there an error handling function? */ StkId errfunc = restorestack(L, L-&gt;errfunc); if (!ttisfunction(errfunc)) luaD_throw(L, LUA_ERRERR); setobjs2s(L, L-&gt;top, L-&gt;top - 1); /* move argument */ setobjs2s(L, L-&gt;top - 1, errfunc); /* push function */ incr_top(L); luaD_call(L, L-&gt;top - 2, 1); /* call it */ } luaD_throw(L, LUA_ERRRUN); } 首先如果之前保存的errfunc不为空，则首先从Lua栈中得到该函数，如果判断这个地址存放的不是一个函数则直接抛出错误。否则将错误参数压入栈中调用该错误处理函数。最后调用LuaD_throw函数，这个函数与前面的LUAI_TRY宏是对应的。这样就可以回到原来保存的错误恢复地点，恢复调用前的Lua栈，继续执行下去，而不是导致宿主进程退出。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua表的创建和初始化]]></title>
    <url>%2F2018%2F12%2F13%2Flua%E8%A1%A8%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[表的基本实现在Lua中，表是唯一的数据结构，可以使用它，模拟hash表，数组，链表，树等一切常用的数据结构。Lua表分为数组部分和hash部分。比如： local t = {1,2,3,4,5} 以上分配一个Lua数组，依次为1到5. 而如果要初始化hash部分，则需要指定key，有两种方式： local t = {a=&quot;test&quot;} local t = {[&quot;a&quot;]=&quot;test&quot;} 以上都指定了key为”a”的元素对应的值是”test”（注意一些上面两种情况key分别可以加引号和不加引号的）。 现在可以来看Lua表创建相关的操作。涉及到这部分的，是两个OPCODE： NEWTABLE指令。 指令域A指定的是所要创建的表在Lua栈中的地址，而B,C则分别指定的是创建表时数组和hash部分的初始大小。 SETLIST指令。 需要特别说明的是，这个指令仅能用于初始化Lua表的数组部分时使用，hash部分没有作用。指令域A同样指定的是所要初始化的表在Lua栈中的地址，B指定的是初始化时数组的数量，而C指定的是BLOCK的数量。这里需要做一个说明。在Lua中有一个特殊的常量，叫FPF（fields per flush），可以简单的理解为，每次调用SETLIST指令时，写入数组的数量最多可以有多少，Lua中这个常量定义为50.于是，假如这里要初始化一个有60个元素的数组，那么将会拆分成两个SETLIST指令，第一个SETLIST指令，B为50，C为1，而第二个SETLIST指令，B为10而C为0. 实际上，SETLIST指令还是有点复杂的。需要再继续了解一下几个知识点。 lopcodes.h中对这个指令的注释为： OP_SETLIST,/* A B C R(A)[(C-1)*FPF+i] := R(A+i), 1 &lt;= i &lt;= B */ 需要注意的是，A在这里既指定了表的栈位置，还有另一层含义从”=”右边可知，A在栈中紧跟着的数据是需要初始化给A数组的数据，所以A在这个指令中负担了两个数据的指示。换言之，当在A位置创建了这个Lua表之后，紧跟着这个Lua表的数据（数量由B指定）则是准备初始化给Lua表的数据。 Lua还要处理某些情况下，数组元素可变的情况，比如: local t = {func()} 可以看到，此时数组元素的数量是不确定的，依赖于函数的返回值，而当解析到这个点时，也并不知道func的具体情况。Lua在这里的处理是将B置为0，表示从A+1位置开始直到这个函数栈的栈顶位置之间的元素全部用来初始化这个Lua表的数组部分。 C也有可能为0，但是这种情况很少有，仅当初始化数组的数量非常大的时候出现，这里就不做分析了（因为要模拟这种情况有些蛋疼）。 Lua源码中相关的实现。分析Lua表创建部分的入口函数是lparser.c中的constructor函数。首先，函数调用pc = luaK_codeABC(fs, OP_NEWTABLE, 0, 0, 0);生成一个NEWTABLE指令，注意在这里，B/C部分都是0，从前面的分析知道，这两部分分别指定的是Lua表的数组和hash部分的初始尺寸，因为在这里这两部分的大小并不知道，所以先填0，而保存在pc中是要保存这个生成的NEWTABLE指令，后面需要对B/C部分进行改写，填充数组和hash部分的尺寸。 紧跟着，在解析Lua表初始化的整个流程中，使用了结构体ConsControl： struct ConsControl { expdesc v; /* last list item read */ expdesc *t; /* table descriptor */ int nh; /* total number of `record&#39; elements */ int na; /* total number of array elements */ int tostore; /* number of array elements pending to be stored */ }; 每一项的含义分别是，v表示的是上一个解析到表元素，它可能是一个key-value形式的赋值（此时是初始化一个hash元素），也有可能是单独的元素（此时是初始化一个数组元素）；t是一个指针，存放的是待初始化的Lua表；nh和na分别表示表的hash和数组部分尺寸，解析过程中将用这两个变量记录以便在最后重新填充前面的NEWTABLE的B/C部分；tostore则是存放的当前已经有多少数组元素待存放到Lua表中，当这个值达到FPF时，根据上面的分析则生成一个SETLIST指令，然后重新值0进入下一个元素的处理。 checknext(ls, &#39;{&#39;); do { lua_assert(cc.v.k == VVOID || cc.tostore &gt; 0); if (ls-&gt;t.token == &#39;}&#39;) break; closelistfield(fs, &amp;cc); switch(ls-&gt;t.token) { case TK_NAME: { /* may be listfields or recfields */ luaX_lookahead(ls); if (ls-&gt;lookahead.token != &#39;=&#39;) /* expression? */ listfield(ls, &amp;cc); else recfield(ls, &amp;cc); break; } case &#39;[&#39;: { /* constructor_item -&gt; recfield */ recfield(ls, &amp;cc); break; } default: { /* constructor_part -&gt; listfield */ listfield(ls, &amp;cc); break; } } } while (testnext(ls, &#39;,&#39;) || testnext(ls, &#39;;&#39;)); check_match(ls, &#39;}&#39;, &#39;{&#39;, line); lastlistfield(fs, &amp;cc); SETARG_B(fs-&gt;f-&gt;code[pc], luaO_int2fb(cc.na)); /* set initial array size */ SETARG_C(fs-&gt;f-&gt;code[pc], luaO_int2fb(cc.nh)); /* set initial table size */ 这个分析过程的主体部分，是一个循环，循环的终止条件是遇到了”}”符号，则该数组的初始化部分完成。每次循环做以下的事情： 调用closelistfield函数。 它是对数组元素做处理。首先将上一个分析到的数组元素，写入到当前的Lua栈中，这一点可以结合前面分析SETLIST指令来看。同时，如果当前的tostore数量达到FPF时，则生成SETLIST指令，这一点前面也做了分析。 然后就是两种情况的处理： hash和数组部分，可以参看最开始Lua表初始化的语法就能知道什么语法是用于初始化hash部分，什么语法是初始化数组部分的了。分别调用的是recfield和listfield函数。 listfield函数相对简单，需要判断当前表的数组元素是不是超过了限制，同时增加na和tostore计数。 recfield稍微复杂一点，还涉及到另一个指令SETTABLE，暂时跳过下一节再解释，现在知道它肯定会增加na计数就可以了。 最后，由于初始化Lua表时，不同的元素之间是以”,”或者”;”做分割的，所以在遇到”}”退出循环之后，还有最后一个元素没有处理，于是还要调用lastlistfield函数进行处理。 lastlistfield函数要处理的情况，就是前面分析过的，初始化过程中是不是遇到了函数返回值的情况，如果有则生成的SETLIST指令的域B要为0. 最后就是根据分析过程中得到的na，nh数量重新填充NEWTABLE指令的B/C域了。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua require机制]]></title>
    <url>%2F2018%2F12%2F12%2Flua%20require%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[require(modname) 加载给定的模块.函数首先检查表package.loaded来判定modname是否已经存在. 如果存在,则require返回package.loaded[modname]所存储的值否则它尝试为模块找到一个加载器(loader). 要找到一个加载器,require首先查询package.preloaded[modname].如果它有值,该值(应该是一个函数)就是加载器. 如果没值require使用package.path中存储的路径查找一个Lua的加载器.如果该查找也失败,它使用package.cpath中 存储的路径查找一个C语言加载器(C loader).如果还是失败,它尝试使用all-in-one加载器(如下) 当加载一个C库的时候,require首先使用动态链接工具将应用程序与库连接起来.之后它尝试找到一个该库中的C函数,该函数要被当做加载器使用.这个C函数的名称是字符串”luaopen_”连接着复制的模块名(模块名称中的每个点号”.”都被替换为一个下划线).此外,如果模块名称含有连字符”-“,则第一个连字符的前缀(包括连字符)都被移除.比如,如果模块名称是a.v1-b.c,则函数名称将是luaopen_b_c. 如果require即没有为模块找到一个Lua库也没有为模块找到一个C库,他将调用all-in-one加载器.该加载器为给定模块的根名称查找C路径找到对应库(原文:this loader searches the C path for a library for the root name of the given module).例如,当require a.b.c时,它将为a查找一个库.如果找到,它查询该库内部为子模块找到一个开放函数(open function);在我们这个例子中将会是luaopen_a_b_c.使用这个便利机制(facility),一个包可以将几个子模块打包进单个的库中,同时每个子模块保存着它本来的开放函数. 一旦找到一个加载器,require使用单个的参数modname调用加载器.如果加载器返回任何值,require将其赋值给package.loaded[modname]. 如果加载器没有返回值且没有给package.loaded[modname]赋与任何值,则require为该条目赋值为true. 无论如何,require返回package.loaded[modname]的最终值. 如果加载或者运行模块有任何错误,或者他不能为模块找到一个加载器,则require发出一个错误信号. require函数的实现原理如下: –require 函数的实现 function require(name) ​ if not package.loaded[name] then –是否在package.loaded中存在name ​ local loader = findloader(name) –不存在则查找加载器 ​ if loader == nil then ​ error(“unable to load module” .. name) ​ end ​ package.loaded[name] = true –加载器不存在 设置true ​ local res = loader(name) –加载 ​ if res ~= nil then ​ package.loaded[name] = res –加载返回的值给你 package.loaded ​ end ​ end ​ return package.loaded[name] –返回 package.loaded[name] end package.cpath 由require使用查找C加载器的路径 Lua初始化C路径package.cpath的方法与初始化Lua路径package.path的相同,使用LUA_CPATH中的环境变量(另外一个默认的路径在luaconf.h中定义) package.loaded 一个用于控制哪些模块已经加载的表,该表由require使用.当require一个模块名为modname的模块且package.loaded[modname]不为false时,require仅返回package.loaded[modname]存储的值. package.loadlib(libname,funcname) 使用C库libname动态链接到宿主程序.在这个库中,寻找函数funcname并将该函数作为一个C函数返回.(所以,funcname必须遵守协议(参见lua_CFunction)). 这是一个底层函数.它完全绕过了package和module系统.与require不同,它不执行任何路径查找且不自动添加扩展名.libname必须是C库中完整的文件名,如果必要的话还要包含路径和扩展名.funcname必须是原封不动的C库中导出的名字(这可能取决于使用的C编译器和链接器). 这个函数不被ANSI C支持.就其本身而言,它只在一些平台上才能使用(Windows,Linux,Mac OS X,Solaris,BSD,加上其他支持dlfcn标准的Unix系统) package.path require用于查找Lua加载器的路径 在启动时,Lua使用环境变量LUA_PATH或者如果环境变量未定义就使用luaconf.h中定义的默认值来初始化该值.环境变量中的任何”::”都被替换为默认路径. 路径是一系列由分号隔开的模板(templates).对于每个模板,require将每个模板中的问号替换为filename,filename是modname中每个点都被替换成”目录分隔符”(比如Unix中的”/“)(这句感觉翻译不准确,原文:For each template,require will change each interrogation mark in the template by filename,which is modname with each dot replaced by a “directory separator”(such as “/“ in Unix));之后他将加载产生的文件名.因此,举个例子,如果Lua路径是”./?.lua;./?.lc;/usr/local/?/init.lua”,为模块foo查找一个Lua加载器将会尝试以如下顺序加载文件./foo.lua,./foo.lc和/usr/local/foo/init.lua package.preload 为特定模块存储加载器的一个表(参见require) package.seeall(module) 为module设置一个元表,module的__index只想全局环境(global environment),以便该module继承全局环境中的值.作为函数module中的一个选项来使用. 在Programming Lua中是这么讲的: 默认情况下,module不提供外部访问.必须在调用它之前,为需要访问的外部函数或模块声明适当的局部变量.也可以通过继承来实现外部访问,只需在调用module时附加一个选项package.seeall.这个选项等价于如下代码: setmetatable(M,{__index = _G}) 因而只需这么做: module(…,package.seeall) module(name,[,…]) 创建一个模块.如果在package.loaded[name]中有表,该表便是创建的模块.否则,如果有一个全局表t其名称与给定名称相同,则该全局表便是创建的模块.否则创建一个新的表t lua中import和require的区别 载入一个模块 import() 与 require() 功能相同，但具有一定程度的自动化特性。 假设有如下的目录结构： app/ app/classes/ app/classes/MyClass.luaapp/classes/MyClassBase.luaapp/classes/data/Data1.luaapp/classes/data/Data2.lua MyClass 中需要载入 MyClassBase 和 MyClassData。如果用 require()，MyClass 内的代码如下： local MyClassBase = require(“app.classes.MyClassBase”) local MyClass = class(“MyClass”, MyClassBase) local Data1 = require(“app.classes.data.Data1”) local Data2 = require(“app.classes.data.Data2”) 假如将 MyClass 及其相关文件换一个目录存放，那么就必须修改 MyClass 中的 require() 命令，否则将找不到模块文件。 而使用 import()，只需要如下写： local MyClassBase = import(“.MyClassBase”) local MyClass = class(“MyClass”, MyClassBase) local Data1 = import(“.data.Data1”) local Data2 = import(“.data.Data2”) 当在模块名前面有一个”.” 时，import() 会从当前模块所在目录中查找其他模块。因此 MyClass 及其相关文件不管存放到什么目录里，都不再需要修改 MyClass 中的 import() 命令。这在开发一些重复使用的功能组件时，会非常方便。 可以在模块名前添加多个”.” ，这样 import() 会从更上层的目录开始查找模块。 不过 import() 只有在模块级别调用（也就是没有将 import() 写在任何函数中）时，才能够自动得到当前模块名。如果需要在函数中调用 import()，那么就需要指定当前模块名： # MyClass.lua # 这里的 … 是隐藏参数，包含了当前模块的名字，所以最好将这行代码写在模块的第一行 local CURRENT_MODULE_NAME = … local function testLoad() local MyClassBase = import(“.MyClassBase”, CURRENT_MODULE_NAME) # 更多代码 end Parameters string moduleName 要载入的模块的名字 [string currentModuleName] 当前模块名 Returns module]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua错误跟踪]]></title>
    <url>%2F2018%2F12%2F12%2Flua%E9%94%99%E8%AF%AF%E8%B7%9F%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[pcall() xpcall() debug.traceback() debug.debug() assert() 错误 Errare humanum est（拉丁谚语：犯错是人的本性）。所以我们要尽可能的防止错误的发生，Lua经常作为扩展语言嵌入在别的应用中，所以不能当错误发生时简单的崩溃或者退出。相反，当错误发生时Lua结束当前的chunk并返回到应用中。 当Lua遇到不期望的情况时就会抛出错误，比如：两个非数字进行相加；调用一个非函数的变量；访问表中不存在的值等（可以通过metatables修改这种行为，后面介绍）。你也可以通过调用error函数显式地抛出错误，error的参数是要抛出的错误信息。 print “enter a number:” n = io.read(“*number”) if not n then error(“invalid input”) end Lua提供了专门的内置函数assert来完成上面类似的功能： print “enter a number:” n = assert(io.read(“*number”), “invalid input”) assert首先检查第一个参数，若没问题，assert不做任何事情；否则，assert以第二个参数作为错误信息抛出。第二个参数是可选的。注意，assert会首先处理两个参数，然后才调用函数，所以下面代码，无论n是否为数字，字符串连接操作总会执行： n = io.read() assert(tonumber(n), “invalid input: “ .. n .. “ is not a number”) 当函数遇到异常有两个基本的动作：返回错误代码或者抛出错误。选择哪一种方式，没有固定的规则，不过基本的原则是：对于程序逻辑上能够避免的异常，以抛出错误的方式处理之，否则返回错误代码。 例如sin函数，假定我们让sin碰到错误时返回错误代码，则使用sin的代码可能变为： local res = math.sin(x) if not res then – error ​ … 当然，我们也可以在调用sin前检查x是否为数字： if not tonumber(x) then – error: x is not a number ​ … 而事实上，我们既不是检查参数也不是检查返回结果，因为参数错误可能意味着我们的程序某个地方存在问题，这种情况下，处理异常最简单最实际的方式是抛出错误并且终止代码的运行。 再来看一个例子。io.open函数用于打开文件，如果文件不存在，结果会如何？很多系统中，我们通过“试着去打开文件”来判断文件是否存在。所以如果io.open不能打开文件（由于文件不存在或者没有权限），函数返回nil和错误信息。依据这种方式，我们可以通过与用户交互（比如：是否要打开另一个文件）合理地处理问题： local file, msg repeat print &quot;enter a file name:&quot; local name = io.read() if not name then return end -- no input file, msg = io.open(name, &quot;r&quot;) if not file then print(msg) end until file 如果你想偷懒不想处理这些情况，又想代码安全的运行，可以使用assert： file = assert(io.open(name, “r”)) Lua中有一个习惯：如果io.open失败，assert将抛出错误。 file = assert(io.open(“no-file”, “r”)) ​ –&gt; stdin:1: no-file: No such file or directory 注意：io.open返回的第二个结果（错误信息）会作为assert的第二个参数。 虽然你可以使用任何类型的值作为错误信息，通常情况下，我们使用字符串来描述遇到的错误。如果遇到内部错误（比如对一个非table的值使用索引下标访问）Lua将自己产生错误信息，否则Lua使用传递给error函数的参数作为错误信息。不管在什么情况下，Lua都尽可能清楚的描述问题发生的缘由。 local status, err = pcall(function () a = ‘a’+1 end) print(err) –&gt; stdin:1: attempt to perform arithmetic on a string value local status, err = pcall(function () error(“my error”) end) print(err) –&gt; stdin:1: my error 例子中错误信息给出了文件名（stdin）与行号。 函数error还可以有第二个参数，表示错误发生的层级。比如，你写了一个函数用来检查“error是否被正确调用”： function foo (str) if type(str) ~= &quot;string&quot; then error(&quot;string expected&quot;) end ... end 可有人这样调用此函数： foo({x=1}) Lua会指出发生错误的是foo而不是error，实际上，错误是调用error时产生的。为了纠正这个问题，修改前面的代码让error报告错误发生在第二级（你自己的函数是第一级）如下： function foo (str) if type(str) ~= &quot;string&quot; then error(&quot;string expected&quot;, 2) end ... end 当错误发生的时候，我们常常希望了解详细的信息，而不仅是错误发生的位置。若能了解到“错误发生时的栈信息”就好了，但pcall返回错误信息时，已经释放了保存错误发生情况的栈信息。因此，若想得到tracebacks，我们必须在pcall返回以前获取。Lua提供了xpcall来实现这个功能，xpcall接受两个参数：调用函数、错误处理函数。当错误发生时，Lua会在栈释放以前调用错误处理函数，因此可以使用debug库收集错误相关信息。有两个常用的debug处理函数：debug.debug和debug.traceback，前者给出Lua的提示符，你可以自己动手察看错误发生时的情况；后者通过traceback创建更多的错误信息，也是控制台解释器用来构建错误信息的函数。你可以在任何时候调用debug.traceback获取当前运行的traceback信息： print(debug.traceback())]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua用法2]]></title>
    <url>%2F2018%2F12%2F12%2Flua%E7%94%A8%E6%B3%952%2F</url>
    <content type="text"><![CDATA[loadstring load从给定的字符串得到块(函数)。lua5.3使用load()替换loadstring(). 一般如下用法：assert(loadstring(script))()f = loadstring(&quot;a = 1&quot;)语义上相当于：f = loadstring(&quot;function() a = 1 end&quot;)复杂用法如下：下面是动态加载字符串，并执行，结果为一个table local script = &quot;localee={[0]={id=0,lv=5,text=&#39;yy&#39;},[1]={id=1,lv=3,text=&#39;zz&#39;}} return ee&quot; local tb=assert(loadstring(script))() print(tb[0].text) 下面是动态加载字符串，并执行，结果为方法 local addscript=&quot;function dadd(a,b) return a+b end&quot; assert(loadstring(addscript))() print(tostring(dadd(2,3))) local f = load(&quot;a=1+2&quot;) print(type(f)) --function loadfileloadfile 编译Lua外部代码块，但不会运行代码，将会以函数的形式返回编译结果.返回编译结果函数. local f = laodfile(&quot;a.lua&quot;) print(type(f)) --function dofiledofile 直接编译运行Lua外部代码块，并不返回任何结果。编译错误会返回nil. function dofile(filename) local func = assert(loadfile(filename)) func() end loadload (chunk [, chunkname [, mode [, env]]])加载一个代码块。如果 chunk 是一个字符串，代码块指这个字符串。 如果 chunk 是一个函数， load 不断地调用它获取代码块的片断。 每次对 chunk 的调用都必须返回一个字符串紧紧连接在上次调用的返回串之后。 当返回空串、nil、或是不返回值时，都表示代码块结束。 如果结果函数有上值， env 被设为第一个上值。 若不提供此参数，将全局环境替代它。chunkname 在错误消息和调试消息中，用于代码块的名字。字符串 mode 用于控制代码块是文本还是二进制（即预编译代码块）。 它可以是字符串 “b” （只能是二进制代码块）， “t” （只能是文本代码块）， 或 “bt” （可以是二进制也可以是文本）。 默认值为 “bt”。 _ENV引用一个叫 var 的自由名字在句法上都被翻译为 _ENV.var 。 此外，每个被编译的 Lua 代码块都会有一个外部的局部变量叫 _ENV。 这里特别指出，你可以定义一个新变量或指定一个参数叫这个名字。 当编译器在转译自由名字时所用到的 _ENV ， 指的是你的程序在那个点上可见的那个名为 _ENV 的变量被 _ENV 用于值的那张表被称为 环境。 Lua保有一个被称为 全局环境 特别环境。它被保存在 C 注册表的一个特别索引下。在 Lua 中，全局变量 _G 被初始化为这个值。 当 Lua 加载一个代码块，_ENV 这个上值的默认值就是这个全局环境。 因此，在默认情况下，Lua 代码中提及的自由名字都指的全局环境中的相关项 （它们也被称为 全局变量 ）。此外，所有的标准库都被加载入全局环境，一些函数也针对这个环境做操作。 你可以用 load （或 loadfile）加载代码块，并赋予它们不同的环境。 （在 C 里，当你加载一个代码块后，可以通过改变它的第一个上值来改变它的环境。） select如果 index 是个数字， 那么返回参数中第 index 个之后的部分； 负的数字会从后向前索引（-1 指最后一个参数）。 否则，index 必须是字符串 “#”， 此时 select 返回参数的个数。 do function foo(...) for i = 1, select(&#39;#&#39;, ...) do //get the count of the params local arg = select(i, ...);//select the param print(&quot;arg&quot;, arg); end end foo(1, 2, 3, 4); end nextnext (table [, index])允许程序遍历表的所有字段。它的第一个参数是一个表，它的第二个参数是该表的索引。接下来返回表及其关联值的一个索引。 local tee = {1, 3, 4, 6, 8} t = {3,7,10,17, pi=3.14159, banana=&quot;yellow&quot;} for key,value in next,t,nil do print(key,value) end function pairs (t) return next, t, nil end for k, v in pairs(t) do print(k, v) end pcallpcall (f [, arg1, ···]) 传入参数，以 保护模式 调用函数 f 。 这意味着 f 中的任何错误不会抛出； 取而代之的是，pcall 会将错误捕获到，并返回一个状态码。 第一个返回值是状态码（一个布尔量）， 当没有错误时，其为真。 此时，pcall 同样会在状态码后返回所有调用的结果。 在有错误时，pcall 返回 false 加错误消息。 local ret, msg = pcall(function(i) print(i) end, 33) xpcallxpcall (f, msgh [, arg1, ···])这个函数和 pcall 类似。 不过它可以额外设置一个消息处理器 msgh。 local function __TRACKBACK__(errmsg) local track_text = debug.traceback(tostring(errmsg), 6); print(track_text, &quot;LUA ERROR&quot;); return false; end local function trycall(func, ...) local args = { ... }; return xpcall(function() func(unpack(args)) end, __TRACKBACK__); end local function test(aaa) print(&quot;#&quot;..aaa) end trycall(test, nil) 多行文本使用[[ sun feng sunfeng ]] 定义多行文本。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua版本变化]]></title>
    <url>%2F2018%2F12%2F12%2Flua%E7%89%88%E6%9C%AC%E5%8F%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[从 Lua 5.1 迁移到 5.2 5.2中抛弃module，建议使用require进行加载， 可能是考虑到Module定义对全局表的污染 在5.1版本，可以理解为每个chunk都具有自己的环境表，然后通过setfenv/getfenv进行设置和操作。Lua5.2开始取消了环境表的概念，取消setfenv/getfenv方法，增加了_Env来管理。 _G 和 _Env* _G 是放在注册表LUA_RIDX_GLOBALS中，初始化时核心的库都放在_G中；_Env 是chunk闭包的第一个upvalue，load时默认为_G, 然后后面定义的变量都会在编译时加上_ENV.前缀，以此传递下去，当然也可以修改 全局注册表 在5.2中已经移除了LUA_GLOBALSINDEX,去而带之的是注册表。5.2以后中上面两个函数都是使用的注册标中的LUA_RIDX_GLOBAS伪索引（索引注册表的全局环境）。处理 lua和C交互API的时候需要注意 luaL_register Lua5.2 以后取消了这个接口，不过可以通过luaL_setfunc方法看来实现 #undef luaL_register #define luaL_register(L,n,f) \ { if ((n) == NULL) luaL_setfuncs(L,f,0); else luaL_newlib(L,f); } #endif 从 Lua 5.2 迁移到 5.3 整数 (默认 64 位)，32 位整数的官方支持 位操作符 基本的 utf-8 支持 值的打包及解包函数 整数除法 ipairs 以及表处理库都会考虑元方法 新函数 string.pack 新函数 string.unpack 新函数 string.packsize]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua迭代器]]></title>
    <url>%2F2018%2F12%2F12%2Flua%E8%BF%AD%E4%BB%A3%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言迭代器就是一种可以遍历一种集合中所有元素的机制，在Lua中，通常将迭代器表示为函数。每调用一次函数，就返回集合中的“下一个”元素。每个迭代器都需要在每次成功调用之后保存一些状态，这样才能知道它所在的位置及如何走到下一个位置，通过之前博文的总结，闭包对于这样的任务提供了极佳的支持。现在我们就用代码来实现一个简单的迭代器。 function values(tb) local i = 0 return function () i = i + 1 return tb[i] end end local testTb = {10, 20, 30} for value in values(testTb) do print(value) end 这就是一个最简单的迭代器，使用闭包来完成整个任务；这只是一个简单的例子，接下来，再看看泛型for的语义。 泛型for的语义泛型for比较复杂，它在循环过程内保存了迭代器函数。它实际上保存着3个值：一个迭代器函数、一个恒定状态和一个控制变量。接下来，分别进行总结。泛型for的语法如下： for &lt;var-list&gt; in &lt;exp-list&gt; do &lt;body&gt; end 其中，是一个或多个变量名的列表，以逗号分隔；是一个或多个表达式的列表，同样以逗号分隔。通常表达式列表只有一个元素，即一句对迭代器函数的调用。例如： for k, v in pairs(t) do print(k, v) endfor做的第一件事就是对in后面的表达式求值，这些表达式应该返回3个值供for保存：迭代器函数、恒定状态和控制变量的初值。这里和多重赋值是一样的，只有最后一个表达式才会产生多个结果，并且只会保留前3个值，多余的值会被丢弃；而不够的话，就以nil补足。 在初始化完成以后，for会以恒定状态和控制变量来调用迭代器函数。然后for将迭代器函数的返回值赋予变量列表中的变量。如果第一个返回值为nil，那么循环就终止，否则，for执行它的循环体，随后再次调用迭代器函数，并重复这个过程。在前言部分的代码中，只是返回了迭代器函数，并没有返回恒定状态和控制变量。下面通过代码来说明这个问题，比如： for var_1, ..., var_n in &lt;explist&gt; do &lt;block&gt; end -- 就等价于以下代码： do local _f, _s, _var = &lt;explist&gt; -- 返回迭代器函数、恒定状态和控制变量的初值 while true do local var_1, ..., var_n = _f(_s, _var) _var = var_1 if _var == nil then break end &lt;block&gt; end end end 无状态的迭代器所谓“无状态的迭代器”，就是一种自身不保存任何状态的迭代器。因此，我们可以在多个循环中使用同一个无状态的迭代器，避免创建新的闭包的开销。 在每次迭代中，for循环都会用恒定状态和控制变量来调用迭代器函数。一个无状态的迭代器可以根据这两个值来为下次迭代生成下一个元素。这类迭代器的代表就是ipairs。它可以用来迭代一个数组的所有元素。如下述演示代码： local aTb = {&quot;One&quot;, &quot;Two&quot;, &quot;Three&quot;} for i, v in ipairs(aTb) do print(i, v) end 在这里，迭代器状态就是需要遍历的table（一个恒定状态，它不会在循环中改变）及当前的索引值（控制变量）。我们可以使用Lua代码来实现ipairs，大概就如下代码： local function iter(a, i) i = i + 1 local v = a[i] if v then return i, v end end function ipairs(a) return iter, a, 0 end 函数pairs与ipairs类似，也是用于遍历一个table中的所有元素。不同的是，它的迭代器函数是Lua中的一个基本函next。 function pairs(a) return next, t, nil end 在调用next(t, k)时，k是table t的一个key。此调用会以table中的任意次序返回一组值：此table的下一个key，及这个key所对应的值。而调用next(t, nil)时，返回table的第一组值。若没有下一组值时，next返回nil。所以，我们也可以使用next来判断一个table是否为空。 对于大家经常迷惑的ipairs和pairs的区别，在这里就能看的一清二楚了，ipairs只能用于遍历index是整型的table，同时，由于ipairs返回的控制变量初值为0，这就决定了，ipairs只能访问index从1开始的key和value；ipairs不能返回nil，当key对应的值为nil时，就直接终止遍历；而pairs则没有要求。关于ipairs和pairs的具体差异，请参考这篇博文：点这里。 当然了，有了无状态的迭代器，就有了有状态的迭代器了，有状态的迭代器就是专门用一个table来保存状态；在无状态的迭代器中，我们每一次都是迭代一个table，这个table就是一个无状态的table，它不会再遍历的过程中发生变化，而有状态的迭代器，则会在遍历的过程中对迭代的table进行变更，迭代的table的状态也随之发生了变化。这里不做详细的总结。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua热更新]]></title>
    <url>%2F2018%2F12%2F12%2Flua%E7%83%AD%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[单纯热更新Lua热更新最简单粗暴的热更新就是将package.loaded[modelname]的值置为nil，强制重新加载： function reload_module(module_name) package.loaded[modulename] = nil require(modulename) end 这样做虽然能完成热更，但问题是已经引用了该模块的地方不会得到更新， 因此我们需要将引用该模块的地方的值也做对应的更新。 function reload_module(module_name) local old_module = _G[module_name] package.loaded[module_name] = nil require (module_name) local new_module = _G[module_name] for k, v in pairs(new_module) do old_module[k] = v end package.loaded[module_name] = old_module end 用途 在生产环境上，总有可能出现不可预知的Bug，而通常修改好Bug仅仅又修改几句，停机维护的成本又太高，对于游戏来说，通常每个服就是单独的进程，也做不到像分布式环境下，关掉一部分机器，先升级一部分，再升级另一部分的无缝升级。这时候如果有热更就可以迅速的把Bug修复方案通过热更新进行修复，不会对用户任何的影响。例如： 业务逻辑有Bug 配置的数据有误 需求发生变更 热更新的原则1、热更新不破坏原有数据 热更新更新的基本内容就是更新服务的逻辑，通常只是逻辑发生变化，但原有的值并不能被改变，例如： local a = 1 function get_a() return a end 此时，我们调用get_a()返回是的1，我们将热更成 local a = 2 function get_a() print(&quot;get_a function&quot;) return a end 此时我们改变了a的初始值，但我们并不知道之前服务a的值是不是被重新赋过值，假设热更前a的值仍然为1，那么我们热更后调用get_a()返回的应该是1，而不应受新的初始值影响，而且同能打印出了”get_a function”，这时候则认为热更正常。 2、不为热更新写更多的代码 热更新可以通过很多种方法实现，比如说模块为了支持数据不变的特性，需要在模块里额外写一些代码来记录旧值，热更新之后再把旧值copy过来，或者用一些特殊的语法来支撑。这种方法将会对项目增加很多的负担，而且一旦发生意料之外的Bug，热更系统几乎处于半瘫痪状态。应该来说，代码原本该怎么实现就怎么实现，对于99%的lua代码都是支持的，不需要修改来迎合热更新。通常热更新不改变原有变量值的类型。 热更新的实现，代码适用于5.2以上原理 利用_ENV环境，在加载的时候把数据加载到_ENV下，然后再通过对比的方式修改_G底下的值，从而实现热更新，函数 function hotfix(chunk, check_name) 定义env的table，并为env设置_G访问权限，然后调用load实现把数据重新加载进来 local env = {} setmetatable(env, { __index = _G }) local _ENV = env local f, err = load(chunk, check_name, &#39;t&#39;, env) assert(f,err) local ok, err = pcall(f) assert(ok,err) 此时env我们可以得到新函数有变更的部分，我们替换的为可见变量，也就是可直接访问的变量 for name,value in pairs(env) do local g_value = _G[name] if type(g_value) ~= type(value) then _G[name] = value elseif type(value) == &#39;function&#39; then update_func(value, g_value, name, &#39;G&#39;..&#39; &#39;) _G[name] = value elseif type(value) == &#39;table&#39; then update_table(value, g_value, name, &#39;G&#39;..&#39; &#39;) end end 通过env当前的值和_G当前的值进行对比 如果类型不同我们直接覆盖原值，此时value不为nil，不会出现原则被覆盖成nil的情况 如果当前值为函数，我们进行函数的upvalue值比对 function update_func(env_f, g_f, name, deep) --取得原值所有的upvalue，保存起来 local old_upvalue_map = {} for i = 1, math.huge do local name, value = debug.getupvalue(g_f, i) if not name then break end old_upvalue_map[name] = value end --遍历所有新的upvalue，根据名字和原值对比，如果原值不存在则进行跳过，如果为其它值则进行遍历env类似的步骤 for i = 1, math.huge do local name, value = debug.getupvalue(env_f, i) if not name then break end local old_value = old_upvalue_map[name] if old_value then if type(old_value) ~= type(value) then debug.setupvalue(env_f, i, old_value) elseif type(old_value) == &#39;function&#39; then update_func(value, old_value, name, deep..&#39; &#39;..name..&#39; &#39;) elseif type(old_value) == &#39;table&#39; then update_table(value, old_value, name, deep..&#39; &#39;..name..&#39; &#39;) debug.setupvalue(env_f, i, old_value) else debug.setupvalue(env_f, i, old_value) end end end end 如果当前值为table，我们遍历table值进行对比 local protection = { setmetatable = true, pairs = true, ipairs = true, next = true, require = true, _ENV = true, } --防止重复的table替换，造成死循环 local visited_sig = {} function update_table(env_t, g_t, name, deep) --对某些关键函数不进行比对 if protection[env_t] or protection[g_t] then return end --如果原值与当前值内存一致，值一样不进行对比 if env_t == g_t then return end local signature = tostring(g_t)..tostring(env_t) if visited_sig[signature] then return end visited_sig[signature] = true --遍历对比值，如进行遍历env类似的步骤 for name, value in pairs(env_t) do local old_value = g_t[name] if type(value) == type(old_value) then if type(value) == &#39;function&#39; then update_func(value, old_value, name, deep..&#39; &#39;..name..&#39; &#39;) g_t[name] = value elseif type(value) == &#39;table&#39; then update_table(value, old_value, name, deep..&#39; &#39;..name..&#39; &#39;) end else g_t[name] = value end end --遍历table的元表，进行对比 local old_meta = debug.getmetatable(g_t) local new_meta = debug.getmetatable(env_t) if type(old_meta) == &#39;table&#39; and type(new_meta) == &#39;table&#39; then update_table(new_meta, old_meta, name..&#39;s Meta&#39;, deep..&#39; &#39;..name..&#39;s Meta&#39;..&#39; &#39; ) end end 更新1、可以调用hotfix_file对整个文件进行热更 function hotfix_file(name) local file_str local fp = io.open(name) if fp then io.input(name) file_str = io.read(&#39;*all&#39;) io.close(fp) end if not file_str then return -1 end return hotfix(file_str, name) end 2、可以通过hotfix进行代码的更新 function hotfix(chunk, check_name) 关于坑 这里有一个注意事项，lua的module模块，如： module(&quot;AA&quot;, package.seeall) 当我们加载lua模块的时候，这时候这个模块信息并不像初始化全局代码一样，就算提前设置了package.loaded[“AA”] = nil, 也不会出现在env中同时也不会调用_G的__newindex函数，也就是说env[“AA”]为空，故这种写法无法进行热更新，所以通常模块的写法改成如下 --定义模块AA AA = {} --相当于package.seeall setmetatable(AA, {__index = _G}) --环境隔离 local _ENV = AA]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua支持init64]]></title>
    <url>%2F2018%2F12%2F12%2Flua%E6%94%AF%E6%8C%81init64%2F</url>
    <content type="text"><![CDATA[lua5.3提供了很多很好的特性例如string.pack unpack这样的好东西，同时还支持ini64.在lua之前的版本中number只有一种类型double.对于init64基本按照int来处理. 对于64位的解决方案有很多种,基本的思路都是使用8byte的string或者lightuserdata或者userdata修改元表来实现. luajit使用userdata重载元表运算符实现在 luajit 中,是定义了一个 userdata 并重载其运算符完成的。用 ffi.cast(&quot;int64_t&quot;,0) 来构造一个 64bit 的 0 .userdata的做法存在额外开销问题，当 64bit 的 cdata 做 table 的 key 的时候，相同值的 int64 并不是同一个 key . lightuserdata 设置 metatable实现用 lightuserdata 无损失的表示一个 int64 ,lightuserdata是一个轻量级的cdata,通过给 lightuserdata 设置 metatable ，我们可以重载它的数据运算。存在的问题:比较一个 int64 和普通的 lua number 是否相等时，lua 不能隐式的做转换。目前使用这个方案的实现的已经有了,github上有https://github.com/bytemode/lua-int64.git这个库是云风大神实现的. 这个库只提供了一个显式的 api ，即构造一个 int64 数字。可以从 lua number 构造，也支持从一个 8 字节宽的小头的字符串来构造。实际在内存储存的是一个 lightuserdata 即一个 64bit 指针（所以这个库不适用于 32 位平台）。你也可以通过 C 接口 lua_pushlightuserdata 来把一个 64bit 整数压入堆栈。把 int64 转换为普通的 lua number 借用了 # 操作符。 #include &lt;lua.h&gt; #include &lt;lauxlib.h&gt; #include &lt;stdint.h&gt; #include &lt;math.h&gt; #include &lt;stdlib.h&gt; #include &lt;stdbool.h&gt; static int64_t _int64(lua_State *L, int index) { int type = lua_type(L,index); int64_t n = 0; switch(type) { case LUA_TNUMBER: { lua_Number d = lua_tonumber(L,index); n = (int64_t)d; break; } case LUA_TSTRING: { size_t len = 0; const uint8_t * str = (const uint8_t *)lua_tolstring(L, index, &amp;len); if (len&gt;8) { return luaL_error(L, &quot;The string (length = %d) is not an int64 string&quot;, len); } int i = 0; uint64_t n64 = 0; for (i=0;i&lt;(int)len;i++) { n64 |= (uint64_t)str[i] &lt;&lt; (i*8); } n = (int64_t)n64; break; } case LUA_TLIGHTUSERDATA: { void * p = lua_touserdata(L,index); n = (intptr_t)p; break; } default: return luaL_error(L, &quot;argument %d error type %s&quot;, index, lua_typename(L,type)); } return n; } static inline void _pushint64(lua_State *L, int64_t n) { void * p = (void *)(intptr_t)n; lua_pushlightuserdata(L,p); } static int int64_add(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); _pushint64(L, a+b); return 1; } static int int64_sub(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); _pushint64(L, a-b); return 1; } static int int64_mul(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); _pushint64(L, a * b); return 1; } static int int64_div(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); if (b == 0) { return luaL_error(L, &quot;div by zero&quot;); } _pushint64(L, a / b); return 1; } static int int64_mod(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); if (b == 0) { return luaL_error(L, &quot;mod by zero&quot;); } _pushint64(L, a % b); return 1; } static int64_t _pow64(int64_t a, int64_t b) { if (b == 1) { return a; } int64_t a2 = a * a; if (b % 2 == 1) { return _pow64(a2, b/2) * a; } else { return _pow64(a2, b/2); } } static int int64_pow(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); int64_t p; if (b &gt; 0) { p = _pow64(a,b); } else if (b == 0) { p = 1; } else { return luaL_error(L, &quot;pow by nagtive number %d&quot;,(int)b); } _pushint64(L, p); return 1; } static int int64_unm(lua_State *L) { int64_t a = _int64(L,1); _pushint64(L, -a); return 1; } static int int64_new(lua_State *L) { int top = lua_gettop(L); int64_t n; switch(top) { case 0 : lua_pushlightuserdata(L,NULL); break; case 1 : n = _int64(L,1); _pushint64(L,n); break; default: { int base = luaL_checkinteger(L,2); if (base &lt; 2) { luaL_error(L, &quot;base must be &gt;= 2&quot;); } const char * str = luaL_checkstring(L, 1); n = strtoll(str, NULL, base); _pushint64(L,n); break; } } return 1; } static int int64_eq(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); printf(&quot;%s %s\n&quot;,lua_typename(L,1),lua_typename(L,2)); printf(&quot;%ld %ld\n&quot;,a,b); lua_pushboolean(L,a == b); return 1; } static int int64_lt(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); lua_pushboolean(L,a &lt; b); return 1; } static int int64_le(lua_State *L) { int64_t a = _int64(L,1); int64_t b = _int64(L,2); lua_pushboolean(L,a &lt;= b); return 1; } static int int64_len(lua_State *L) { int64_t a = _int64(L,1); lua_pushnumber(L,(lua_Number)a); return 1; } static int tostring(lua_State *L) { static char hex[16] = &quot;0123456789ABCDEF&quot;; uintptr_t n = (uintptr_t)lua_touserdata(L,1); if (lua_gettop(L) == 1) { luaL_Buffer b; luaL_buffinitsize(L , &amp;b , 28); luaL_addstring(&amp;b, &quot;int64: 0x&quot;); int i; bool strip = true; for (i=15;i&gt;=0;i--) { int c = (n &gt;&gt; (i*4)) &amp; 0xf; if (strip &amp;&amp; c ==0) { continue; } strip = false; luaL_addchar(&amp;b, hex[c]); } if (strip) { luaL_addchar(&amp;b , &#39;0&#39;); } luaL_pushresult(&amp;b); } else { int base = luaL_checkinteger(L,2); int shift , mask; switch(base) { case 0: { unsigned char buffer[8]; int i; for (i=0;i&lt;8;i++) { buffer[i] = (n &gt;&gt; (i*8)) &amp; 0xff; } lua_pushlstring(L,(const char *)buffer, 8); return 1; } case 10: { int64_t dec = (int64_t)n; luaL_Buffer b; luaL_buffinitsize(L , &amp;b , 28); if (dec&lt;0) { luaL_addchar(&amp;b, &#39;-&#39;); dec = -dec; } int buffer[32]; int i; for (i=0;i&lt;32;i++) { buffer[i] = dec%10; dec /= 10; if (dec == 0) break; } while (i&gt;=0) { luaL_addchar(&amp;b, hex[buffer[i]]); --i; } luaL_pushresult(&amp;b); return 1; } case 2: shift = 1; mask = 1; break; case 8: shift = 3; mask = 7; break; case 16: shift = 4; mask = 0xf; break; default: luaL_error(L, &quot;Unsupport base %d&quot;,base); break; } int i; char buffer[64]; for (i=0;i&lt;64;i+=shift) { buffer[i/shift] = hex[(n&gt;&gt;(64-shift-i)) &amp; mask]; } lua_pushlstring(L, buffer, 64 / shift); } return 1; } static void make_mt(lua_State *L) { luaL_Reg lib[] = { { &quot;__add&quot;, int64_add }, { &quot;__sub&quot;, int64_sub }, { &quot;__mul&quot;, int64_mul }, { &quot;__div&quot;, int64_div }, { &quot;__mod&quot;, int64_mod }, { &quot;__unm&quot;, int64_unm }, { &quot;__pow&quot;, int64_pow }, { &quot;__eq&quot;, int64_eq }, { &quot;__lt&quot;, int64_lt }, { &quot;__le&quot;, int64_le }, { &quot;__len&quot;, int64_len }, { &quot;__tostring&quot;, tostring }, { NULL, NULL }, }; luaL_newlib(L,lib); } int luaopen_int64(lua_State *L) { if (sizeof(intptr_t)!=sizeof(int64_t)) { return luaL_error(L, &quot;Only support 64bit architecture&quot;); } lua_pushlightuserdata(L,NULL); make_mt(L); lua_setmetatable(L,-2); lua_pop(L,1); lua_newtable(L); lua_pushcfunction(L, int64_new); lua_setfield(L, -2, &quot;new&quot;); lua_pushcfunction(L, tostring); lua_setfield(L, -2, &quot;tostring&quot;); return 1; }]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua类的实现]]></title>
    <url>%2F2018%2F12%2F11%2Flua%E7%B1%BB%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[子类在定义时复制所有基类的方法，在实例化时将该类作为metatable的__index赋值给实例。这就是cocos2dx里面的lua class的实现。 function class(classname, super) ​ local cls = {} ​ if super then --复制基类方法 ​ cls = {} ​ for k,v in pairs(super) do cls[k] = v end ​ cls.super = super ​ else ​ cls = {ctor = function() end} ​ end ​ cls.__cname = classname ​ cls.__index = cls ​ function cls.new(...) --实例化 ​ local instance = setmetatable({}, cls) ​ instance.class = cls ​ instance:ctor(...) ​ return instance ​ end ​ return cls end]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua垃圾回收]]></title>
    <url>%2F2018%2F12%2F11%2Flua%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[采用垃圾回收机制对所有的lua对象(GCObject)进行管理。Lua虚拟机会定期运行GC，释放掉已经不再被被引用到的lua对象。 基本算法【标记清除】 基本的垃圾回收算法被称为”mark-and-sweep”算法。算法本身其实很简单。 1.系统管理着所有已经创建了的对象。每个对象都有对其他对象的引用。 2.root集合代表着已知的系统级别的对象引用。 3.从root集合出发，就可以访问到系统引用到的所有对象。而没有被访问到的对象就是垃圾对象，需要被销毁。 我们可以将所有对象分成三个状态： White状态，也就是待访问状态。表示对象还没有被垃圾回收的标记过程访问到。 Gray状态，也就是待扫描状态。表示对象已经被垃圾回收访问到了，但是对象本身对于其他对象的引用还没有进行遍历访问。 Black状态，也就是已扫描状态。表示对象已经被访问到了，并且也已经遍历了对象本身对其他对象的引用。 基本的算法可以描述如下： 当前所有对象都是White状态; 将root集合引用到的对象从White设置成Gray，并放到Gray集合中; while(Gray集合不为空) { ​ 从Gray集合中移除一个对象O，并将O设置成Black状态; ​ for(O中每一个引用到的对象O1) { ​ if(O1在White状态) { ​ 将O1从White设置成Gray，并放到到Gray集合中； ​ } ​ } } for(任意一个对象O){ ​ if(O在White状态) ​ 销毁对象O; ​ else ​ 将O设置成White状态; } Incremental Garbage Collection 上面的算法如果一次性执行，在对象很多的情况下，会执行很长时间，严重影响程序本身的响应速度。其中一个解决办法就是，可以将上面的算法分步执行，这样每个步骤所耗费的时间就比较小了。我们可以将上述算法改为以下下几个步骤。 首先标识所有的root对象： 当前所有对象都是White状态; 将root集合引用到的对象从White设置成Gray，并放到Gray集合中; 遍历访问所有的gray对象。如果超出了本次计算量上限，退出等待下一次遍历: while(Gray集合不为空,并且没有超过本次计算量的上限){ ​ 从Gray集合中移除一个对象O，并将O设置成Black状态; ​ for(O中每一个引用到的对象O1) { ​ if(O1在White状态) { ​ 将O1从White设置成Gray，并放到到Gray集合中； ​ } ​ } } 销毁垃圾对象： for(任意一个对象O){ ​ if(O在White状态) ​ 销毁对象O; ​ else ​ 将O设置成White状态; } 在每个步骤之间，由于程序可以正常执行，所以会破坏当前对象之间的引用关系。black对象表示已经被扫描的对象，所以他应该不可能引用到一个white对象。当程序的改变使得一个black对象引用到一个white对象时，就会造成错误。解决这个问题的办法就是设置barrier。barrier在程序正常运行过程中，监控所有的引用改变。如果一个black对象需要引用一个white对象，存在两种处理办法： 将white对象设置成gray，并添加到gray列表中等待扫描。这样等于帮助整个GC的标识过程向前推进了一步。 将black对象该回成gray，并添加到gray列表中等待扫描。这样等于使整个GC的标识过程后退了一步。 这种垃圾回收方式被称为”Incremental Garbage Collection”(简称为”IGC”，Lua所采用的就是这种方法。使用”IGC”并不是没有代价的。IGC所检测出来的垃圾对象集合比实际的集合要小，也就是说，有些在GC过程中变成垃圾的对象，有可能在本轮GC中检测不到。不过，这些残余的垃圾对象一定会在下一轮GC被检测出来，不会造成泄露。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua元表]]></title>
    <url>%2F2018%2F12%2F11%2Flua%E5%8E%9F%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[在 Lua table 中我们可以访问对应的key来得到value值，但是却无法对两个 table 进行操作。 因此 Lua 提供了元表(Metatable)，允许我们改变table的行为，每个行为关联了对应的元方法。 例如，使用元表我们可以定义Lua如何计算两个table的相加操作a+b。 当Lua试图对两个表进行相加时，先检查两者之一是否有元表，之后检查是否有一个叫”add”的字段，若找到，则调用对应的值。”add”等即时字段，其对应的值（往往是一个函数或是table）就是”元方法”。 有两个很重要的函数来处理元表： setmetatable(table,metatable):对指定table设置元表(metatable)，如果元表(metatable)中存在__metatable键值，setmetatable会失败 。 getmetatable(table):返回对象的元表(metatable)。 __index 元方法 这是 metatable 最常用的键。 当你通过键来访问 table 的时候，如果这个键没有值，那么Lua就会寻找该table的metatable（假定有metatable）中的index 键。如果index包含一个表格，Lua会在表格中查找相应的键。 Lua查找一个表元素时的规则，其实就是如下3个步骤: 1.在表中查找，如果找到，返回该元素，找不到则继续 2.判断该表是否有元表，如果没有元表，返回nil，有元表则继续。 3.判断元表有没有index方法，如果index方法为nil，则返回nil；如果index方法是一个表，则重复1、2、3；如果index方法是一个函数，则返回该函数的返回值。 __newindex 元方法 newindex 元方法用来对表更新，index则用来对表访问 。 当你给表的一个缺少的索引赋值，解释器就会查找__newindex 元方法：如果存在则调用这个函数而不进行赋值操作。 __call 元方法 __call 元方法在 Lua 调用一个值时调用。 __tostring 元方法 __tostring 元方法用于修改表的输出行为。 table存在两种行为：查询和修改（赋值），通过元方法index和newindex来改变table的这两种行为。 __index主要用于table的查询 table[key] 的访问过程，首先检查table表中是否存在key的字段，如果有则返回，否则检查是否有__index的元方法，没有返回nil,有则查找元方法。 __index元方法可以是一个函数，还可以是一个table。如果是一个函数，则以table和不存在的key作为参数方位该函数， 例如：__index = function(t,key) 如果是一个table时，就以相同的方式来访问这个table（即传入key访问元方法的table，如果存在则放回值，反之返回nil） 例如：__index = tab –此时会返回tab[key]的值 __index可以很好的实现具有默认值的table function setDefaultValues(t,d) ​ local mt = {__index = function() return d end} ​ setmetatable(t, mt) end tab = {x=10,y=20} print(tab.x ,tab.y,tab.z) --由于没有设置元方法则为nil setDefaultValues(tab,100) --设置默认值（设置__index元方法） print(tab.z) --检查到有__index的元方法则返回默认值 __newindex主要用于table的更新 当对table中不存在的索引赋值时，解释器就会查找__newindex元方法。如果有这个元方法，就调用这个元方法，而不是执行赋值。如果这个元方法是一个table，解释器就在table中进行赋值，而不是对原来的table。 local k = {} local mt = { ​ __newindex = k } local t = {} setmetatable(t, mt) print(&quot;赋值前：&quot;) for k,v in pairs(k) do ​ print(k ,v) end t[1] = 20 print(&quot;赋值后：t表中的值:&quot;) for k,v in pairs(t) do ​ print(k ,v) end print(&quot;赋值后：k表中的值:&quot;) for k,v in pairs(k) do ​ print(k ,v) end]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua易错点]]></title>
    <url>%2F2018%2F12%2F11%2Flua%E5%9D%91%E7%82%B9%2F</url>
    <content type="text"><![CDATA[table.remove 删除时导致的错？正确的删除方案：先记录要删除的表记录的k(位置)，然后反向遍历记录逐个删除。 删除1~10中的4,5,6,7,8. Table.remove 删除表时后面的元素会自动向前与移动导致隔一个删除一个. table长度table当字数组来用时获取的是正确的长度，当map来用时# 和table.getn获取的都是不是争取的长度，需要自行使用 for k，v in pairs获取长度. # 和 table.getn遇到v为nil时会返回长度. 字符串链接尽量使用table.concat连接字符串 使用运算符.. 每次拼接都需要申请新的空间，旧的result对应的空间会在某时刻被Lua的垃圾回收期GC，且随着result不断增长，越往后会开辟更多新的空间，并进行拷贝操作，产生更多需要被GC的空间，所以性能降低。 使用table.concat (table [, sep [, start [, end]]])函数 table.concat 底层拼接字符串的方式也是使用运算符.. ，但是其使用算法减少了使用运算符..的次数，减少了GC，从而提高效率 pairs 和 ipairs区别 pairs: 迭代 table，可以遍历表中所有的 key 可以返回 nil ipairs: 迭代数组，不能返回 nil,如果遇到 nil 则退出function定义的两种方式local function func() .. endlocal func = function() … end第一种方法定义是可以做递归的第二种是不行的，第二种定义必须待函数体定义之后才能调用自己 a and b or c 当b为nil时总是返回c?a and b :当a为真时返回b为假时返回a a or b: a为true返回a 为false返回b \&gt; true and true or 1 true \&gt; true and false or 1 1 \&gt; false and true or 1 1 \&gt; false and false or 1 1 \&gt; 2 and true or 1 true \&gt; (true and false) or 1 1 \&gt; (1 and false) or 1 1 \&gt; (a and {b} or {c})[1] nil \&gt; (1 and {false} or {2})[1] false \&gt; 解决方式：if else 另外就是(a and {b} or {c})[1] 弱引用表1.弱引用 元表 __mode字段来设置表k,v是弱引用，被弱引用table引用，垃圾回收时可回收，只要k,v被回收，整个条目会删除。 Lua采用了基于垃圾收集的内存管理机制，当某个table对象被存放在容器中，而容器的外部不再有任何变量引用该对象，对于这样的对象，Lua的垃圾收集器是不会清理的，因为容器对象仍然引用着他。见如下代码： 1 a = {} 2 key = {} 3 a[key] = 1 4 key = {} 5 a[key] = 2 6collectgarbage() 7for k,v inpairs(a) do 8print(v) 9end ​ 在执行垃圾收集之后，table a中的两个key都无法被清理，但是对value等于1的key而言，如果后面的逻辑不会遍历table a的话，那么我们就可以认为该对象内存泄露了。在Lua中提供了一种被称为弱引用table的机制，可以提示垃圾收集器，如果某个对象，如上面代码中的第一个table key，只是被弱引用table引用，那么在执行垃圾收集时可以将其清理。 ​ Lua中的弱引用表提供了3中弱引用模式，即key是弱引用、value是弱引用，以及key和value均是弱引用。不论是哪种类型的弱引用table，只要有一个key或value被回收，那么它们所在的整个条目都会从table中删除。 ​ 一个table的弱引用类型是通过其元表的__mode字段来决定的。如果该值为包含字符”k”，那么table就是key弱引用，如果包含”v”，则是value若引用，如果两个字符均存在，就是key/value弱引用。见如下代码： 1 a = {} 2 b = {__mode = &quot;k&quot;} 3setmetatable(a,b) 4 key = {} 5 a[key] = 1 6 key = {} 7 a[key] = 2 8collectgarbage() 9for k,v inpairs(a) do 10print(v) 11end 12--仅仅输出2 ​ 在上面的代码示例中，第一个key在被存放到table a之后，就被第二个key的定义所覆盖，因此它的唯一引用来自key弱引用表。事实上，这种机制在Java中也同样存在，Java在1.5之后的版本中也提供了一组弱引用容器，其语义和Lua的弱引用table相似。 ​ 最后需要说明的是，Lua中的弱引用表只是作用于table类型的变量，对于其他类型的变量，如数值和字符串等，弱引用表并不起任何作用。 尾递归什么是尾递归 尾递归的写法只是具备了使当前函数在调用下一个函数前把当前占有的栈销毁，但是会不会真的这样做，是要具体看编译器是否最终这样做。 什么是尾递归呢?(tail recursion), 顾名思议，就是一种“不一样的”递归，说到它的不一样，就得先说说一般的递归。对于一般的递归，比如下面的求阶乘，教科书上会告诉我们，如果这个函数调用的深度太深，很容易会有爆栈的危险。 // 先不考虑溢出问题 int func(int n) { if (n &lt;= 1) return 1; return (n * func(n-1)); } 原因很多人的都知道，让我们先回顾一下函数调用的大概过程： 1）调用开始前，调用方（或函数本身）会往栈上压相关的数据，参数，返回地址，局部变量等。 2）执行函数。 3）清理栈上相关的数据，返回。 因此，在函数 A 执行的时候，如果在第二步中，它又调用了另一个函数 B，B 又调用 C…. 栈就会不断地增长不断地装入数据，当这个调用链很深的时候，栈很容易就满 了，这就是一般递归函数所容易面临的大问题。 而尾递归在某些语言的实现上，能避免上述所说的问题，注意是某些语言上，尾递归本身并不能消除函数调用栈过长的问题，那什么是尾递归呢？在上面写的一般递归函数 func() 中，我们可以看到，func(n) 是依赖于 func(n-1) 的，func(n) 只有在得到 func(n-1) 的结果之后，才能计算它自己的返回值，因此理论上，在 func(n-1) 返回之前，func(n)，不能结束返回。因此func(n)就必须保留它在栈上的数据，直到func(n-1)先返回，而尾递归的实现则可以在编译器的帮助下，消除这个限制： // 先不考虑溢出 int tail_func(int n, int res) { if (n &lt;= 1) return res; return tail_func(n - 1, n * res); } // 像下面这样调用 tail_func(10000000000, 1); 从上可以看到尾递归把返回结果放到了调用的参数里。这个细小的变化导致，tail_func(n, res)不必像以前一样，非要等到拿到了tail_func(n-1, nres)的返回值，才能计算它自己的返回结果 – 它完全就等于tail_func(n-1, nres)的返回值。因此理论上：tail_func(n)在调用tail_func(n-1)前，完全就可以先销毁自己放在栈上的东西。 这就是为什么尾递归如果在得到编译器的帮助下，是完全可以避免爆栈的原因：每一个函数在调用下一个函数之前，都能做到先把当前自己占用的栈给先释放了，尾递归的调用链上可以做到只有一个函数在使用栈，因此可以无限地调用！ 所谓尾调用，就是一个函数返回另一个函数的返回值： function f() … return g() end 因为调用g()后，f()中不再执行任何代码，所以不需要保留f()的调用桟信息；Lua做了这样的优化，称为”尾调用消除”，g()返回后，控制点直接返回到调用f()的地方。 这种优化对尾递归非常有益，通常递归意味着调用桟的不断增长，甚至可能造成堆栈溢出；而尾递归提供了优化条件，编译器可以优化掉调用桟]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua实现continue]]></title>
    <url>%2F2018%2F12%2F11%2Flua%E5%AE%9E%E7%8E%B0continue%2F</url>
    <content type="text"><![CDATA[for i = 1， 10 do repeat if i == 5 then break end until true end for i= 1， 10 do while true do break end end 满足条件时会跳出repeat的内层循环，继续外层循环相当于continue.]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua用法]]></title>
    <url>%2F2018%2F12%2F11%2Flua%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[loadstring load从给定的字符串得到块(函数)。lua5.3使用load()替换loadstring(). 一般如下用法：assert(loadstring(script))()f = loadstring(&quot;a = 1&quot;)语义上相当于：f = loadstring(&quot;function() a = 1 end&quot;)复杂用法如下：下面是动态加载字符串，并执行，结果为一个table local script = &quot;localee={[0]={id=0,lv=5,text=&#39;yy&#39;},[1]={id=1,lv=3,text=&#39;zz&#39;}} return ee&quot; local tb=assert(loadstring(script))() print(tb[0].text) 下面是动态加载字符串，并执行，结果为方法 local addscript=&quot;function dadd(a,b) return a+b end&quot; assert(loadstring(addscript))() print(tostring(dadd(2,3))) local f = load(&quot;a=1+2&quot;) print(type(f)) --function loadfileloadfile 编译Lua外部代码块，但不会运行代码，将会以函数的形式返回编译结果.返回编译结果函数. local f = laodfile(&quot;a.lua&quot;) print(type(f)) --function dofiledofile 直接编译运行Lua外部代码块，并不返回任何结果。编译错误会返回nil. function dofile(filename) local func = assert(loadfile(filename)) func() end loadload (chunk [, chunkname [, mode [, env]]])加载一个代码块。如果 chunk 是一个字符串，代码块指这个字符串。 如果 chunk 是一个函数， load 不断地调用它获取代码块的片断。 每次对 chunk 的调用都必须返回一个字符串紧紧连接在上次调用的返回串之后。 当返回空串、nil、或是不返回值时，都表示代码块结束。 如果结果函数有上值， env 被设为第一个上值。 若不提供此参数，将全局环境替代它。chunkname 在错误消息和调试消息中，用于代码块的名字。字符串 mode 用于控制代码块是文本还是二进制（即预编译代码块）。 它可以是字符串 “b” （只能是二进制代码块）， “t” （只能是文本代码块）， 或 “bt” （可以是二进制也可以是文本）。 默认值为 “bt”。 _ENV引用一个叫 var 的自由名字在句法上都被翻译为 _ENV.var 。 此外，每个被编译的 Lua 代码块都会有一个外部的局部变量叫 _ENV。 这里特别指出，你可以定义一个新变量或指定一个参数叫这个名字。 当编译器在转译自由名字时所用到的 _ENV ， 指的是你的程序在那个点上可见的那个名为 _ENV 的变量被 _ENV 用于值的那张表被称为 环境。 Lua保有一个被称为 全局环境 特别环境。它被保存在 C 注册表的一个特别索引下。在 Lua 中，全局变量 _G 被初始化为这个值。 当 Lua 加载一个代码块，_ENV 这个上值的默认值就是这个全局环境。 因此，在默认情况下，Lua 代码中提及的自由名字都指的全局环境中的相关项 （它们也被称为 全局变量 ）。此外，所有的标准库都被加载入全局环境，一些函数也针对这个环境做操作。 你可以用 load （或 loadfile）加载代码块，并赋予它们不同的环境。 （在 C 里，当你加载一个代码块后，可以通过改变它的第一个上值来改变它的环境。） select如果 index 是个数字， 那么返回参数中第 index 个之后的部分； 负的数字会从后向前索引（-1 指最后一个参数）。 否则，index 必须是字符串 “#”， 此时 select 返回参数的个数。 do function foo(...) for i = 1, select(&#39;#&#39;, ...) do //get the count of the params local arg = select(i, ...);//select the param print(&quot;arg&quot;, arg); end end foo(1, 2, 3, 4); end nextnext (table [, index])允许程序遍历表的所有字段。它的第一个参数是一个表，它的第二个参数是该表的索引。接下来返回表及其关联值的一个索引。 local tee = {1, 3, 4, 6, 8} t = {3,7,10,17, pi=3.14159, banana=&quot;yellow&quot;} for key,value in next,t,nil do print(key,value) end function pairs (t) return next, t, nil end for k, v in pairs(t) do print(k, v) end pcallpcall (f [, arg1, ···]) 传入参数，以 保护模式 调用函数 f 。 这意味着 f 中的任何错误不会抛出； 取而代之的是，pcall 会将错误捕获到，并返回一个状态码。 第一个返回值是状态码（一个布尔量）， 当没有错误时，其为真。 此时，pcall 同样会在状态码后返回所有调用的结果。 在有错误时，pcall 返回 false 加错误消息。 local ret, msg = pcall(function(i) print(i) end, 33) xpcallxpcall (f, msgh [, arg1, ···])这个函数和 pcall 类似。 不过它可以额外设置一个消息处理器 msgh。 local function __TRACKBACK__(errmsg) local track_text = debug.traceback(tostring(errmsg), 6); print(track_text, &quot;LUA ERROR&quot;); return false; end local function trycall(func, ...) local args = { ... }; return xpcall(function() func(unpack(args)) end, __TRACKBACK__); end local function test(aaa) print(&quot;#&quot;..aaa) end trycall(test, nil) 多行文本使用[[ sun feng sunfeng ]] 定义多行文本。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua调用so]]></title>
    <url>%2F2018%2F12%2F11%2Flua%E8%B0%83%E7%94%A8so%2F</url>
    <content type="text"><![CDATA[lua5.1动态库c so#include &lt;stdio.h&gt; #include &quot;./src/lua.h&quot; #include &quot;./src/lualib.h&quot; #include &quot;./src/lauxlib.h&quot; static int add(lua_State *L) { int a,b,c; a = lua_tonumber(L,1); b = lua_tonumber(L,2); c = a+b; lua_pushnumber(L,c); printf(&quot;test hello!!!\r\n&quot;); return 1; } static const struct luaL_Reg lib[] = { {&quot;testadd&quot;, add}, {NULL,NULL} }; int luaopen_testlib_core(lua_State *L) // 注意这里的函数写法 { //luaL_register(L,&quot;testlib&quot;,lib); // 1 luaL_openlib(L,&quot;testlib&quot;,lib,0); // 2 return 1; } lua调用脚本require(&quot;testlib.core&quot;) // 注意这里的调用,和上面的函数写法是相关联的 c = testlib.testadd(15,25) print(&quot;The result is &quot;,c); lua5.3c sostatic int lnow(lua_State *L) { uint64_t ti = skynet_now(); lua_pushinteger(L, ti); return 1; } int luaopen_skynet_core(lua_State *L) { luaL_checkversion(L); luaL_Reg l[] = { { &quot;send&quot; , lsend }, { &quot;genid&quot;, lgenid }, { &quot;redirect&quot;, lredirect }, { &quot;command&quot; , lcommand }, { &quot;intcommand&quot;, lintcommand }, { &quot;error&quot;, lerror }, { &quot;tostring&quot;, ltostring }, { &quot;harbor&quot;, lharbor }, { &quot;pack&quot;, luaseri_pack }, { &quot;unpack&quot;, luaseri_unpack }, { &quot;packstring&quot;, lpackstring }, { &quot;trash&quot; , ltrash }, { &quot;callback&quot;, lcallback }, { &quot;now&quot;, lnow }, { NULL, NULL }, }; luaL_newlibtable(L, l); lua_getfield(L, LUA_REGISTRYINDEX, &quot;skynet_context&quot;); struct skynet_context *ctx = lua_touserdata(L,-1); if (ctx == NULL) { return luaL_error(L, &quot;Init skynet context first&quot;); } luaL_setfuncs(L,l,1); return 1; } 编译so直接local c = require &quot;skynet.core&quot;]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua模块定义]]></title>
    <url>%2F2018%2F12%2F11%2Flua%E6%A8%A1%E5%9D%97%E5%AE%9A%E4%B9%89%2F</url>
    <content type="text"><![CDATA[lua5.1中提供的module方法在lua5.3中已经放弃使用，推荐使用的模块儿定义方式如下 require table 方式定义模块 -- square.lua local _M = {} -- 局部的变量 _M._VERSION = &#39;1.0&#39; -- 模块版本 local mt = { __index = _M } function _M.new(self, width, height) return setmetatable({ width=width, height=height }, mt) end function _M.get_square(self) return self.width * self.height end function _M.get_circumference(self) return (self.width + self.height) * 2 end return _M 引用示例代码： local square = require &quot;square&quot; local s1 = square:new(1, 2) print(s1:get_square()) --output: 2 print(s1:get_circumference()) --output: 6 module 方式定义模块`module （“moduleA”) –相当于执行如下代码local name = “moduleA”local M = {}_G[name] = Mpackage.loaded[modname] = Msetfenv(1,M) –设置一个函数的环境当第一个参数为一个数字时，为1代表当前函数 module (…, package.seeall)t = {}function f() –todoend` module会导致当前环境压栈，module之后全局变量都不在可见。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua沙盒]]></title>
    <url>%2F2018%2F12%2F10%2Flua%E6%B2%99%E7%9B%92%2F</url>
    <content type="text"><![CDATA[背景知识Lua 给我的感觉是：各种内置函数和标准库的存在感都是比较强的。如果执行这句： for name in pairs(_G) do print(_G) end就会把各种环境中已存在名称的打印出来： 全局变量：比如字符串 _VERSION。内置函数：比如 print、tonumber、dofile 之类。模块名称：比如 string、io、coroutine 之类。这里的全局变量 _G 就是存放环境的表（于是会有 _G 中存在着 _G._G 的递归）。 于是，平时对于全局变量的访问就可以等同于对 _G 表进行索引： value = _G[varname] –&gt; value = varname_G[varname] = value –&gt; varname = value 改变函数的环境函数的上下文环境可以通过 setfenv(f, table) 函数改变，其中 table 是新的环境表，f 表示需要被改变环境的函数。如果 f 是数字，则将其视为堆栈层级（Stack Level），从而指明函数（1 为当前函数，2 为上一级函数）： a = 3 -- 全局变量 a setfenv(1, {}) -- 将当前函数的环境表改为空表 print(a) -- 出错，因为当前环境表中 print 已经不存在了 没错，不仅是 a 不存在，连 print 都一块儿不存在了。如果需要引用以前的 print 则需要在新的环境表中放入线索： a = 3 setfenv(1, { g = _G }) g.print(a) -- 输出 nil g.print(g.a) -- 输出 3 沙盒于是，出于安全或者改变一些内置函数行为的目的，需要在执行 Lua 代码时改变其环境时便可以使用 setfenv 函数。仅将你认为安全的函数或者新的实现加入新环境表中： local env = {} -- 沙盒环境表，按需要添入允许的函数 function run_sandbox(code) local func, message = loadstring(code) if not func then return nil, message end -- 传入代码本身错误 setfenv(func, env) return pcall(func) end Lua 5.2 的 _ENV 变量Lua 5.2 中所有对全局变量 var 的访问都会在语法上翻译为 _ENV.var。而 _ENV 本身被认为是处于当前块外的一个局部变量。（于是只要你自己定义一个名为 _ENV 的变量，就自动成为了其后代码所处的「环境」（enviroment）。另有一个「全局环境」（global enviroment）的概念，指初始的 _G 表。） Lua 的作者之一 Roberto Ierusalimschy 同志在介绍 Lua 5.2 时说： the new scheme, with _ENV, allows the main benefit of setfenv with a little more than syntactic sugar. 就我的理解来说，优点就是原先虚无缥缈只能通过 setfenv、getfenv 访问的所谓「环境」终于实体化为一个始终存在的变量 _ENV 了。 于是以下两个函数内容大致是一样的： -- Lua 5.1 function foobar() setfenv(1, {}) -- code here end -- Lua 5.2 function foobar() local _ENV = {} -- code here end 而更进一步的是，5.2 中对 load 函数作出了修改。（包括但不限于 :)）合并了 loadstring 功能，并可以在参数中指定所使用的环境表： local func, message = load(code, nil, &quot;t&quot;, env) setfenv当我们在全局环境中定义变量时经常会有命名冲突，尤其是在使用一些库的时候，变量声明可能会发生覆盖，这时候就需要一个非全局的环境来解决这问题。setfenv函数可以满足我们的需求。 setfenv(f, table)：设置一个函数的环境 （1）当第一个参数为一个函数时，表示设置该函数的环境 （2）当第一个参数为一个数字时，为1代表当前函数，2代表调用自己的函数，3代表调用自己的函数的函数，以此类推 所谓函数的环境，其实一个环境就是一个表，该函数被限定为只能访问该表中的域，或在函数体内自己定义的变量。下面这个例子，设定当前函数的环境为一个空表，那么在设定执行以后，来自全局的print函数将不可见，所以调用会失败。 – 一个环境就是一个表，该表记录了新环境能够访问的全部域newfenv = {}setfenv(1, newfenv)print(1) – attempt to call global `print’ (a nil value) 我们可以这样继承已有的域： a = 10 newfenv = {_G = _G} setfenv(1, newfenv) _G.print(1) -- 1 _G.print(_G.a) -- 10 _G.print(a) -- nil 注意此处是nil，新环境没有a域，但可以通过_G.a访问_G的a域 可以看到，新环境中可以访问_G，但有一点就是_G中的所有函数必须手动调用，这样其实很不方便。我们可以使用metatable来对上述代码进行改进： -- 任何赋值操作都对新表进行，不用担心误操作修改了全局变量表。另外，你仍然可以通过_G修改全局变量： newfenv = {} setmetatable(newfenv, {__index = _G}) setfenv(1, newfenv) print(1) -- 1 新环境直接继承了全局环境的所有域，好处：可以不需要通过_G来手动调用 这样，当访问到函数中不存在的变量时，会自动在_G中查找。对于当前函数和_G都存在的变量，可以通过是否用_G显示调用来区分，比如如果有两个a，那么_G.a表示继承来的，a就是当前函数环境的。 另外，可以通过getfenv(f)函数查看函数所处的环境，默认会返回全局环境_G。]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cocos2dx游戏内存优化]]></title>
    <url>%2F2018%2F12%2F10%2Fcocos2dx%E6%B8%B8%E6%88%8F%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[纹理消耗了大量内存在大部分情况下，是纹理（textures）消耗了游戏程序大量的内存。因此，纹理是我们首要考虑优化的对象 纹理加载cocos2d里面纹理加载分为两个阶段：从图片文件中创建一个Image对象;以这个创建好的Image对象来创建Texture2D对象.加载纹理的文件io操作和纹理创建都是耗时的，需要避免一帧之内加载大量图片资源.因为不仅会导致卡顿还会导致内存过高.最好的方式是多线程加载即异步加载. 使用JPG图片？cocos2d使用JPG纹理的时候有一个问题,因为JPG纹理在加载的时候，会实时地转化为PNG格式的纹理，而且JPG纹理将消耗三倍于本身内存占用大小的内存。jpg不论在加载速度和内存消耗方面都很差。所以，千万不要大量使用JPG大图. 重视文件图片大小图片文件大小和纹理内存占用是两码事，图片文件大多是压缩过的，它们被使用的话必须先解压缩，然后才能会GPU所处理，变成我们熟知的纹理。一个2048*2048的png图片，采用32位颜色深度编码，那么它在磁盘上占用空间只有2MB。但是，如果变成纹理，它将消耗16MB的内存！ 使用16-bit纹理最快速地减少纹理内存占用的办法就是把它们作为16位颜色深度的纹理来加载。cocos2d默认的纹理像素格式是32位颜色深度。如果把颜色深度减半，那么内存消耗也就可以减少一半。并且这还会带来渲染效率的提升，大约提高10%。 你可以使用Texture2D对象的类方法setDefaultAlphaPixelFormat来更改默认的纹理像素格式，代码如下： [Texture2D setDefaultAlphaPixelFormat:kCCTexture2DPixelFormat_RGB5A1]; 这里有个问题：首先，纹理像素格式的改变会影响后面加载的所有纹理。因此，如果你想后面加载纹理使用不同的像素格式的话，必须再调用此方法，并且重新设置一遍像素格式。 其次，如果你的CCTexture2D设置的像素格式与图片本身的像素格式不匹配的话，就会导致显示严重失真。比如颜色不对，或者透明度不对等等。 有哪些比较有用的纹理像素格式呢?generate 32-bit textures: kCCTexture2DPixelFormat_RGBA8888 (default) generate 16-bit textures: kCCTexture2DPixelFormat_RGBA4444 generate 16-bit textures: kCCTexture2DPixelFormat_RGB5A1 generate 16-bit textures: kCCTexture2DPixelFormat_RGB565 (no alpha) RGBA8888是默认的格式。对于16位的纹理来说，使用RGB565可以获得最佳颜色质量，因为16位全部用来显示颜色：总共有65536总颜色值。但是，这里有个缺点，除非图片是矩形的，并且没有透明像素。所以RBG565格式比较适合背景图片和一些矩形的用户控件。 RGB5A1格式使用一位颜色来表示alpha通道，因此图片可以拥有透明区域。只是，1位似乎有点不够用，它只能表示32768种可用颜色值。而且图片要么只能全部是透明像素，或者全部是不透明的像素。因为一位的alpha通道的缘故，所以没有中间值。但是你可以使用fade in/out动作来改变纹理的opacity属性。 如果你的图片包含有半透明的区域，那么RBGA4444格式很有用。它允许每一个像素值有127个alpha值，因此透明效率与RGBA8888格式的纹理差别不是很大。但是，由于颜色总量减少至4096，所以，RBGA4444是16位图片格式里面颜色质量最差的。 现在，你可以得到16位纹理的不足之处了：它由于颜色总量的减少，有一些图片显示起来可能会失真 使16位纹理看起来更棒幸运的是，我们有TexturePacker.（简称TP） TP有一个特性叫做“抖动”，它可以使得原本由于颜色数量减少而产生的失真问题得到改善。 特别是在拥有Retina显示的像素密度下，你几乎看不出16位与32位的纹理之间的显示差别。当然，前提是你需要采用“抖动”算法。 使用NPOT纹理NOPT是“non power of two”的缩写，译作“不是2的幂”。NPOT stands for “non power of two”.cocos2dx它默认是支持NPOT的。 如果纹理图集（texture atlas）使用NPOT的纹理，它将有一个具大的优势：它允许TP更好地压缩纹理。因此，我们会更少地浪费纹理图集的空白区域。而且，这样的纹理在加载的时候，会少使用1%到49%左右的内存。而且你可以使用TP强制生成NPOT的纹理。(你只需要勾选“allow free size”即可） 默认使用PVR格式的纹理TP让你可以创建PVR格式的纹理。除了PVR纹理支持NPOT外，它们不仅可以不是2的幂，而且还可以不是方形的。 PVR是最灵活的纹理文件格式。除了支持标准的未压缩的RGB图片格式外，不支持有损压缩的pvrtc格式。另外，未压缩的pvr格式的纹理的内存消耗非常地低。不像png图片那样要消耗2倍于本身内存占用大小的内存，pvr格式只需要消耗纹理本身内存大小再加上一点点处理该图片格式的内存大小。 pvr格式的一个缺点就是，你不能在Mac上面打开查看。但是，如果你安装了TP的话，就可以使用TP自带的pvr图片浏览器来浏览pvr格式的图片了. 使用PVR格式的文件几乎没有缺点。此外，它还可以极大地提高加载速度，后面我会解释到。 使用pvr.ccz文件格式在三种可选用的pvr文件格式中，优先选择pvr.ccz格式。它是专门为cocos2d和TP设计的。在TP里面，这是它生成的最小的pvr文件。而且pvr.ccz格式比其它任何文件格式的加载速度都要快。 当在cocos2d里面使用pvr格式的纹理时，只使用pvr.ccz格式，不要使用其它格式！因为它加载速度超快，而且加载的时候使用更少的内存！ 当视觉察觉不出来的时候，可以考虑使用PVRTC压缩PVR纹理支持PVRTC纹理压缩格式。它主要是采用的有损压缩。如果拿PVRTC图片与JPG图片作对比的话，它只有JPG图片中等质量，但是，最大的好处是可以不用在内存里面解压缩纹理。 这里把32位的png图片（左边）与最佳质量的PVRTC4（4位）图片（点击图片查看完整的大小）作对比： 注意，在一些高对比度的地方，明显有一些瑕疵。有颜色梯度的地方看起来还好一点。 PVRTC肯定不是大部分游戏想要采用的纹理格式。但是，它们对于粒子效果来说，非常适用。因为那些小的粒子在不停地移动、旋转、缩放，所以你很难看出一些视觉瑕疵。 PVRTC压缩图片格式TP提供的PVR格式不仅有上面两种，还包括TC2和TC4这两种没有alpha通道的格式。 这里的alpha和16位纹理的alpha是一样的。没有alpha通道意味着图片里面没有透明像素，但是，更多的颜色位会用来表示颜色，那么颜色质量看起来也会更好一些。 有时候，PVRTC图片格式指的是使用4位或者2位颜色值 ，但是，并不完全是那样。PVRTC图片格式可以编码更多的颜色值。 预先加载所有的纹理定要预先加载所有的纹理，你可以在第一个loading场景的时候就全部加载进来。 这样做最大的好处在于，你的游戏体验会表现得非常平滑，而且你不需要再担心资源的加载和卸载问题了。 这样也使得你可以让每一个纹理都使用合适的纹理像素格式，而且可以更方便地找出其它与纹理无关的内存问题。因为如果与纹理有关，那么在第一次加载所有的纹理的时候，这个问题就会暴露出来的。如果所有的纹理都加载完毕，这时候再出现内存问题，那么肯定就与纹理无关了，而是其它的问题了。 按照纹理size从大到小的顺序加载纹理由于加载纹理时额外的内存消耗问题，所以，采用按纹理size从大到小的方式来加载纹理是一个最佳实践。 假设，你有一个占内存16MB的纹理和四个占用内存4MB的纹理。如果你首先加载4MB的纹理，这个程序将会使用16MB的内存，而当它加载第四张纹理的时候，短时间内会飙到20MB。这时，你要加载16MB的那个纹理了，内存会马上飙到48MB（44 + 162），然后再降到32MB（4*4 + 16）。 但是，反过来，你先加载16MB的纹理，然后短时候内飙到32MB。然后又降到16MB。这时候，你再依次加载剩下的4个4MB的，这时，最多会彪到（43 + 42 + 16=36）MB。 在这两种情况下，内存的峰值使用相差12MB，要知道，可能就是这12MB会断送你的游戏进程的小命哦！ 避免在收到内存警告消息的时候清除缓存纹理已经全部在Loading场景里面加载完毕了，这时候，内存警告发生了，然后cocos2d就会把没有使用的纹理从缓存中释放掉。 你刚刚把所有的纹理都加载进来，还没有进入任何一个场景中（此时所有的纹理都被当作“unused”），但是马上被全部从texture cache中移除出去。可是，你又需要在其它场景中使用它们。在loading场景完了之后进入下一个场景的时候很卡的原因了。cocos2dx 在收到内存警告的时候会自动清理缓存. 理解在什么时候、在哪里去清除缓存不要随机清除缓存，也可以心想着释放一些内存而去移除没有使用的纹理。那不是好的代码设计。有时候，它甚至会增加加载次数，并多次引发“间歇内存飙高”。分析你的程序的内存使用，看看内存里面到底有什么，以及什么应该被清除，然后只清除该清除的。 你可以使用dumpCachedTextureInfo方法来观察哪些纹理被缓存了： [[TextureCache] dumpCachedTextureInfo]; cocos2d: &quot;ingamescorefont.png&quot; rc=9 name=ingamescorefont-hd.png id=13 128 x 64 @ 32 bpp =&gt; 32 KB cocos2d: &quot;ui.png&quot; rc=15 name=ui-hd.png id=5 2048 x 2048 @ 16 bpp =&gt; 8192 KB cocos2d: &quot;ui-ingame.png&quot; rc=36 name=ui-ingame-hd.png id=8 1024 x 1024 @ 16 bpp =&gt; 2048 KB cocos2d: &quot;digits.png&quot; rc=13 name=digits-hd.png id=10 512 x 64 @ 16 bpp =&gt; 64 KB cocos2d: &quot;hilfe.png&quot; rc=27 name=hilfe-hd.png id=6 1024 x 2048 @ 32 bpp =&gt; 8192 KB cocos2d: &quot;settings.png&quot; rc=8 name=settings-hd.png id=9 1024 x 1024 @ 16 bpp =&gt; 2048 KB cocos2d: &quot;blitz_kurz.png&quot; rc=1 name=(null) id=12 50 x 50 @ 32 bpp =&gt; 9 KB cocos2d: &quot;gameover.png&quot; rc=8 name=gameover-hd.png id=7 1024 x 2048 @ 32 bpp =&gt; 8192 KB cocos2d: &quot;home.png&quot; rc=32 name=home-hd.png id=4 2048 x 2048 @ 16 bpp =&gt; 8192 KB cocos2d: &quot;particleTexture.png&quot; rc=2 name=(null) id=11 87 x 65 @ 32 bpp =&gt; 22 KB cocos2d: &quot;stern.png&quot; rc=2 name=(null) id=2 87 x 65 @ 32 bpp =&gt; 22 KB cocos2d: &quot;clownmenu.png&quot; rc=60 name=clownmenu-hd.png id=1 1024 x 2048 @ 32 bpp =&gt; 8192 KB cocos2d: CCTextureCache dumpDebugInfo: 13 textures using 60.1 MB （纹理总共占用的内存大小！！！） 上面包含了非常多有用的信息。纹理的大小、颜色深度（bpp）和每一个被缓存的纹理在内存中所占用大小等。这里的“rc”代表纹理的“引用计数”。如果这个引用计数等于1或2的话，那么意味着，这个纹理当前可能不会需要使用了，此时，你可以放心地把它从纹理cache中移除出去。 你只移除你知道在当前场景下不太可能会被使用的纹理（即上面介绍的引用计数为1或2的情况），这是一个明智的做法。另外，只移除那些占用内存大的纹理。如果一个纹理只占几个kb的内存，其它移不移除都没什么太大的影响。 SpriteFrames retain textures上面提到的例子中，纹理的引用计数可能有点让人看不懂。你会发现，纹理集有很高的retain count，即使你知道这些纹理集中的纹理当前并没有被使用。 你可能忽略了一件事：SprteFrame会retain它的纹理。因此，如果你使用了纹理集，你要完全移除它不是那么容易。因为，由这个纹理集产生的sprite frame还是保留在内存中。所以，你必须调用SpriteFrameCache的removeSpriteFramesFromTexture方法，能彻底清除纹理缓存中的纹理集。 [[CCSpriteFrameCache sharedSpriteFrameCache] removeSpriteFramesFromTexture:uncachedTexture]; 你也可以使用 removeSpriteFramesFromFile，并指定一个纹理集的.plist文件来清除缓存起来的精灵帧（spriteframes）. 你可以清除任何缓存（比如animation,sprite frames等），但是请不要轻易清除纹理缓存cocos2d有许多缓存类，比如纹理缓存、精灵帧缓存，动画缓存等。 当然，如果你想从内存中移除一个纹理，你也必须移除与之相关的精灵帧(因为精灵帧会retain纹理）。 例外：检查声音文件的内存使用！声音文件会被缓存起来，然后可以重复播放而不会被中断。由于声音文件一般比较大，特别是，我看到有一些开发者使用没有压缩的声音文件作为游戏的背景音乐，而这些背景音乐文件非常大，它们通常会造成大量的内存消耗。 请使用MP3格式的声音文件。因为使用没有压缩的声音文件既浪费内存又占用程序大小。当你加载完一些游戏音效时，在不需要的时候，记得要卸载掉。 如何避免缓存特定的纹理如果你有一个纹理，你确实不想缓存起来，那怎么办呢？比如，在初始的加载场景中的图片，或者那些用户很少会在意的图片–比如你的非常牛比的致谢场景的图片。 经常容易被误解的一点是，一个纹理显示出来了，那么它就被缓存起来了。如果你从缓存中移除此纹理，那么此时你再移除精灵就会程序崩溃。这个理解不正确。 TextureCache只不过是对纹理再添加了一次retain函数的调用，这样，当没有其它对象（比如sprite）持有纹理的引用的时候，纹理仍然会存在内存之间。基于这一点，我们可以立马从缓存中移除出去，这样，当纹理不存需要的时候，马上就会从内存中释放掉。如下代码所示： bg = [Sprite spriteWithFile:@&quot;introBG.png&quot;]; // don&#39;t cache this texture: [[TextureCache ] removeTextureForKey:@&quot;introBG.png&quot;]; 当TextureCache中移除一个纹理的时候，cocos2d下一次在调用spriteWithFile的时候，还是会再加载该纹理的–不管是否有没有一张名字一样的图片正在被其它精灵所使用。因此，如果你不够细心的话，你有可能最后会在内存中加载两张重复的纹理。 使用一个Loading 场景如果你不能预先加载所有的纹理的话，你可以使用一个loading场景，同时显示一个动画来表明加载的进度。这样可以在进入下一个场景之前，让前面一个场景销毁，同时释放它所占用的内存资源。 实现起来非常简单。这个loading场景调度一个selector，然后每一帧（或者0.1秒也可以）执行一个函数，比如update。除非你前面一个场景有内存泄漏，否则的话，每一次update函数执行的时候，都会把一些引用计数为0的内存资源释放掉。在这个update方法里面，你可以创建新的场景。 这样极大地避免了“间歇性内存飙高”的问题，可以极大地减小内存压力。 在后台加载纹理TextureCache类还支持异步加载资源的功能，利用addImageAsync方法。你可以很方面地给addImageAsync方法添加一个回调方法，这样，当纹理异步加载结束的时候，可以得到通知。 必须等待一个资源加载完毕。否则的话，由于“间歇性内存飙高”，可能会引发下列问题： 1) 程序崩溃2) 纹理被加载两次！因为异步加载并不能保证加载顺序。 减少你的程序的大小把纹理的颜色位深度减少到16位，不仅可以减少内存压力，还可以有效地减少程序的体积。但是，我们还有其它方法可以更进一步地减少程序的大小。 TexturePacker PNG 图片优化如果你有某些原因，让你坚持要使用PNG文件格式而不是我之前极力向你推荐的pvr.ccz文件格式，那么TexturePacker有一个选项，叫做“Png Opt Level”(Png优化级别)，可以帮助我们减少png文件的大小 注意，在xcode里面有一项设置，你可能会把它忽略掉。你需要关闭”Compress PNG files”开关，因为这个选项有可能会使你的png图片膨胀。xcode会在png文件打包进程序的时候运行自带的png优化程序。所以，有可能会使我们先前使用TP优化过的png图片再次膨胀。因此，再次确保这个选项已关闭！ 不过即使你没有禁用此选项，你的程序大小还是会有所减小。因为，你有可能使用一些没有被TP优化过的png图片。 检查你的程序在App Store 里面的大小在Xcode里面，运行Archive build（在菜单中选择Product-&gt;Archive）。当build成功的时候，Xcode的Organizer窗口会打开，然后你会看到一个“Estimate Size”（评估大小）的按钮，可以用来估算你的应用程序大小： 移除未使用的资源文件在开发游戏的过程中，你会经常添加、移除和替换游戏资源。所以，你可能会因为某些原因，忘记移除一些不用的图片资源。所以，你需要额外注意把它们都从项目中移除出去，至少要从程序的target中出去。对于android 的so而言可以做一些选择，针对多种cpu架构可以选择一个. 减少声音文件大小有时候，我们也会忽视这个问题。如果你不考虑声音文件的格式，不管是就内存的使用还是程序的大小而言，都是一种极大的浪费。下面是一些方法可以用来减少声音文件的大小。 立体声道变单声道 – 你的mp3文件可以采用立体声，但是，这样做值得吗？如果你听不出来差别的话，建议还是采用单一声道。这样可以把文件大小和内存使用都减少一半。 MP3 比特率 –在iOS设备上面，任何比特率大于192kbps的声音都是浪费。你可以尽量采用低的比特率来获得最好的音质效果，这是一个折中。一般来说，96到128kbps对于mp3文件来说够用了。 采样率 – 大部分的声音文件使用11，22，44，或者48kHz采样率。采样率越低，声音文件越小。但是，这样声音质量也会越低。44kHz已经达到了CD的音质了，而48kHz会更好（这个差别只有调音师才可以听出来） 在大部分情况下，44kHz或者更高的比特率都有点浪费。所以，可以尝试下减小采样率（在Audacity里面：Tarck-&gt;Resample）。不要只是修改采样率，因为这样会改变声音文件的音高。 Streaming MP3 Filesmp3文件的播放，首先是加载到内存中，然后解码为未压缩的声音buffer，最后再播放。 就我目前所知，CocosDenshion的SimpleAudioEngine的playBackgoundMusic是流式播放mp3文件的。流试处理有两个优点：1.更小的内存足迹。2.解码mp3文件采用ios硬件，而不是cpu。但是，硬件一次只能解码一个文件，如果同时播放多个，那么只有一个采用的是硬件解码，其它的都是软件解码。 减少Tilemap大小许多开发者没有注意到，tilemap大小太大会消耗大量内存。假设你有一个1000*1000的tilemap，这个大概要消耗1M的内存–如果每一个tile消耗一个字节的内存的话。然而，如果每一个tile大概消耗64个字节的话，那么这个tilemap就会消耗60MB内存。我的天啊！ 除了写一个更优的tilemap渲染器以外，我们唯一可以做的就是减少tilemap的大小了，也可以把地图一分为二。]]></content>
      <categories>
        <category>cocos2dx</category>
      </categories>
      <tags>
        <tag>cocos2dx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua表访问跟踪]]></title>
    <url>%2F2018%2F12%2F05%2Flua%E8%A1%A8%E8%AE%BF%E9%97%AE%E8%B7%9F%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[当访问一个 table 或者更新 table 中的某个元素时，lua 首先会在 table 查找是否存在该元素，如果没有，就会查找 table 是否存在 index(访问) 或者 newindex(更新) 原方法。以访问为例，首先在 table 中查找某个字段，如果不存在，解释器会去查找 index 这个原方法，如果仍然没有，返回 nil。所以说，index 和 __newindex 是在 table 中没有所需访问的 index 时才发挥作用的。 根据上面这种思路，如果我们想跟踪一个 table 的操作行为，那么需要一个空表，每次对这个空表操作的时候，就会使用 index 或者 newindex 这些元方法，在元方法中对原始 table 进行访问和操作，并打印跟踪信息。而之前创建的那个空表，就是代理。 --------------------------------------------- print &quot;跟踪单个表&quot; local _t = {} local mt = { __newindex = function(t, name, value) print(&quot;__newindex&quot;, name, value) --rawset(_t, name, value) --原始访问 不访问原表 _t[name] = value end, __index = function(t, name) print(&quot;__index&quot;, name, value) --return rawget(_t, name) --原始访问 不访问原表 return _t[name] end } --a.__index = a local a = {} setmetatable(a, mt) a.x = 1 print(a.x) --------------------------------------------- print &quot;跟踪多个表&quot; local index = {} -- 创建私有索引，即原表在代理表中特殊字段 local mt = { __index = function (t, k) print(&quot;__index &quot; .. tostring(k)) return t[index][k] end, __newindex = function (t, k, v) print(&quot;__newindex &quot; .. tostring(k) .. &quot; to &quot; .. tostring(v)) t[index][k] = v end } function track (t) local proxy = {} proxy[index] = t setmetatable(proxy, mt) return proxy end local ori_table = {} --在其他地方创建的原表，对他进行跟踪 local _o = track(ori_table) _o[2] = &quot;lua&quot; print(_o[2])]]></content>
      <categories>
        <category>lua</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git重点用法]]></title>
    <url>%2F2018%2F12%2F05%2Fgit%E9%87%8D%E7%82%B9%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[流程 Workspace：工作区Index / Stage：暂存区Repository：仓库区（或本地仓库）Remote：远程仓库 基本操作 放入暂存区git add .git add file 提交到仓库git commit -m &#39;log&#39; 撤销工作区修改git checkout -- filegit checkout . 暂存区回退到工作区git reset HEAD file Reset回退commit回滚commit,工作区暂存区也改变git reset --hard commitid只回滚commit,工作区暂存区代码没有改变git reset --soft commitid回滚commit,暂存区改变,工作区不变git reset -mixed commitid 等同 git reset commitid revert回退commit git revert commit 但是会生成一次新的提交，需要填写提交注释，以前的历史记录都在. 而reset是指将HEAD指针指到指定提交,历史记录中不会出现放弃的提交记录. commit id查看git loggit reflog git pushgit push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;推送本地master分支到远程origin主机的master分支，后者不存在就创建git push origin master 省略了远程分支名 git pullgit pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;远程主机origin的master分支拉取过来，与本地的brantest分支合并:git pull origin master:brantest将远程origin主机的master分支拉取过来和本地的当前分支进行合并git pull origin master 远程操作 本地代码回滚到commitidgit reset --hard commitid 远程代码回回滚方法1：回滚后强制推送本地到远程git reset --hard commitidgit push origin branch -f方法2：且分支在分支上reset然后删除远程分支，使用本地分支重新远程分支git checkout the_branch git branch bk git pull git reset --hard th_commit_id git push origin :the_branch 删除远程then_branch git push origin the_branch 特殊操作 删除某次提交 git rebase -i commitid^ 在命令编辑里边把某次提交之前的内容改为drop.退出交互模式,就会删除相应commit.之后强制推送就ok. 修改某次提交 git rebase -i commitid^ 在编辑框中把需要修改的某次提交所在commit之前的pick改为edit然后保存退出.之后做出修改,完成之后执行如下命令： git add . git commit --amend git rebase --continue 子仓库主要用于工程中以来的第三方库，第三方库是独立的git仓库可以自行管理. 添加submodule git submodule add 仓库地址 localpath 会在.gitmodules和.git/config中添加submodule路径和对应的仓库库地址 clone父仓库之后更新子仓库 git submodule init git submodule update submodule修改后再localpath中 add commit push 删除submodule 删除.gitmodules和.git.config中的submodule信息;git rm –cached localpath. 合并代码 git merge $ git merge issueFix 如果没有冲突的话，merge完成。有冲突的话，git会提示那个文件中有冲突，比如有如下冲突： &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD:test.c printf (“test1″); ======= printf (“test2″); >&gt;&gt;&gt;&gt;&gt;&gt; issueFix:test.c 可以看到 ======= 隔开的上半部分，是 HEAD（即 master 分支，在运行 merge 命令时检出的分支）中的内容，下半部分是在 issueFix 分支中的内容。解决冲突的办法无非是二者选其一或者由你亲自整合到一起。比如你可以通过把这段内容替换为下面这样来解决： printf (“test2″); 这个解决方案各采纳了两个分支中的一部分内容，而且删除了 &lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，和&gt;&gt;&gt;&gt;&gt;&gt;&gt; 这些行。在解决了所有文件里的所有冲突后，运行 git add 将把它们标记为已解决（resolved）。 分支操作 创建分支 git branch bname 切换分支 git checkout bname 创建并切分支 git checkout -b bname git checkout -b 本地分支名x origin/远程分支名x git checkout -b dev origin/dev 远程分支dev切分支到本地dev分支 查看分支 git branch -av]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cocos2dx性能优化]]></title>
    <url>%2F2018%2F12%2F03%2Fcocos2dx%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[游戏性能应该在设计编码时就需要认真对待,在按照常规处理之后需要使用工具查找游戏性能瓶颈，之后针对处理. 主要的性能问题所在基本是GPU,CPU.经常涉及到游戏逻辑优化,优化效果的指标：帧率、内存、drawcall. 查找 GPU 性能瓶颈的工具 使用 Xcode OpenGL ES Profiler。 文档链接地址 如果你想 profiling 特定 GPU 的移动设备的图形性能，我们可以使用这些 GPU 制造商提供的工具： 对于 ARM Mali GPU，可以使用 mali graphics debugger: http://malideveloper.arm.com/resources/tools/mali-graphics-debugger/ 对于 Imagination PowerVR GPU，可以使用 PVRTune: https://community.imgtec.com/developers/powervr/tools/pvrtune/ 对于 Qualcomm Adreno GPU，可以使用 adreno GPU profiler: https://developer.qualcomm.com/software/adreno-gpu-profiler 使用工具查看图形渲染管线哪个阶段遇到瓶颈了，是顶点处理阶段，还是像素着色阶段。 查找 CPU 性能瓶颈的工具 Mac 平台可以使用 Xcode 的 Time Profiler 工具： https://developer.apple.com/library/ios/documentation/DeveloperTools/Conceptual/InstrumentsUserGuide/MeasuringCPUUse.html Windows 平台可以使用 Visual Studio 的 CPU profiler： https://blogs.msdn.microsoft.com/visualstudioalm/2015/10/29/profile-your-cpu-in-the-debugger-in-visual-studio-2015/ Cocos Creator 的用户，可以使用 Chrome 自带的 timeline 工具和 CPU profile 工具。 熟悉你的移动设备和你使用的游戏引擎熟悉你的移动设备使用的 GPU 和 CPU 的型号， Android 手机可以安装一个应用“GPU-Z”可以非常方便地查看到这些信息，而到目前为止iOS 设备统一使用的都是 PowerVR 的 GPU。如果你在测试游戏的过程中，发现其它手机都没有问题，但是某些具有同种类型的GPU 的设备性能表现都不佳，此时你可能需要留意一下针对特定 GPU 的优化技巧了. 同样的，了解你所使用的游戏引擎的局限也是非常重要的。你需要清楚地知道你所使用的游戏引擎是如何组织图形渲染命令的，这些命令又是如何处理 Batch Draw 的。以及，我们需要如何组织我们的纹理和游戏节点对象，这样才能最大限度地利用引擎提供的自动批处理功能。 如果你知道这些内容，那么你就可以避免一些常见的性能瓶颈。 常见的优化技巧 对于资源在能满足效果的前提下需要使用省资源和计算的方式实现 例如像素格式为RGBA4444可以达到效果就不要使用RGBA8888;不带通道的图片使用jpg而非png;使用压缩纹理和多级纹理;声音可以采纳较低采样率和单通道;使用九宫图等 关于CPU瓶颈一般跟Draw call 数量和你的游戏循环的复杂度相关 降低你的游戏的 Draw call 数量，最大限度地利用批次渲染来减少 Draw call 数量。 Cocos2d-x 3.x 包含了自动批处理功能，但是它需要你合图，并且生成的图形渲染命令必须相邻，且有相同的 material id。 对于游戏中出现的大量对象,可以使用对象缓存池来避免对象生成的消耗的时间 对于外部资源例如纹理声音文字等,尽量采用预加载避免游戏循环中出现大量IO操作 对于复杂UI的实现如listview等,里面重复的item可以使用clone的方法 避免在游戏循环做复杂运算,对于系统更新可以分系统选择不同的更新频率,特别是AI有些事不用每帧更新。 GPU 瓶颈通常局限于Overdraw和 Bandwidth Overdraw 这个问题会导致你的 GPU 很容易碰到带宽的瓶颈,从而降低你的图形性能.所谓 Overdraw，指的是在图形渲染管线中,很多像素的着色对于最终显示在屏幕上的颜色没有帮助,这些多余的计算和处理是浪费的，最重要的就是浪费带宽，因为它们需要从主存中采样纹理坐标。 Cocos2d-x 引擎总是按照从后往前的顺序去提交图形渲染命令的，因为在 2D 里面，大量的图片都是带有透明像素的，为了保证 blending 的正确性，就必须保持这种顺序的渲染命令提交。即使按照这种顺序去提交渲染命令，PowerVR 的 HSR 也可以在片断着色之前剔除掉不需要计算的像素。这也是为什么同样的 Cocos2d-x 游戏在很垃圾的 iPod 上面性能也不错，但是在某些 Android 旗舰机上面性能却表现得一团糟的原因。 注意: 通过使用工具， 预先将 2D 图片三角化，可以提高 Fillrate。具体做法可以参考 TexturePacker 作者写的文章： https://www.codeandweb.com/texturepacker/tutorials/cocos2d-x-performance-optimization cocos2dx优化方案 尽可能地使用批次渲染（Batch Draw） 控制Draw 数量尽量少 减少 32 位未压缩纹理的使用，尽量使用 16 位且压缩过的纹理格式。 尽可能地使用支持硬件解码的压缩纹理：比如 iOS 平台使用 PVRTC 纹理， 在安卓平台上面使用 ETC格式的纹理。 请使用对象缓存池和预加载技术来避免临时创建耗时导致卡顿。 使用 armeabi-v7a 架构来编译 Android 的 SO，因为在此架构下面 Cocos2d-x 会启用 neon 指令集，矩阵运算的效率会大大提高。 避免在 pixel shader 里面做非常复杂的计算 避免在 pixel shader 里面使用 discard 和 alpha test，因为这样会破坏 GPU 自身的 depth testing 优化，比如 PowerVR 的 HSR。]]></content>
      <categories>
        <category>cocos2dx</category>
      </categories>
      <tags>
        <tag>cocos2dx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang服务器开发]]></title>
    <url>%2F2018%2F11%2F30%2Fgolang%2F</url>
    <content type="text"><![CDATA[golang开发笔记涉及内容包括web服务器、游戏服务器的开始使用,包括一些开元的golang软件的解读. leaf goworld 等教程. 同时会有一些游戏demo展示. 跳转链接： golang深度解析 leaf解析 goworld解析 https://gameloses.github.io/golang/]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>go</tag>
        <tag>游戏服务器</tag>
        <tag>leaf</tag>
        <tag>goworld</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitbook使用]]></title>
    <url>%2F2018%2F11%2F28%2Fgitbook%2F</url>
    <content type="text"><![CDATA[Gitbook的搭建 gitbook是一个npm工具使用的是git和markdown技术支持构建多种格式的ebook. 安装npm install gitbook-cli gitbook -V 初始化创建一个空目录,生成README.md SUMMARY.md两个文件,使用如下命令 gitbook init README.md —— 书籍的介绍写在这个文件里 SUMMARY.md —— 书籍的目录结构在这里配置 编辑电子书目录编辑 * [第一章](section1/README.md) * [第一节](section1/example1.md) * [第二节](section1/example2.md) * [第二章](section2/README.md) * [第一节](section2/example1.md) 目录支持三级，目录中可以带链接.名录名+链接的方式.链接即相对md文件名字. 本地预览gitbook serve 发布电子书gitbook build 在本地目录生成_book静态网页电子书 生成电子书安装插件calibre. https://calibre-ebook.com/download 添加环境变量： cd ~ vim .bash_profile PATH = /Applications/calibre.app/Contents/MacOS:${PATH}&quot; source .bash_profile 生成电子书命令如下： gitbook pdf gitbook mobi 部署到github利用gh-pages将gitbook生成的静态网页发布到github pages上. 安装gh-pages npm install g gh-pages 在github上创建仓库例如cocos2dx 将书籍源码push到仓库的master分支 将_book发布到github仓库的gh-pages分支 gitbook build gh-pages -d _book]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>Gitbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github上搭建hexo博客]]></title>
    <url>%2F2018%2F11%2F23%2Fhexo%E6%90%AD%E5%BB%BAgithubblog%2F</url>
    <content type="text"><![CDATA[打算在github上搭建起hexo博客和gitbook,主要记录一些技术积累.涉及游戏开前后端区块链等.解读一些开源的库.像skynet,pomelo,kbengine,coco2dx,cocos creator,ETH,goworld等.本文记录一下搭建hexo的过程纯属经验之谈. 基本流程 安装前提 node.js mac下注意npm对user/local的权限问题 git 保证使用ssh和github进行认证测试通过：ssh -T git@github.com. 创建github仓库 例如github用户名为gameloses则仓库名为:gameloses.github.io 安装hexonpm install -g hexo-cli hexo init blog cd blog npm install 基本配置在 _config.yml 中修改大部份的配置 配置部署参数 deploy: type: git repository: git@github.com:gameloses/gameloses.github.io.git branch: master 安装部署插件 cd blog npm install hexo-deployer-git --save 安装首页文章显示插件 npm install --save hexo-auto-excerpt 设置显示字数： auto_excerpt: enable: true length: 300 手动添加文章描述 npm install --save hexo-front-matter-excerpt 在文章标题描述中添加：excerpt: xxxxxxxx 或者文章中添加 ““ 文章资源文件夹 post_asset_folder: true {% asset_img example.jpg This is an example image %} 发布上传博客hexo d -g 常见的其他命令 hexo s == hexo server //启动本地服务 hexo g == hexo generate //生成 hexo d == hexo deploy //发布 hexo n == hexo new //新建 书写文章hexo new post &quot;文章名字&quot;使用模板生成文章 title: cocos2dx引擎架构概述 comments: true date: 2018-11-23 20:51:11 tags: categories: 分类标签为了使分类标签生效需要生成两个page文件 hexo new page categories hexo new page tags 主题配置一个模仿github样式的主题 git clone git@github.com:sabrinaluo/hexo-theme-replica.git themes/replica Set theme: replica in _config.yml (the one in your root folder) 安装插件安装rssnpm install hero-generator-feed配置如下： plugin: - hexo-generator-feed feed: type: atom path: atom.xml limit: 20 rss: /atom.xml 绑定域名添加WWW和@主机记录，记录类型为CNAME. 在source目录下创建CNAME文件，文件内容为域名例如：chuangyutime.com QA mac下node安装好之后使用npm安装全局包会出现usr/local目录权限读写问题？sudo chown -R $USER /usr/local修改权限之后使用ls -l /usr/local 查看权限 分类标签404？需要创建两个page categories、tags vscode 编写markdown回退文本之后以后存在特殊的bs字符问题？显示隐藏字符 &quot;editor.renderControlCharacters&quot;: true安装插件：Remove backspace control character开启设置：&quot;editor.formatOnType&quot;: true 在被设定的情况下，进行变换时;输入时启动]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
