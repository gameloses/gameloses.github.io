<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小工知识库</title>
  
  <subtitle>coding wiki</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://bytemode.github.io/"/>
  <updated>2019-01-07T10:59:46.592Z</updated>
  <id>https://bytemode.github.io/</id>
  
  <author>
    <name>sunfeng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>cocos2dx自动批绘制的条件</title>
    <link href="https://bytemode.github.io/2019/01/07/%E8%87%AA%E5%8A%A8%E6%89%B9%E7%BB%98%E5%88%B6%E7%9A%84%E6%9D%A1%E4%BB%B6/"/>
    <id>https://bytemode.github.io/2019/01/07/自动批绘制的条件/</id>
    <published>2019-01-07T10:56:49.000Z</published>
    <updated>2019-01-07T10:59:46.592Z</updated>
    
    <content type="html"><![CDATA[<h4 id="为什么必须要相同纹理、相同混合函数、相同shader？"><a href="#为什么必须要相同纹理、相同混合函数、相同shader？" class="headerlink" title="为什么必须要相同纹理、相同混合函数、相同shader？"></a>为什么必须要相同纹理、相同混合函数、相同shader？</h4><p>要满足Auto-batching，就必须有这三个条件，这是为什么呢？</p><p>我们回到之前的代码，在调用节点的draw函数时，调用了QuadCommand的init函数：</p><pre><code> void Sprite::draw(Renderer *renderer, const Mat4 &amp;transform, uint32_t flags) {     // Don&#39;t do calculate the culling if the transform was not updated     _insideBounds = (flags &amp; FLAGS_TRANSFORM_DIRTY) ? renderer-&gt;checkVisibility(transform, _contentSize) : _insideBounds;     if(_insideBounds)     {         _quadCommand.init(_globalZOrder, _texture-&gt;getName(), getGLProgramState(), _blendFunc, &amp;_quad, 1, transform);         renderer-&gt;addCommand(&amp;_quadCommand);     } }</code></pre><p>在init中调用了 生成材料id的方法：</p><pre><code>void QuadCommand::generateMaterialID(){    if(_glProgramState-&gt;getUniformCount() &gt; 0)    {        _materialID = Renderer::MATERIAL_ID_DO_NOT_BATCH;    }    else    {        int glProgram = (int)_glProgramState-&gt;getGLProgram()-&gt;getProgram();        int intArray[4] = { glProgram, (int)_textureID, (int)_blendType.src, (int)_blendType.dst};        _materialID = XXH32((const void*)intArray, sizeof(intArray), 0);    }}</code></pre><p>材料id的生成方法是按照gl shader textureid blandfunc 内存地址连接 再hash 得倒的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;为什么必须要相同纹理、相同混合函数、相同shader？&quot;&gt;&lt;a href=&quot;#为什么必须要相同纹理、相同混合函数、相同shader？&quot; class=&quot;headerlink&quot; title=&quot;为什么必须要相同纹理、相同混合函数、相同shader？&quot;&gt;&lt;/a&gt;为什么必须
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx 引用计数机制</title>
    <link href="https://bytemode.github.io/2019/01/07/Ref%E6%9C%BA%E5%88%B6/"/>
    <id>https://bytemode.github.io/2019/01/07/Ref机制/</id>
    <published>2019-01-07T10:49:23.000Z</published>
    <updated>2019-01-07T10:53:18.470Z</updated>
    
    <content type="html"><![CDATA[<h4 id="autorelease和release的区别"><a href="#autorelease和release的区别" class="headerlink" title="autorelease和release的区别"></a>autorelease和release的区别</h4><p>  release是立即释放引用计数，如果到达0，对象被销毁。 </p><p>  autorelease是延迟释放，是为了更好管理内存产生的。</p><h4 id="关于Ref"><a href="#关于Ref" class="headerlink" title="关于Ref"></a>关于Ref</h4><p>一个Ref对象new之后，引用计数为1，retain（）执行+1,release()执行-1;</p><p>autorelease()只是将其放入了当前缓存池中及AutoReleasePool中。</p><pre><code>class CC_DLL Ref{public:    void retain();    void release();    Ref* autorelease();    unsigned int getReferenceCount() const;protected:    Ref();public:    virtual ~Ref();protected:    unsigned int _referenceCount;    friend class AutoreleasePool;   //友元可以访问与其有friend关系的类中的私有成员};Ref::Ref(): _referenceCount(1){}void Ref::retain(){++_referenceCount;}void Ref::release()   //引用计数较少 如果引用计数==0 则delete this{    --_referenceCount;   if (_referenceCount == 0)    {//如果一个对象在对象管理池中 但是引用计数为0  则此对象存在问题\#if defined(COCOS2D_DEBUG) &amp;&amp; (COCOS2D_DEBUG &gt; 0)        auto poolManager = PoolManager::getInstance();        if (!poolManager-&gt;getCurrentPool()-&gt;isClearing() &amp;&amp; poolManager-&gt;isObjectInPools(this))        {            CCASSERT(false, &quot;The reference shouldn&#39;t be 0 because it is still in autorelease pool.&quot;);        }\#endif        delete this;    }}Ref* Ref::autorelease() //将对象放入当前管理池的最后{    PoolManager::getInstance()-&gt;getCurrentPool()-&gt;addObject(this);    return this;}</code></pre><h4 id="关于AutoReleasePool"><a href="#关于AutoReleasePool" class="headerlink" title="关于AutoReleasePool"></a>关于AutoReleasePool</h4><p>AutoreleasePool管理一个 std::vector&lt;Ref*&gt;列表，添加时只是放入vector 引用计数不发生变化，</p><p>clear（）遍历vector调用release()</p><pre><code>class CC_DLL AutoreleasePool{public:    AutoreleasePool();   //分配大小 入栈   _managedObjectArray.reserve(150); PoolManager::getInstance()-&gt;push(this);    AutoreleasePool(const std::string &amp;name);    ~AutoreleasePool(); //清理 出栈 clear(); PoolManager::getInstance()-&gt;pop();    void addObject(Ref *object);    void clear();    bool isClearing() const { return _isClearing; };    bool contains(Ref* object) const;    void dump();    private:    std::vector&lt;Ref*&gt;   _managedObjectArray;    std::string _name;    bool _isClearing;};</code></pre><h4 id="关于PoolManager"><a href="#关于PoolManager" class="headerlink" title="关于PoolManager"></a>关于PoolManager</h4><p>保存一个std::vector&lt;AutoreleasePool*&gt;以堆栈的形式进行管理。</p><pre><code>class CC_DLL PoolManager{public:    static PoolManager* getInstance(); //添加一个初始的AutoreleasePool  new AutoreleasePool(&quot;cocos2d autorelease pool&quot;);    static void destroyInstance();    AutoreleasePool *getCurrentPool() const;    bool isObjectInPools(Ref* obj) const;    friend class AutoreleasePool;private:    PoolManager();    ~PoolManager();    void push(AutoreleasePool *pool);    void pop(); //弹出时访问栈顶的AutoreleasePool     static PoolManager* s_singleInstance;     std::vector&lt;AutoreleasePool*&gt; _releasePoolStack;};</code></pre><h4 id="如何清理"><a href="#如何清理" class="headerlink" title="如何清理"></a>如何清理</h4><p>在每一帧绘制完成之后会执行清理工作。</p><pre><code>mainLoop(){        drawScene();        // release the objects        PoolManager::getInstance()-&gt;getCurrentPool()-&gt;clear();}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;autorelease和release的区别&quot;&gt;&lt;a href=&quot;#autorelease和release的区别&quot; class=&quot;headerlink&quot; title=&quot;autorelease和release的区别&quot;&gt;&lt;/a&gt;autorelease和release的
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx Event机制</title>
    <link href="https://bytemode.github.io/2019/01/07/dispatcher%E6%9C%BA%E5%88%B6/"/>
    <id>https://bytemode.github.io/2019/01/07/dispatcher机制/</id>
    <published>2019-01-07T10:34:51.000Z</published>
    <updated>2019-01-07T10:47:27.244Z</updated>
    
    <content type="html"><![CDATA[<h4 id="基本机制"><a href="#基本机制" class="headerlink" title="基本机制"></a>基本机制</h4><p>事件机制类似观察者模式。</p><p>EventListener 事件监听者，封装事件处理代码，包含事件会回调。</p><p>事件包含时间信息。</p><p>EventDispatcher 事件分发者，管理分发事件。</p><h4 id="事件添加机制"><a href="#事件添加机制" class="headerlink" title="事件添加机制"></a>事件添加机制</h4><p>EventDispatcher中以 listenerId-&gt;EventListenerVector的方式保存了事件监听者。</p><p>事件有两种添加方式一种是关联节点，一种是固定优先级的。</p><p>添加时根据是添加的方式放入不同的vector。</p><p>std::unordered_map&lt;EventListener::ListenerID, EventListenerVector*&gt; _listenerMap;</p><p>EventListenerVector包含。</p><p>std::vector&lt;EventListener<em>&gt;</em> _fixedListeners;</p><p>std::vector&lt;EventListener<em>&gt;</em> _sceneGraphListeners;</p><p>void EventDispatcher::addEventListenerWithSceneGraph(EventListener<em> listener, Node</em> node)</p><p>void EventDispatcher::addEventListenerWithFixedPriority(EventListener* listener, int priority)</p><h4 id="事件移除"><a href="#事件移除" class="headerlink" title="事件移除"></a>事件移除</h4><p>固定优先级的需要removeEventListener（）</p><p>关联节点的节点消失会自行移除。</p><h4 id="事件分发"><a href="#事件分发" class="headerlink" title="事件分发"></a>事件分发</h4><p>根据id取出事件监听者，</p><p>排序事件监听者按照绘制顺序相反顺序或者是事件的优先级排序</p><p>sortEventListeners(listenerID);</p><p>取出事件监听者id关联的事件监听者列表  将事件分发给每个事件监听者。</p><h4 id="分发顺序"><a href="#分发顺序" class="headerlink" title="分发顺序:"></a>分发顺序:</h4><p>分别取出节点关联的和固定优先级的时间接听者给予分发</p><p>分发顺序是按照优先级<0 =="0(关联节点)">0 的分发顺去</0></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;基本机制&quot;&gt;&lt;a href=&quot;#基本机制&quot; class=&quot;headerlink&quot; title=&quot;基本机制&quot;&gt;&lt;/a&gt;基本机制&lt;/h4&gt;&lt;p&gt;事件机制类似观察者模式。&lt;/p&gt;
&lt;p&gt;EventListener 事件监听者，封装事件处理代码，包含事件会回调。&lt;/p&gt;

      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>aocos2dx action机制</title>
    <link href="https://bytemode.github.io/2019/01/07/action%E6%9C%BA%E5%88%B6/"/>
    <id>https://bytemode.github.io/2019/01/07/action机制/</id>
    <published>2019-01-07T10:25:07.000Z</published>
    <updated>2019-01-07T10:29:11.684Z</updated>
    
    <content type="html"><![CDATA[<p>依赖scheduler更新机制。</p><p>1.Action它通过在一段时间内对Node元素的某些属性进行插值计算。 </p><p>   然后依赖时间更新去更新属性。依赖step()-&gt;update()</p><p>2.Action的管理是放在ActionManager 的hash表中，通过target作为key action防止在hash 节点的数组中。</p><p>ActionManager 添加到动作队列，并通过调用startWithTarget方法绑定动作执行者。</p><p>1.当我们对CCNode 调用runAction(Action* action)的时候，动作管理类ActionManager会新的Action和对应的目标节点添加到期管理的动作类表中。</p><pre><code>Action * Node::runAction(Action* action) {    _actionManager-&gt;addAction(action, this, !_running);    return action; } </code></pre><p>2.在addAction中将动作添加到动作队列之后，会调用Aciton的startWithTarget方法，来绑定动作的执行者。</p><pre><code> void ActionManager::addAction(Action *action, Node *target, bool paused) {            tHashElement *element = nullptr;              // we should convert it to Ref*, because we save it as Ref*              Ref *tmp = target;              HASH_FIND_PTR(_targets, &amp;tmp, element);              if (! element)     {                      element = (tHashElement*)calloc(sizeof(*element), 1);                      element-&gt;paused = paused;                      target-&gt;retain();                      element-&gt;target = target;                      HASH_ADD_PTR(_targets, target, element);              }               actionAllocWithHashElement(element);               ccArrayAppendObject(element-&gt;actions, action);               action-&gt;startWithTarget(target);  }</code></pre><p>3.在Director初始化时ActionManager 就像scheduler注册了一个系统级别的回调，每帧更新update中调用step方法进行动作更新。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;依赖scheduler更新机制。&lt;/p&gt;
&lt;p&gt;1.Action它通过在一段时间内对Node元素的某些属性进行插值计算。 &lt;/p&gt;
&lt;p&gt;   然后依赖时间更新去更新属性。依赖step()-&amp;gt;update()&lt;/p&gt;
&lt;p&gt;2.Action的管理是放在ActionMa
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx schedule机制</title>
    <link href="https://bytemode.github.io/2019/01/07/schedule%E6%9C%BA%E5%88%B6/"/>
    <id>https://bytemode.github.io/2019/01/07/schedule机制/</id>
    <published>2019-01-07T10:15:44.000Z</published>
    <updated>2019-01-07T10:23:05.955Z</updated>
    
    <content type="html"><![CDATA[<p>是cocos2d-x核心的一块，负责调度执行，更新动作等。</p><h4 id="如何计时？"><a href="#如何计时？" class="headerlink" title="如何计时？"></a>如何计时？</h4><p>Timer保存了调度任务的 时间线 重复次数 事件间隔 延迟等数据。</p><p>每帧更新后Timer做事件累加，根据时间线去触发或者取消更新回调。</p><h4 id="Scheduler有两种添加更新的机制"><a href="#Scheduler有两种添加更新的机制" class="headerlink" title="Scheduler有两种添加更新的机制"></a>Scheduler有两种添加更新的机制</h4><ol><li><p>自定义更新</p><p>根据target的不同Ref<em>和void</em>,分为两种。一种是TimerTargetCallback一种是TimerTargetSelector</p><p>他们同时继承自Timer，Timer有计时机制，含有触发和取消器。</p></li></ol><p>​    void schedule(SEL_SCHEDULE selector, Ref *target, float interval, unsigned int repeat, float delay, bool paused);</p><p>​    void schedule(const ccSchedulerFunc&amp; callback, void *target, float interval, bool paused, const std::string&amp; key);</p><ol start="2"><li>每帧更新（带优先级的）</li></ol><p>​    void Scheduler::schedulePerFrame(const ccSchedulerFunc&amp; callback, void *target, int priority, bool paused)</p><h4 id="如何保存这些回调更新？"><a href="#如何保存这些回调更新？" class="headerlink" title="如何保存这些回调更新？"></a>如何保存这些回调更新？</h4><p>每帧更新每帧更新的回调放在 _hashForUpdates结构中以target作为key,同时根据优先级放在不同的hash表中。</p><p>自定义更新更新回调放在_hashForTimers hash表中，以target作为key.</p><p>uthash,uthash是Scheduler的核心数据结构。</p><pre><code>    struct _listEntry * _updatesNegList;        // list of priority &lt; 0    struct _listEntry * _updates0List;            // list priority == 0    struct _listEntry * _updatesPosList;        // list priority &gt; 0    struct _hashUpdateEntry *_hashForUpdates; // hash used to fetch quickly the list entries for pause,delete,etc    struct _hashSelectorEntry *_hashForTimers;</code></pre><p>自定义更新的hash表  _hashForTimers以target作为key，hash节点中包含数组数组中包含了Timer.</p><p>每帧更新的hash表 则使用_hashForUpdates 其中以target作为key，节点中包含了链表，链表中存储timer.</p><h4 id="如何执行调度？"><a href="#如何执行调度？" class="headerlink" title="如何执行调度？"></a>如何执行调度？</h4><p>每帧开始绘制之前执行Scheduler::update(float dt)</p><p>在里面遍历hash表，执行update更新回调，完成后移出。</p><p>按照优先级<0 =="0">0 自定义更新的顺序遍历执行。</0></p><h4 id="如何取消？"><a href="#如何取消？" class="headerlink" title="如何取消？"></a>如何取消？</h4><p>TimerTargetCallback 通过key来取消，因为一个lambada表达式无法比较。 </p><p>TimerTargetSeletor 通过设置的成员回调函数的指针来移出。</p><p>void Scheduler::unschedule(const std::string &amp;key, void *target)</p><p>void Scheduler::unschedule(SEL_SCHEDULE selector, Ref *target)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;是cocos2d-x核心的一块，负责调度执行，更新动作等。&lt;/p&gt;
&lt;h4 id=&quot;如何计时？&quot;&gt;&lt;a href=&quot;#如何计时？&quot; class=&quot;headerlink&quot; title=&quot;如何计时？&quot;&gt;&lt;/a&gt;如何计时？&lt;/h4&gt;&lt;p&gt;Timer保存了调度任务的 时间线 重复次
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>横竖屏切换方案</title>
    <link href="https://bytemode.github.io/2019/01/07/%E6%A8%AA%E7%AB%96%E5%B1%8F%E5%88%87%E6%8D%A2%E6%96%B9%E6%A1%88/"/>
    <id>https://bytemode.github.io/2019/01/07/横竖屏切换方案/</id>
    <published>2019-01-07T10:07:16.000Z</published>
    <updated>2019-01-07T10:07:36.347Z</updated>
    
    <content type="html"><![CDATA[<h1 id="切换横竖屏的方案"><a href="#切换横竖屏的方案" class="headerlink" title="切换横竖屏的方案"></a>切换横竖屏的方案</h1><ol><li>在AndroidManifest.xml中配置</li></ol><p>在项目的AndroidManifest.xml中找到你所指定的activity中加上android:screenOrientation属性，它有以下几个参数：</p><p>“unspecified”:默认值 由系统来判断显示方向.判定的策略是和设备相关的，所以不同的设备会有不同的显示方向. </p><p>“landscape”:横屏显示（宽比高要长） </p><p>“portrait”:竖屏显示(高比宽要长) </p><p>“user”:用户当前首选的方向 </p><p>“behind”:和该Activity下面的那个Activity的方向一致(在Activity堆栈中的) </p><p>“sensor”:有物理的感应器来决定。如果用户旋转设备这屏幕会横竖屏切换。 </p><p>“nosensor”:忽略物理感应器，这样就不会随着用户旋转设备而更改了（”unspecified”设置除外）。</p><ol start="2"><li>在Activity代码中设置，注意语句一定要在setContentView()方法之前</li></ol><p>设置横屏代码：setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);//横屏</p><p>因为横屏有两个方向，而你在执行设置横屏的语句时，如果此时屏幕不是默认的横屏方向，会把已经横屏的屏幕旋转180°，调至默认的横屏方向。如果你不想在横屏的情况下再继续变化，可以先判断是否已经为横屏了，如果是横屏，就不执行该语句，代码如下：</p><pre><code>if(this.getResources().getConfiguration().orientation ==Configuration.ORIENTATION_PORTRAIT){      setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);}设置竖屏代码：setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_PORTRAIT);//竖屏</code></pre><h1 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h1><p>横竖屏有默认的方向，在切换横屏或者竖屏的时候需要检测当前是否已经是要切换到的屏幕状态防止（自动感应横竖屏情况下）多次切换导致横竖屏方向不对。因为切换回使用默认的横竖屏方向导致方向问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;切换横竖屏的方案&quot;&gt;&lt;a href=&quot;#切换横竖屏的方案&quot; class=&quot;headerlink&quot; title=&quot;切换横竖屏的方案&quot;&gt;&lt;/a&gt;切换横竖屏的方案&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;在AndroidManifest.xml中配置&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在项
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>apk内部存储路径</title>
    <link href="https://bytemode.github.io/2019/01/07/apk%E5%86%85%E9%83%A8%E5%AD%98%E5%82%A8%E8%B7%AF%E5%BE%84/"/>
    <id>https://bytemode.github.io/2019/01/07/apk内部存储路径/</id>
    <published>2019-01-07T10:04:21.000Z</published>
    <updated>2019-01-07T10:06:55.285Z</updated>
    
    <content type="html"><![CDATA[<p>首先内部存储路径为/data/data/youPackageName/，下面讲解的各路径都是基于你自己的应用的内部存储路径下。所有内部存储中保存的文件在用户卸载应用的时候会被删除。</p><h4 id="files"><a href="#files" class="headerlink" title="files"></a>files</h4><ol><li><p>Context.getFilesDir()，该方法返回/data/data/youPackageName/files的File对象。</p></li><li><p>Context.openFileInput()与Context.openFileOutput()，只能读取和写入files下的文件，返回的是FileInputStream和FileOutputStream对象。</p></li><li><p>Context.fileList()，返回files下所有的文件名，返回的是String[]对象。</p></li><li><p>Context.deleteFile(String)，删除files下指定名称的文件。</p></li></ol><h4 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h4><p>Context.getCacheDir()，该方法返回/data/data/youPackageName/cache的File对象。</p><h4 id="custom-dir"><a href="#custom-dir" class="headerlink" title="custom dir"></a>custom dir</h4><p>getDir(String name, int mode)，返回/data/data/youPackageName/下的指定名称的文件夹File对象，如果该文件夹不存在则用指定名称创建一个新的文件夹。</p><p>一些路径的标准写法</p><p> Environment.getDataDirectory() = /data</p><p> Environment.getDownloadCacheDirectory() = /cache</p><p> Environment.getExternalStorageDirectory() = /mnt/sdcard</p><p> Environment.getRootDirectory() = /system</p><p> context.getCacheDir() = /data/data/com.mt.mtpp/cache</p><p> context.getExternalCacheDir() = /mnt/sdcard/Android/data/com.mt.mtpp/cache</p><p> context.getFilesDir() = /data/data/com.mt.mtpp/files</p><p>使用adb查看apk内存储数据：【手机有root权限】</p><p>adb shell</p><p>su -</p><p>cd data/data/airfight.dawx.com/</p><p>ls</p><p>下面包含了四个文件见  files  cache  lib database</p><p>使用adb获取数据：</p><p>adb push D:\file.txt system/</p><p>adb pull system/file.txt D:/</p><p>-—————————————————————————–</p><p>apk的安装卸载流程：</p><p>应用安装涉及到如下几个目录：</p><p>system/app </p><p> 系统自带的应用程序，无法删除</p><p>data/app</p><p> 用户程序安装的目录，有删除权限。</p><p>安装时把apk文件复制到此目录</p><p>data/data</p><p> 存放应用程序的数据</p><p>Data/dalvik-cache</p><p> 将apk中的dex文件安装到dalvik-cache目录下(dex文件是dalvik虚拟机的可执行文件,其大小约为原始apk文件大小的四分之一)</p><p> 安装过程：复制APK安装包到data/app目录下，解压并扫描安装包，把dex文件(Dalvik字节码)保存到dalvik-cache目录，并data/data目录下创建对应的应用数据目录。</p><p>卸载过程：删除安装过程中在上述三个目录下创建的文件及目录</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;首先内部存储路径为/data/data/youPackageName/，下面讲解的各路径都是基于你自己的应用的内部存储路径下。所有内部存储中保存的文件在用户卸载应用的时候会被删除。&lt;/p&gt;
&lt;h4 id=&quot;files&quot;&gt;&lt;a href=&quot;#files&quot; class=&quot;hea
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx接入第三方的so</title>
    <link href="https://bytemode.github.io/2019/01/07/cocos2dx%E8%AE%A1%E5%85%A5%E7%AC%AC%E4%B8%89%E6%96%B9%E7%9A%84so/"/>
    <id>https://bytemode.github.io/2019/01/07/cocos2dx计入第三方的so/</id>
    <published>2019-01-07T09:58:40.000Z</published>
    <updated>2019-01-07T10:00:50.685Z</updated>
    
    <content type="html"><![CDATA[<p>Android平台</p><p>添加第三方.so</p><p>1.将.so放到prebuild目录下。</p><p>2.修改mk.</p><p>例如添加的库文件是：libfmod.so。</p><pre><code>LOCAL_PATH := $(call my-dir)\##### 添加第三方so库 BEGIN ######include $(CLEAR_VARS)LOCAL_MODULE := libfmodLOCAL_SRC_FILES := prebuild/$(TARGET_ARCH_ABI)/libfmod.so  #第三方soLOCAL_EXPORT_C_INCLUDES := $(LOCAL_PATH)/../../../cocos2d-x/external/fmod/include  #导出的头文件路径include $(PREBUILT_SHARED_LIBRARY)\##### 添加第三方so库 END ######include $(CLEAR_VARS)    #开始一个新的编译LOCAL_MODULE := cocos2dlua_sharedLOCAL_MODULE_FILENAME := libcocos2dlua\# 遍历目录及子目录的函数define walk    $(wildcard $(1)) $(foreach e, $(wildcard $(1)/*), $(call walk, $(e)))endef\# Classes目录下所有文件MY_FILES := $(call walk, $(LOCAL_PATH)/../../Classes)MY_C_FILES := $(filter %.cpp %.c, $(MY_FILES))MY_H_FILES := $(filter %.h, $(MY_FILES))LOCAL_SRC_FILES := hellolua/main.cpp \                    hellolua/JniUtil.cppLOCAL_SRC_FILES += $(MY_C_FILES:$(LOCAL_PATH)/%=%)\# Classes目录下所有文件夹MY_H_FOLDERS := $(sort $(dir $(MY_FILES)))\#$(warning MY_H_FOLDERS:$(MY_H_FOLDERS))MY_LOCAL_C_INCLUDES := $(sort $(dir $(LOCAL_PATH)/../../Classes/*)) MY_LOCAL_C_INCLUDES += $(MY_H_FOLDERS)LOCAL_C_INCLUDES := \$(LOCAL_PATH)/../../../cocos2d-x/external \$(LOCAL_PATH)/../../../cocos2d-x/tools/simulator/libsimulator/lib \$(LOCAL_PATH)/../../../cocos2d-x/tools/simulator/libsimulator/lib/protobuf-liteLOCAL_C_INCLUDES += $(LOCAL_PATH)/../../../cocos2d-x/cocos/uiLOCAL_C_INCLUDES += $(LOCAL_PATH)/../../../cocos2d-x/cocos/editor-support/cocostudioLOCAL_C_INCLUDES += $(LOCAL_PATH)/../../../cocos2d-x/external/fmod/include #使用了共享库导出的头文件 在在此处定义路径LOCAL_C_INCLUDES += $(sort $(MY_LOCAL_C_INCLUDES))\# _COCOS_HEADER_ANDROID_BEGIN\# _COCOS_HEADER_ANDROID_ENDLOCAL_STATIC_LIBRARIES := cocos2d_lua_staticLOCAL_STATIC_LIBRARIES += cocos2d_simulator_staticLOCAL_STATIC_LIBRARIES += testin_agent_helper_static LOCAL_STATIC_LIBRARIES += testin_agent_helper_lua\# _COCOS_LIB_ANDROID_BEGIN\# _COCOS_LIB_ANDROID_ENDLOCAL_SHARED_LIBRARIES := libfmod     #添加共享库include $(BUILD_SHARED_LIBRARY)   #编译成共享库$(call import-module,scripting/lua-bindings/proj.android)$(call import-module,tools/simulator/libsimulator/proj.android)$(call import-module,external/testinagenthelper) $(call import-module,external/testinagenthelper/lua)\# _COCOS_LIB_IMPORT_ANDROID_BEGIN\# _COCOS_LIB_IMPORT_ANDROID_END</code></pre><p>PREBUILT_SHARED_LIBRARY—&gt;LOCAL_C_INCLUDES —&gt;LOCAL_SHARED_LIBRARIES  这三放置的位置得注意。</p><p>3.在java层加载so</p><p>   合适的地方调用 如下代码，一般放在静态方法里面。</p><pre><code>   try {          System.loadLibrary(&quot;fmod&quot;);   }catch (UnsatisfiedLinkError e) { }  static {        System.loadLibrary(&quot;XXX&quot;);  }</code></pre><p>  注意加载的第三方库一定得在 cocos的so之前加载。</p><p>  以上添加一个动态库编译完成后.so会出现在包里。</p><p>-——————————————————————————————————–</p><p>添加第三方.a</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Android平台&lt;/p&gt;
&lt;p&gt;添加第三方.so&lt;/p&gt;
&lt;p&gt;1.将.so放到prebuild目录下。&lt;/p&gt;
&lt;p&gt;2.修改mk.&lt;/p&gt;
&lt;p&gt;例如添加的库文件是：libfmod.so。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;LOCAL_PATH := $(call my-
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2d分辨率适配</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2d%E5%88%86%E8%BE%A8%E7%8E%87%E9%80%82%E9%85%8D/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2d分辨率适配/</id>
    <published>2019-01-04T10:56:53.000Z</published>
    <updated>2019-01-07T08:50:01.453Z</updated>
    
    <content type="html"><![CDATA[<p>最好的对多分辨率支持的方案是不处理分辨率，应用程序按照一个预定义的分辨率进行设计，低阶游戏引擎统一处理分辨率的缩放，这个预设的分辨率就是设计分辨率.</p><h4 id="设计分辨率"><a href="#设计分辨率" class="headerlink" title="设计分辨率"></a>设计分辨率</h4><h5 id="缩放策略"><a href="#缩放策略" class="headerlink" title="缩放策略"></a>缩放策略</h5><p><code>setDesignResolutionSize</code>可以设置设计分辨率和缩放策略，目前的缩放策略主要有</p><pre><code>EXACT_FIT: 充满屏幕设计分辨率直接缩放为屏幕分辨率，会变形NO_BORDER: 充满屏幕，较宽的部分被裁切，设计分辨率是等比缩放SHOW_ALL:等比缩放，以较宽的一边缩放，会出现黑边FIXED_HEIGHT:固定高度宽度等比缩放，充满屏幕，不会裁切FIXED_WIDTH：固定宽度高度等比缩放，充满屏幕，不会裁切</code></pre><p>建议使用的是FIXED_XXX可以根据游戏类型进行选择，同时在界面编辑的时候使用左边也要做选择，在cocos studio中设置百分比、固定文职或者距离边距多少都有影响需要小心处理</p><h5 id="常见变量"><a href="#常见变量" class="headerlink" title="常见变量"></a>常见变量</h5><ul><li>getWinSizeL OpenGl视口在转化到设计分辨率下的尺寸，表示绘制区域</li><li>getVisibleSize OpenGl视口在转化到设计分辨率下的尺寸屏幕可见区域的部分</li><li>getVisibleOrigin 表示可见区域原点在绘制区域中的位置</li></ul><h5 id="视口设置"><a href="#视口设置" class="headerlink" title="视口设置"></a>视口设置</h5><p><code>setDesignResolutionSize</code>的调用导致了 视口、透视矩阵和观察点被重新设置</p><h5 id="什么时候缩放"><a href="#什么时候缩放" class="headerlink" title="什么时候缩放"></a>什么时候缩放</h5><p>由设计分辨率到实际的屏幕分辨率的缩放是什么时候执行的？其实没有执行这个操作.<br><strong>cocos2dx使用设计分辨率来设置投影矩阵和观察点</strong>，并没有将其缩放到屏幕实际分辨率，而只有视口设置为实际分辨率。透视矩阵定义的长宽比和视口窗宽比是相等的。<br><strong>程序中每个顶点使用设计分辨率下的坐标来定义坐标值，且被当做顶点属性发送给顶点着色器，顶点着色器使用设计分辨率下的模型视图变换矩阵对顶点进行坐标变化。顶点着色器输出的归一化坐标，图元组装阶段归一化坐标转换为屏幕坐标.</strong><br>视椎体定义的远近平面和视口的长宽比例相等，归一话的坐标被完全投影到是视口上.</p><h4 id="资源分辨率"><a href="#资源分辨率" class="headerlink" title="资源分辨率"></a>资源分辨率</h4><p>资源分辨率用来对同一个设计分辨率使用不同的分辨率资源进行缩放，如此针对不同分辨率设备使用接近的分辨率资源</p><h5 id="资源分辨率的设置"><a href="#资源分辨率的设置" class="headerlink" title="资源分辨率的设置"></a>资源分辨率的设置</h5><p>通过setFactor设置资源分辨率的缩放因子，设置缩放因子后所有的资源很好都会被缩放,cocos2dx使用setSearchPaths设置搜索路径来切换对应不同分辨率的资源使用</p><h5 id="缩放时机"><a href="#缩放时机" class="headerlink" title="缩放时机"></a>缩放时机</h5><p>sprite的顶点数据依赖contentsize，contentsize依赖于实际纹理大小，缩放时机就是在getContentSize, contextsize是将实际的像素分辨率转化为设计分辨率在进行缩放. 绘制纹理的时候使用的是归一化的uv不需要知道纹理实际大小</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最好的对多分辨率支持的方案是不处理分辨率，应用程序按照一个预定义的分辨率进行设计，低阶游戏引擎统一处理分辨率的缩放，这个预设的分辨率就是设计分辨率.&lt;/p&gt;
&lt;h4 id=&quot;设计分辨率&quot;&gt;&lt;a href=&quot;#设计分辨率&quot; class=&quot;headerlink&quot; title=&quot;
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx接入sdk方案</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E6%8E%A5%E5%85%A5sdk%E6%96%B9%E6%A1%88/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx接入sdk方案/</id>
    <published>2019-01-04T10:55:46.000Z</published>
    <updated>2019-01-07T09:55:38.510Z</updated>
    
    <content type="html"><![CDATA[<p>使用jni java反射机制 和callfunc</p><p>jni:java c++相互调用。</p><p>反射机制：主要使用Class Filed Constructor来动态的获取类的方法属性构造器进一步调用对象的方法属性以及构造对象。</p><p>callfunc：函数调用。</p><p>java-&gt;c++ : </p><p>通过jni调用CPPNativeCallHandler 调用c++的 NDKHelper::handleMessage 通过查找名字管理的callfunc最终调用callfunc.execute()执行c++方法。</p><p>c++调用java:</p><p>通过jni调用ReceiveCppMessage：利用反射机制实现方法调用。</p><p>最终实现的结果类型一种消息机制，省去类写jni的大量流程。</p><pre><code>//  NDKMessage.java package com.easyndk.classes;import java.lang.reflect.Method;import org.json.JSONObject;public class NDKMessage{   public Method methodToCall;   public JSONObject methodParams;}//AndroidNDKHelper package com.easyndk.classes;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import org.json.JSONException;import org.json.JSONObject;import android.os.Handler;import android.os.Message;public class AndroidNDKHelper { private static Object callHandler = null; private static Handler NDKHelperHandler = null; private static native void CPPNativeCallHandler(String json);    //调用c++方法 private static String __CALLED_METHOD__                 = &quot;calling_method_name&quot;; private static String __CALLED_METHOD_PARAMS__ = &quot;calling_method_params&quot;; private final  static int __MSG_FROM_CPP__ = 5;//设置java层接受c++方法调用的类 public static void SetNDKReceiver(Object callReceiver) {    callHandler = callReceiver;    NDKHelperHandler = new Handler()   {          public void handleMessage(Message msg)         {            switch(msg.what)            {            case __MSG_FROM_CPP__:               NDKMessage message = (NDKMessage)msg.obj;               message.methodToCall.invoke(AndroidNDKHelper.callHandler,  message.methodParams);            }            break;             }        }    }; }//java 调用c++方法 public static void SendMessageWithParameters(String methodToCall, JSONObject paramList) {      JSONObject obj = new JSONObject();       obj.put(__CALLED_METHOD__, methodToCall);       obj.put(__CALLED_METHOD_PARAMS__, paramList);       CPPNativeCallHandler(obj.toString()); }//接受c++调用 封装成method 进一步发送消息到接受的类中调用 public static void ReceiveCppMessage(String json) {      if (json != null)      {                JSONObject obj = new JSONObject(json);                if (obj.has(__CALLED_METHOD__))                {                     String methodName = obj.getString(__CALLED_METHOD__);                     JSONObject methodParams = null;                     methodParams = obj.getJSONObject(__CALLED_METHOD_PARAMS__);                    Method m = AndroidNDKHelper.callHandler.getClass().getMethod(methodName,                                          new Class[] { JSONObject.class });                    NDKMessage message = new NDKMessage();                    message.methodToCall = m;                    message.methodParams = methodParams;                   Message msg = new Message();                   msg.what = __MSG_FROM_CPP__;                   msg.obj = message;                   AndroidNDKHelper.NDKHelperHandler.sendMessage(msg);              }     }}--------------------------------------------------------------------------------------------------------NDKHelper.h#include &quot;cocos2d.h&quot;#include &quot;jansson\jansson.h&quot;#include &quot;NDKCallbackNode.h&quot;class NDKHelper{public:    static void addSelector(const char *groupName, const char *name, FuncNV selector, cocos2d::Node *target);    static void printSelectorList();    static void removeSelectorsInGroup(const char *groupName);    static cocos2d::Value getValueFromJson(json_t *obj);    static json_t *getJsonFromValue(cocos2d::Value value);    static void handleMessage(json_t *methodName, json_t *methodParams);private:    static std::vector&lt;NDKCallbackNode&gt; selectorList;};extern &quot;C&quot;{    void sendMessageWithParams(std::string methodName, cocos2d::Value methodParams);}NDKHelper.cpp#include &quot;NDKHelper.h&quot;USING_NS_CC;#define __CALLED_METHOD__           &quot;calling_method_name&quot;#define __CALLED_METHOD_PARAMS__    &quot;calling_method_params&quot;std::vector&lt;NDKCallbackNode&gt; NDKHelper::selectorList;void NDKHelper::addSelector(const char *groupName, const char *name, FuncNV selector, Node *target){    NDKHelper::selectorList.push_back(NDKCallbackNode(groupName, name, selector, target));}void NDKHelper::printSelectorList(){    for (unsigned int i = 0; i &lt; NDKHelper::selectorList.size(); ++i) {        std::string s = NDKHelper::selectorList[i].getGroup();        s.append(NDKHelper::selectorList[i].getName());    }}void NDKHelper::removeSelectorsInGroup(const char *groupName){    std::vector&lt;int&gt; markedIndices;    for (unsigned int i = 0; i &lt; NDKHelper::selectorList.size(); ++i) {        if (NDKHelper::selectorList[i].getGroup().compare(groupName) == 0) {            markedIndices.push_back(i);        }    }    for (long i = markedIndices.size() - 1; i &gt;= 0; --i) {        NDKHelper::selectorList.erase(NDKHelper::selectorList.begin() + markedIndices[i]);    }}Value NDKHelper::getValueFromJson(json_t *obj){    if (obj == NULL) {        return Value::Null;    }    if (json_is_object(obj)) {        ValueMap valueMap;        const char *key;        json_t *value;        void *iter = json_object_iter(obj);        while (iter) {            key = json_object_iter_key(iter);            value = json_object_iter_value(iter);            valueMap[key] = NDKHelper::getValueFromJson(value);            iter = json_object_iter_next(obj, iter);        }        return Value(valueMap);    } else if (json_is_array(obj)) {        ValueVector valueVector;        size_t sizeArray = json_array_size(obj);        for (unsigned int i = 0; i &lt; sizeArray; i++) {            valueVector.push_back(NDKHelper::getValueFromJson(json_array_get(obj, i)));        }        return Value(valueVector);    } else if (json_is_boolean(obj)) {        if (json_is_true(obj)) {            return Value(true);        } else {            return Value(false);        }    } else if (json_is_integer(obj)) {        int value = (int) json_integer_value(obj);        return Value(value);    } else if (json_is_real(obj)) {        double value = json_real_value(obj);        return Value(value);    } else if (json_is_string(obj)) {        std::string value = json_string_value(obj);        return Value(value);    }    return Value::Null;}json_t *NDKHelper::getJsonFromValue(Value value){    if (value.getType() == Value::Type::MAP) {        ValueMap valueMap = value.asValueMap();        json_t *jsonDict = json_object();        for (auto &amp;element : valueMap) {            json_object_set_new(jsonDict, element.first.c_str(),                                NDKHelper::getJsonFromValue(element.second));        }        return jsonDict;    } else if (value.getType() == Value::Type::VECTOR) {        ValueVector valueVector = value.asValueVector();        json_t *jsonArray = json_array();        size_t sizeVector = valueVector.size();        for (unsigned int i = 0; i &lt; sizeVector; i++) {            json_array_append_new(jsonArray,                                  NDKHelper::getJsonFromValue(valueVector.at(i)));        }        return jsonArray;    } else if (value.getType() == Value::Type::BOOLEAN) {        return json_boolean(value.asBool());    } else if (value.getType() == Value::Type::INTEGER) {        return json_integer(value.asInt());    } else if (value.getType() == Value::Type::DOUBLE) {        return json_real(value.asDouble());    } else if (value.getType() == Value::Type::STRING) {        return json_string(value.asString().c_str());    }    return NULL;}//接受java层调用void NDKHelper::handleMessage(json_t *methodName, json_t *methodParams){    if (methodName == NULL) {        return;    }    const char *methodNameStr = json_string_value(methodName);    for (unsigned int i = 0; i &lt; NDKHelper::selectorList.size(); ++i) {        if (NDKHelper::selectorList[i].getName().compare(methodNameStr) == 0) {            Value value = NDKHelper::getValueFromJson(methodParams);            FuncNV sel = NDKHelper::selectorList[i].getSelector();            Node *target = NDKHelper::selectorList[i].getTarget();            CallFuncNV *caller = CallFuncNV::create(sel);            caller-&gt;setValue(value);   /*            if (target) {                FiniteTimeAction *action = Sequence::create(caller, NULL);                target-&gt;runAction(action);            } else {                caller-&gt;execute();            }   */   if (!target)   {    CCAssert(false, &quot;target is null&quot;);   }   caller-&gt;execute();            break;        }    }}#if (CC_TARGET_PLATFORM == CC_PLATFORM_ANDROID)#include &quot;../../cocos2d/cocos/2d/platform/android/jni/JniHelper.h&quot;#include &lt;android/log.h&gt;#include &lt;jni.h&gt;#define LOG_TAG    &quot;EasyNDK-for-cocos2dx&quot;#define CLASS_NAME &quot;com/easyndk/classes/AndroidNDKHelper&quot;#endif#if (CC_TARGET_PLATFORM == CC_PLATFORM_IOS)#import &quot;IOSNDKHelper-C-Interface.h&quot;#endifextern &quot;C&quot;{#if (CC_TARGET_PLATFORM == CC_PLATFORM_ANDROID)    // Method for receiving NDK messages from Java, Android    void Java_com_easyndk_classes_AndroidNDKHelper_CPPNativeCallHandler(JNIEnv *env, jobject thiz, jstring json) {        /* The JniHelper call resulted in crash, so copy the jstring2string method here */        //std::string jsonString = JniHelper::jstring2string(json);        if (json == NULL) {            return;        }        JNIEnv *pEnv = JniHelper::getEnv();        if (!env) {            return;        }        const char *chars = env-&gt;GetStringUTFChars(json, NULL);        std::string ret(chars);        env-&gt;ReleaseStringUTFChars(json, chars);        std::string jsonString = ret;        /* End jstring2string code */        const char *jsonCharArray = jsonString.c_str();        json_error_t error;        json_t *root;        root = json_loads(jsonCharArray, 0, &amp;error);        if (!root) {            fprintf(stderr, &quot;error: on line %d: %s\n&quot;, error.line, error.text);            return;        }        json_t *jsonMethodName, *jsonMethodParams;        jsonMethodName = json_object_get(root, __CALLED_METHOD__);        jsonMethodParams = json_object_get(root, __CALLED_METHOD_PARAMS__);        // Just to see on the log screen if messages are propogating properly        // __android_log_print(ANDROID_LOG_DEBUG, LOG_TAG, jsonCharArray);        NDKHelper::handleMessage(jsonMethodName, jsonMethodParams);        json_decref(root);    }#endif    // Method for sending message from CPP to the targeted platform    //通过jni调用java的ReceiveCppMessage方法    void sendMessageWithParams(std::string methodName, Value methodParams) {        if (0 == strcmp(methodName.c_str(), &quot;&quot;)) {            return;        }        json_t *toBeSentJson = json_object();        json_object_set_new(toBeSentJson, __CALLED_METHOD__, json_string(methodName.c_str()));        if (!methodParams.isNull()) {            json_t *paramsJson = NDKHelper::getJsonFromValue(methodParams);            json_object_set_new(toBeSentJson, __CALLED_METHOD_PARAMS__, paramsJson);        }#if (CC_TARGET_PLATFORM == CC_PLATFORM_ANDROID)        JniMethodInfo t;  if (JniHelper::getStaticMethodInfo(t,                                           CLASS_NAME,                                           &quot;ReceiveCppMessage&quot;,                                           &quot;(Ljava/lang/String;)V&quot;)) {            char *jsonStrLocal = json_dumps(toBeSentJson, JSON_COMPACT | JSON_ENSURE_ASCII);            std::string jsonStr(jsonStrLocal);            free(jsonStrLocal);            jstring stringArg1 = t.env-&gt;NewStringUTF(jsonStr.c_str());            t.env-&gt;CallStaticVoidMethod(t.classID, t.methodID, stringArg1);            t.env-&gt;DeleteLocalRef(stringArg1);     t.env-&gt;DeleteLocalRef(t.classID);  }#endif#if (CC_TARGET_PLATFORM == CC_PLATFORM_IOS)        json_t *jsonMessageName = json_string(methodName.c_str());        if (!methodParams.isNull()) {            json_t *jsonParams = NDKHelper::getJsonFromValue(methodParams);            IOSNDKHelperImpl::receiveCPPMessage(jsonMessageName, jsonParams);            json_decref(jsonParams);        } else {            IOSNDKHelperImpl::receiveCPPMessage(jsonMessageName, NULL);        }        json_decref(jsonMessageName);#endif        json_decref(toBeSentJson);    }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用jni java反射机制 和callfunc&lt;/p&gt;
&lt;p&gt;jni:java c++相互调用。&lt;/p&gt;
&lt;p&gt;反射机制：主要使用Class Filed Constructor来动态的获取类的方法属性构造器进一步调用对象的方法属性以及构造对象。&lt;/p&gt;
&lt;p&gt;callfu
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx网络模块</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9D%97/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx网络模块/</id>
    <published>2019-01-04T10:55:15.000Z</published>
    <updated>2019-01-07T09:17:28.377Z</updated>
    
    <content type="html"><![CDATA[<p>cocos2dx除了curllib和websocket其他的没有封装好用的网络库，尤其是使用socket的时候得自己分装网络层。网络层有哪些东西呢或者说我们要连接服务器收发数据需要怎样的流程？</p><p>####### 自己造轮子</p><h6 id="关于socket"><a href="#关于socket" class="headerlink" title="关于socket"></a>关于socket</h6><p>首先是socket还好是跨平台支持，至于connect receive send就不说了，至于select epoll poll这些是服务端的东西.</p><p>创建socket connect之后就是手法数据了当然之前我们得定义好数据专属的协议使用json pb还是直接传byte.收到数据之后我们需要的是解析数据，解析之前得是完整的包吧需要处理粘包问题,解析之后当然是处理了，根据预定义的消息id或者名字分发到逻辑层进行处理.</p><h6 id="消息通信格式"><a href="#消息通信格式" class="headerlink" title="消息通信格式"></a>消息通信格式</h6><p>通常的消息格式是：长度+消息内容</p><p>消息内容：消息id+消息结构体</p><h6 id="消息编码"><a href="#消息编码" class="headerlink" title="消息编码"></a>消息编码</h6><p>使用pb或者json或者是使用struct</p><h6 id="消息接受"><a href="#消息接受" class="headerlink" title="消息接受"></a>消息接受</h6><p>开启一个读线程receive消息并且把消息放入消息缓冲区，然后读取消息缓冲区中完整的消息，需要读出长度信息在进行分别处理可能涉及多次receive.完整的消息结构字后放入消息队列，然后通过schedule将消息发送到cocos的逻辑层进行分发处理</p><h6 id="消息发送"><a href="#消息发送" class="headerlink" title="消息发送"></a>消息发送</h6><p>开启一个发送线程，逻辑层将消息编码后交给发送线程发送线程组装数据，加上长度信息然后发送给socket,这里需要队列，因为发送失败需要再次发送</p><h6 id="读线程"><a href="#读线程" class="headerlink" title="读线程"></a>读线程</h6><p>receive消息，解析消息。具体的消息结构最好在逻辑层解析</p><h6 id="写线程"><a href="#写线程" class="headerlink" title="写线程"></a>写线程</h6><p>处理发送操作涉及重发</p><h6 id="心跳包"><a href="#心跳包" class="headerlink" title="心跳包"></a>心跳包</h6><p>这个主要是看是否离线</p><h4 id="现成的轮子"><a href="#现成的轮子" class="headerlink" title="现成的轮子"></a>现成的轮子</h4><p>现成的轮子有很多，分门别类的介绍，例如有mqtt,kcp,sprotop,pbc,lpack,struct，bjson等</p><p><a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:bytemode/cocos2dx-socket.git</p><p><a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:bytemode/skynet_multithread_client_socket.git</p><p><a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:bytemode/sproto.git</p><p><a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:bytemode/pbc.git</p><p><a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:LuaDist/lpack.git</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;cocos2dx除了curllib和websocket其他的没有封装好用的网络库，尤其是使用socket的时候得自己分装网络层。网络层有哪些东西呢或者说我们要连接服务器收发数据需要怎样的流程？&lt;/p&gt;
&lt;p&gt;####### 自己造轮子&lt;/p&gt;
&lt;h6 id=&quot;关于socke
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx热更新机制</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E7%83%AD%E6%9B%B4%E6%96%B0%E6%9C%BA%E5%88%B6/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx热更新机制/</id>
    <published>2019-01-04T10:55:04.000Z</published>
    <updated>2019-01-07T07:41:17.029Z</updated>
    
    <content type="html"><![CDATA[<p>游戏脚本资源配置的更新，可以在游戏启动的时候，或者在游戏内更新。cocos2dx更新需要注意的是Lua文件的重新加载问题和纹理的重新加载的问题，纹理的加载需要注意合图文件的plist重新加载.游戏内更新需要注意的是更多需要小心处理精灵帧缓存纹理缓存和动画缓存</p><h4 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h4><p>热更新实现了项目资源和脚本文件的动态更新。当工程有新的改动时，用户无需重新下载完整的安装包，而是通过对比本地与最新的版本信息，仅下载有改动的文件到本地，完成版本的更新。cocos2dx3.10前版本存在问题后续经过改善基本没有问题。</p><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><p>工程的资源和脚本文件存放分2个地方，一个是安装目录，一个是数据目录，当app安装完后，安装目录则不再可写，此后所有的更新文件统一存放到数据目录当中，APP调用文件时，也优先搜索数据目录的文件，当数据目录中找不到文件时，再到安装目录中搜索。</p><p>配置文件分2种，project.manifest和version.manifest。服务器和客户端都存有备份，服务器存放着最新的版本配置文件，版本号最高，客户端每次启动前都会将服务器版本文件下载下来，并和本地配置文件对行对比，如果不是最新版本，则下载并安装补丁包。配置文件内容都是Json对象，且结构一样，只是version.manifest只存储了版本信息，project.manifest存储了版本信息和补丁信息。</p><p>project.manifest文件结构如下：</p><pre><code>{     &quot;packageUrl&quot; :&quot;xxxxx&quot;,     &quot;remoteManifestUrl&quot; :&quot;xxxxx/project.manifest&quot;,     &quot;remoteVersionUrl&quot; :&quot;xxxxx/version.manifest&quot;,     &quot;minVersion&quot;:&quot;1.0.0.0&quot;,     &quot;version&quot; : &quot;1.0.0.1&quot;,     &quot;assets&quot; : {            &quot;images.zip&quot; : {&quot;md5&quot; : &quot;xxxxxx&quot;,&quot;compressed&quot; : true }     },     &quot;searchPaths&quot; :[&quot;res&quot;,&quot;src&quot;]}</code></pre><ul><li>packageUrl表示服务器下载目录的根目录</li><li>remoteManifestUrl字段表示project.manifest文件的下载url</li><li>remoteVersionUrl字段表示version.manifest的下载url</li><li>minVersion 表示支持更新的最低版本，低于该版本则提示重新下载安装包。version字段表示工程的当前版本（如果配置文件是服务器上的，表示服务器的当前版本，如果是客户端的，则表示客户端的当前版本）</li><li>Assets字段表示要更新的资源列表，p1.zip为补丁包名（包全路径为xxxxx/p1.zip），md5字段为该补丁包的唯一标识，compressed表示下载完后是否需解压。</li><li>searchPaths表示要添加的搜索路径（。</li><li>Version.manifest文件结构与上同，但是没有assets字段。</li></ul><h4 id="更新流程"><a href="#更新流程" class="headerlink" title="更新流程"></a>更新流程</h4><ol><li><p>构造AssetsManagerEx对象<br>绑定下载成功、失败、进度的回调函数<br>设置下载文件的存放路径<br>加载本地project.manifest文件，若失败，则抛出消息ERROR_NO_LOCAL_MANIFEST，结束。</p></li><li><p>下载version.manifest启动更新</p></li></ol><p>下载version.manifest文件，若成功goto 3，否则下载project.manifest，若成功goto3，否则抛出ERROR_DOWNLOAD_MANIFEST，结束。</p><ol start="3"><li><p>版本比较<br>加载下载的配置文件并与本地project.manifest版本号进行对比，<br>若版本相同，则抛出消息ALREADY_UP_TO_DATE，结束。<br>若版本低于可更新版本号，则抛出NONUPDATABLE_VERSION，提示下载完整安装包，结束。<br>否则下载project.manifest加载下载的配置文件并与本地project.manifest版本号进行对比，<br>若版本相同，则抛出消息ALREADY_UP_TO_DATE，结束。<br>若版本低于可更新版本号，则抛出NONUPDATABLE_VERSION，提示下载完整安装包.</p></li><li><p>下载补丁包<br>清空下载记录，下载失败记录，解压记录<br>查看是否有未完成的下载记录，有则继续逐个下载（通过查看.temp文件）<br>获取本地assets和服务器asset差异列表，根据补丁包名：<br>a.如果本地有，服务器没有，则删除，<br>b.如果本地有，服务器也有，但md5不同，刚更新,<br>c.如果服务器有，本地没有，则添加</p></li><li><p>解压删除<br>依次解压列表中的文件。删除补丁包。结束。</p></li></ol><h4 id="流程图如下所示"><a href="#流程图如下所示" class="headerlink" title="流程图如下所示"></a>流程图如下所示</h4><p><img src="https://img-blog.csdnimg.cn/20190107150910349.png" alt="assetmanagerex"></p><h4 id="热更新时机"><a href="#热更新时机" class="headerlink" title="热更新时机"></a>热更新时机</h4><p>热更新一般在进入游戏之前也就是登录模块之后，也有放在登录模块之前.<br>需要确定好那些文件可以热更尤其是在执行热更新时有些已经加载的lua文件，再次require的时候不会重新加载，更新主要有两种情况，第一种是游戏启动更新，第二种是游戏内更新.</p><h5 id="游戏启动更新"><a href="#游戏启动更新" class="headerlink" title="游戏启动更新"></a>游戏启动更新</h5><p>全局基础的更新，此时需要注意框架层是否更新本次是否立即生效，更新之后可能需要对一些lua文件和游戏纹理资源配置资源重新加载，在重新加载纹理的时候需要尤其你注意</p><h4 id="游戏内更新"><a href="#游戏内更新" class="headerlink" title="游戏内更新"></a>游戏内更新</h4><p>对于有些游戏需要在游戏内下载子游戏包，此时需要做的是，每次退出子游戏需要全部清理掉纹理和lua资源，负责返回更新会导致更新不立即生效的问题</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;游戏脚本资源配置的更新，可以在游戏启动的时候，或者在游戏内更新。cocos2dx更新需要注意的是Lua文件的重新加载问题和纹理的重新加载的问题，纹理的加载需要注意合图文件的plist重新加载.游戏内更新需要注意的是更多需要小心处理精灵帧缓存纹理缓存和动画缓存&lt;/p&gt;
&lt;h4
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx资源管理</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx资源管理/</id>
    <published>2019-01-04T10:54:51.000Z</published>
    <updated>2019-01-07T08:01:13.473Z</updated>
    
    <content type="html"><![CDATA[<p>资源管理其实主要涉及lua脚本和图片资源.由于lua资源的gc和lua对c++对象的绑定和cocos2dx的各种缓存加上cocos2dx的autoreleasepool机制，是资源管理工作和内存管理需要同步进行，本文就先说cache然后内存.<br>cocos2dx在创建一个对象的时候是autorelease放入和当前的pool,帧渲染完成之后release一次，对于资源来说就是Sprite关联Texture2D关联Image.然后对于plist来说还有一个蛋疼的spriteframe.</p><h4 id="TextureCache"><a href="#TextureCache" class="headerlink" title="TextureCache"></a>TextureCache</h4><p>TextureCache纹理缓存。缓存的是加载到内存中的纹理资源。它到底有什么用呢？我先描述一个现象吧：假设游戏中有个界面用到的图片非常多，，第一次点进这界面时速度非常慢（因为要加载绘制很多图片），可第二次点击却一下子就进去了。这是为什么呢？原来Cocos2dx的渲染机制是可以重复使用同一份纹理在不同的场合进行绘制，从而达到重复使用，降低内存和GPU运算资源的消耗与开销。<br>第一次使用一个是先将图片加载进TextureCache缓存中，下一步是绘制图片，从而将其显示在场景中。<br>第二次使用，因为之前已经被放入TextureCache中，所以这里只需从缓存中找到这张图片，然后将其绘制出来就可以。</p><h4 id="SpriteFrameCache"><a href="#SpriteFrameCache" class="headerlink" title="SpriteFrameCache"></a>SpriteFrameCache</h4><p>缓存的是精灵帧，是纹理指定区域的矩形块。各精灵帧都在同一纹理中，通过切换不同的框帧来显示出不同的图案。<br>缓存就是SpriteFrame的缓存。跟TextureCache功能一样，不过跟TextureCache不同的是，如果内存池中不存在要查找的图片，它会提示找不到，而不会去本地加载图片。</p><h4 id="AnimationCache"><a href="#AnimationCache" class="headerlink" title="AnimationCache"></a>AnimationCache</h4><p>动画的缓存。对于精灵动画，每次创建时都需要加载精灵帧，然后按顺序添加到数组，再用Animation读取数组创建动画。这是一个非常烦琐的计算过程。而对于使用频率高的动画，例如角色的走动、跳舞等，可以将其加入到AnimationCache中，每次使用都从这个缓存中调用，这样可以有效的降低创建动画的巨大消耗。</p><h4 id="原理："><a href="#原理：" class="headerlink" title="原理："></a>原理：</h4><ul><li>TextureCache<br>原理是存在一个map,文理名字对应Texture2D对象。std::unordered_map&lt;std::string, Texture2D*&gt; _textures。</li><li>SpriteFrameCache<br>原理存在一个map,存储精灵帧的名字和精灵帧对象。Map&lt;std::string, SpriteFrame*&gt; _spriteFrames。</li><li>AnimationCache<br>原理存在一个map保存动画数据的名字和动画数据对象。Map&lt;std::string, Animation*&gt; _animations。</li></ul><h4 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h4><p>图片资源管理就是管理这些个cache，安全起见在合适的地方是需要清除动画缓存-&gt;精灵帧缓存-&gt;纹理缓存这样的顺序.如果引用出现问题，及时你removeunused这些都是不管用的.</p><h4 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h4><p>在源码分析中会详细讲解cocos的引用计数机制和智能指针</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;资源管理其实主要涉及lua脚本和图片资源.由于lua资源的gc和lua对c++对象的绑定和cocos2dx的各种缓存加上cocos2dx的autoreleasepool机制，是资源管理工作和内存管理需要同步进行，本文就先说cache然后内存.&lt;br&gt;cocos2dx在创建一
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx中使用ecs框架</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E4%B8%AD%E4%BD%BF%E7%94%A8ecs%E6%A1%86%E6%9E%B6/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx中使用ecs框架/</id>
    <published>2019-01-04T10:37:14.000Z</published>
    <updated>2019-01-04T10:37:44.850Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
      <category term="ecs" scheme="https://bytemode.github.io/tags/ecs/"/>
    
  </entry>
  
  <entry>
    <title>opengl帧缓冲</title>
    <link href="https://bytemode.github.io/2019/01/04/opengl%E5%B8%A7%E7%BC%93%E5%86%B2/"/>
    <id>https://bytemode.github.io/2019/01/04/opengl帧缓冲/</id>
    <published>2019-01-04T09:45:27.000Z</published>
    <updated>2019-01-04T09:59:58.636Z</updated>
    
    <content type="html"><![CDATA[<h4 id="缓冲区"><a href="#缓冲区" class="headerlink" title="缓冲区"></a>缓冲区</h4><p>用于写入颜色值的颜色缓冲、用于写入深度信息的深度缓冲和允许我们根据一些条件丢弃特定片段的模板缓冲。这些缓冲结合起来叫做帧缓冲(Framebuffer)，它被储存在内存中。OpenGL允许我们定义我们自己的帧缓冲，也就是说我们能够定义我们自己的颜色缓冲，甚至是深度缓冲和模板缓冲。</p><p>我们目前所做的所有操作都是在默认帧缓冲的渲染缓冲上进行的。默认的帧缓冲是在你创建窗口的时候生成和配置的（GLFW帮我们做了这些）。有了我们自己的帧缓冲，我们就能够有更多方式来渲染了。</p><h4 id="创建缓冲区"><a href="#创建缓冲区" class="headerlink" title="创建缓冲区"></a>创建缓冲区</h4><p>和OpenGL中的其它对象一样，我们会使用一个叫做glGenFramebuffers的函数来创建一个帧缓冲对象(Framebuffer Object, FBO)：</p><pre><code>unsigned int fbo;glGenFramebuffers(1, &amp;fbo);</code></pre><p>这种创建和使用对象的方式我们已经见过很多次了，所以它的使用函数也和其它的对象类似。首先我们创建一个帧缓冲对象，将它绑定为激活的(Active)帧缓冲，做一些操作，之后解绑帧缓冲。我们使用glBindFramebuffer来绑定帧缓冲。</p><pre><code>glBindFramebuffer(GL_FRAMEBUFFER, fbo);</code></pre><p>在绑定到GL_FRAMEBUFFER目标之后，所有的读取和写入帧缓冲的操作将会影响当前绑定的帧缓冲。</p><p>一个完整的帧缓冲需要满足以下的条件：</p><ul><li>附加至少一个缓冲（颜色、深度或模板缓冲）。</li><li>至少有一个颜色附件(Attachment)。</li><li>所有的附件都必须是完整的（保留了内存）。</li><li>每个缓冲都应该有相同的样本数。</li></ul><p>从上面的条件中可以知道，我们需要为帧缓冲创建一些附件，并将附件附加到帧缓冲上。在完成所有的条件之后，我们可以以GL_FRAMEBUFFER为参数调用glCheckFramebufferStatus，检查帧缓冲是否完整。它将会检测当前绑定的帧缓冲，并返回规范中这些值的其中之一。如果它返回的是GL_FRAMEBUFFER_COMPLETE，帧缓冲就是完整的了。</p><p>之后所有的渲染操作将会渲染到当前绑定帧缓冲的附件中。由于我们的帧缓冲不是默认帧缓冲，渲染指令将不会对窗口的视觉输出有任何影响。出于这个原因，渲染到一个不同的帧缓冲被叫做离屏渲染(Off-screen Rendering)。要保证所有的渲染操作在主窗口中有视觉效果，我们需要再次激活默认帧缓冲，将它绑定到0。</p><p><code>glBindFramebuffer(GL_FRAMEBUFFER, 0);</code></p><p>在完成所有的帧缓冲操作之后，不要忘记删除这个帧缓冲对象：</p><p><code>glDeleteFramebuffers(1, &amp;fbo);</code><br>在完整性检查执行之前，我们需要给帧缓冲附加一个附件。附件是一个内存位置，它能够作为帧缓冲的一个缓冲，可以将它想象为一个图像。当创建一个附件的时候我们有两个选项：<br><strong>纹理或渲染缓冲对象(Renderbuffer Object)</strong></p><h4 id="纹理附件"><a href="#纹理附件" class="headerlink" title="纹理附件"></a>纹理附件</h4><p>当把一个纹理附加到帧缓冲的时候，所有的渲染指令将会写入到这个纹理中，就想它是一个普通的颜色/深度或模板缓冲一样。使用纹理的优点是，所有渲染操作的结果将会被储存在一个纹理图像中，我们之后可以在着色器中很方便地使用它。</p><h5 id="为帧缓冲创建一个纹理和创建一个普通的纹理差不多："><a href="#为帧缓冲创建一个纹理和创建一个普通的纹理差不多：" class="headerlink" title="为帧缓冲创建一个纹理和创建一个普通的纹理差不多："></a>为帧缓冲创建一个纹理和创建一个普通的纹理差不多：</h5><pre><code>unsigned int texture;glGenTextures(1, &amp;texture);glBindTexture(GL_TEXTURE_2D, texture);glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);</code></pre><p>主要的区别就是，我们将维度设置为了屏幕大小（，并且我们给纹理的data参数传递了NULL。对于这个纹理，我们仅仅分配了内存而没有填充它。填充这个纹理将会在我们渲染到帧缓冲之后来进行。同样注意我们并不关心环绕方式或多级渐远纹理，我们在大多数情况下都不会需要它们。</p><p>如果你想将你的屏幕渲染到一个更小或更大的纹理上，你需要（在渲染到你的帧缓冲之前）再次调用glViewport，使用纹理的新维度作为参数，否则只有一小部分的纹理或屏幕会被渲染到这个纹理上。</p><h5 id="现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了"><a href="#现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了" class="headerlink" title="现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了"></a>现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了</h5><pre><code>glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texture, 0);</code></pre><p>glFrameBufferTexture2D有以下的参数：</p><p>target：帧缓冲的目标（绘制、读取或者两者皆有）<br>attachment：我们想要附加的附件类型。当前我们正在附加一个颜色附件。注意最后的0意味着我们可以附加多个颜色附件。我们将在之后的教程中提到。<br>textarget：你希望附加的纹理类型<br>texture：要附加的纹理本身<br>level：多级渐远纹理的级别。我们将它保留为0。<br>除了颜色附件之外，我们还可以附加一个深度和模板缓冲纹理到帧缓冲对象中。要附加深度缓冲的话，我们将附件类型设置为GL_DEPTH_ATTACHMENT。注意纹理的格式(Format)和内部格式(Internalformat)类型将变为GL_DEPTH_COMPONENT，来反映深度缓冲的储存格式。要附加模板缓冲的话，你要将第二个参数设置为GL_STENCIL_ATTACHMENT，并将纹理的格式设定为GL_STENCIL_INDEX。</p><h5 id="也可以将深度缓冲和模板缓冲附加为一个单独的纹理。"><a href="#也可以将深度缓冲和模板缓冲附加为一个单独的纹理。" class="headerlink" title="也可以将深度缓冲和模板缓冲附加为一个单独的纹理。"></a>也可以将深度缓冲和模板缓冲附加为一个单独的纹理。</h5><p>纹理的每32位数值将包含24位的深度信息和8位的模板信息。要将深度和模板缓冲附加为一个纹理的话，我们使用GL_DEPTH_STENCIL_ATTACHMENT类型，并配置纹理的格式，让它包含合并的深度和模板值。将一个深度和模板缓冲附加为一个纹理到帧缓冲的例子可以在下面找到：</p><pre><code>glTexImage2D(  GL_TEXTURE_2D, 0, GL_DEPTH24_STENCIL8, 800, 600, 0,   GL_DEPTH_STENCIL, GL_UNSIGNED_INT_24_8, NULL);glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_TEXTURE_2D, texture, 0);</code></pre><h4 id="渲染缓冲对象附件"><a href="#渲染缓冲对象附件" class="headerlink" title="渲染缓冲对象附件"></a>渲染缓冲对象附件</h4><p>渲染缓冲对象(Renderbuffer Object)是在纹理之后引入到OpenGL中，作为一个可用的帧缓冲附件类型的，所以在过去纹理是唯一可用的附件。和纹理图像一样，渲染缓冲对象是一个真正的缓冲，即一系列的字节、整数、像素等。渲染缓冲对象附加的好处是，它会将数据储存为OpenGL原生的渲染格式，它是为离屏渲染到帧缓冲优化过的。</p><p>渲染缓冲对象直接将所有的渲染数据储存到它的缓冲中，不会做任何针对纹理格式的转换，让它变为一个更快的可写储存介质。然而，渲染缓冲对象通常都是只写的，所以你不能读取它们（比如使用纹理访问）。当然你仍然还是能够使用glReadPixels来读取它，这会从当前绑定的帧缓冲，而不是附件本身，中返回特定区域的像素。</p><p>因为它的数据已经是原生的格式了，当写入或者复制它的数据到其它缓冲中时是非常快的。所以，交换缓冲这样的操作在使用渲染缓冲对象时会非常快。我们在每个渲染迭代最后使用的glfwSwapBuffers，也可以通过渲染缓冲对象实现：只需要写入一个渲染缓冲图像，并在最后交换到另外一个渲染缓冲就可以了。渲染缓冲对象对这种操作非常完美。</p><p>创建一个渲染缓冲对象的代码和帧缓冲的代码很类似：</p><pre><code>unsigned int rbo;glGenRenderbuffers(1, &amp;rbo);</code></pre><p>类似，我们需要绑定这个渲染缓冲对象，让之后所有的渲染缓冲操作影响当前的rbo：</p><pre><code>glBindRenderbuffer(GL_RENDERBUFFER, rbo);</code></pre><p>由于渲染缓冲对象通常都是只写的，它们会经常用于深度和模板附件，因为大部分时间我们都不需要从深度和模板缓冲中读取值，只关心深度和模板测试。我们需要深度和模板值用于测试，但不需要对它们进行采样，所以渲染缓冲对象非常适合它们。当我们不需要从这些缓冲中采样的时候，通常都会选择渲染缓冲对象，因为它会更优化一点。</p><p>创建一个深度和模板渲染缓冲对象可以通过调用glRenderbufferStorage函数来完成：</p><pre><code>glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, 800, 600);</code></pre><p>创建一个渲染缓冲对象和纹理对象类似，不同的是这个对象是专门被设计作为图像使用的，而不是纹理那样的通用数据缓冲(General Purpose Data Buffer)。这里我们选择GL_DEPTH24_STENCIL8作为内部格式，它封装了24位的深度和8位的模板缓冲。</p><p>最后一件事就是附加这个渲染缓冲对象：</p><pre><code>glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo);</code></pre><p>渲染缓冲对象能为你的帧缓冲对象提供一些优化，但知道什么时候使用渲染缓冲对象，什么时候使用纹理是很重要的。通常的规则是，如果你不需要从一个缓冲中采样数据，那么对这个缓冲使用渲染缓冲对象会是明智的选择。如果你需要从缓冲中采样颜色或深度值等数据，那么你应该选择纹理附件。性能方面它不会产生非常大的影响的。</p><h4 id="渲染到纹理"><a href="#渲染到纹理" class="headerlink" title="渲染到纹理"></a>渲染到纹理</h4><p>既然我们已经知道帧缓冲（大概）是怎么工作的了，是时候实践它们了。我们将会将场景渲染到一个附加到帧缓冲对象上的颜色纹理中，之后将在一个横跨整个屏幕的四边形上绘制这个纹理。这样视觉输出和没使用帧缓冲时是完全一样的，但这次是打印到了一个四边形上。这为什么很有用呢？我们会在下一部分中知道原因。</p><ol><li>首先要创建一个帧缓冲对象，并绑定它，这些都很直观：</li></ol><pre><code>unsigned int framebuffer;glGenFramebuffers(1, &amp;framebuffer);glBindFramebuffer(GL_FRAMEBUFFER, framebuffer);</code></pre><ol start="2"><li>接下来我们需要创建一个纹理图像，我们将它作为一个颜色附件附加到帧缓冲上。<br>我们将纹理的维度设置为窗口的宽度和高度，并且不初始化它的数据：</li></ol><pre><code>// 生成纹理unsigned int texColorBuffer;glGenTextures(1, &amp;texColorBuffer);glBindTexture(GL_TEXTURE_2D, texColorBuffer);glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR );glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);glBindTexture(GL_TEXTURE_2D, 0);// 将它附加到当前绑定的帧缓冲对象glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texColorBuffer, 0);  </code></pre><ol start="3"><li>添加一个深度（和模板）附件到帧缓冲中。<br>由于我们只希望采样颜色缓冲，而不是其它的缓冲，我们可以为它们创建一个渲染缓冲对象。</li></ol><p>创建一个渲染缓冲对象不是非常复杂。我们需要记住的唯一事情是，我们将它创建为一个深度和模板附件渲染缓冲对象。我们将它的内部格式设置为GL_DEPTH24_STENCIL8。</p><pre><code>unsigned int rbo;glGenRenderbuffers(1, &amp;rbo);glBindRenderbuffer(GL_RENDERBUFFER, rbo); glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, 800, 600);  glBindRenderbuffer(GL_RENDERBUFFER, 0);</code></pre><p>当我们为渲染缓冲对象分配了足够的内存之后，我们可以解绑这个渲染缓冲。</p><ol start="4"><li>将渲染缓冲对象附加到帧缓冲的深度和模板附件上：</li></ol><pre><code>glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo);</code></pre><p>要想绘制场景到一个纹理上，我们需要采取以下的步骤：</p><ul><li>将新的帧缓冲绑定为激活的帧缓冲，和往常一样渲染场景</li><li>绑定默认的帧缓冲</li><li>绘制一个横跨整个屏幕的四边形，将帧缓冲的颜色缓冲作为它的纹理。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;缓冲区&quot;&gt;&lt;a href=&quot;#缓冲区&quot; class=&quot;headerlink&quot; title=&quot;缓冲区&quot;&gt;&lt;/a&gt;缓冲区&lt;/h4&gt;&lt;p&gt;用于写入颜色值的颜色缓冲、用于写入深度信息的深度缓冲和允许我们根据一些条件丢弃特定片段的模板缓冲。这些缓冲结合起来叫做帧缓冲(Fra
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl测试操作</title>
    <link href="https://bytemode.github.io/2019/01/04/opengl%E6%B5%8B%E8%AF%95%E6%93%8D%E4%BD%9C/"/>
    <id>https://bytemode.github.io/2019/01/04/opengl测试操作/</id>
    <published>2019-01-04T09:19:45.000Z</published>
    <updated>2019-01-04T09:38:05.122Z</updated>
    
    <content type="html"><![CDATA[<h4 id="深度测试"><a href="#深度测试" class="headerlink" title="深度测试"></a>深度测试</h4><p>深度缓冲(Depth Buffer)来防止被阻挡的面渲染到其它面的前面。在这一节中，我们将会更加深入地讨论这些储存在深度缓冲（或z缓冲(z-buffer)）中的深度值(Depth Value)，以及它们是如何确定一个片段是处于其它片段后方的。</p><p>深度缓冲就像颜色缓冲(Color Buffer)（储存所有的片段颜色：视觉输出）一样，在每个片段中储存了信息，并且（通常）和颜色缓冲有着一样的宽度和高度。深度缓冲是由窗口系统自动创建的，它会以16、24或32位float的形式储存它的深度值。在大部分的系统中，深度缓冲的精度都是24位的。</p><p>当深度测试(Depth Testing)被启用的时候，OpenGL会将一个片段的的深度值与深度缓冲的内容进行对比。OpenGL会执行一个深度测试，如果这个测试通过了的话，深度缓冲将会更新为新的深度值。如果深度测试失败了，片段将会被丢弃。</p><p>深度缓冲是在片段着色器运行之后（以及模板测试(Stencil Testing)运行之后，我们将在下一节中讨论）在屏幕空间中运行的。屏幕空间坐标与通过OpenGL的glViewport所定义的视口密切相关，并且可以直接使用GLSL内建变量gl_FragCoord从片段着色器中直接访问。gl_FragCoord的x和y分量代表了片段的屏幕空间坐标（其中(0, 0)位于左下角）。gl_FragCoord中也包含了一个z分量，它包含了片段真正的深度值。z值就是需要与深度缓冲内容所对比的那个值。</p><h5 id="开启关闭深度测试"><a href="#开启关闭深度测试" class="headerlink" title="开启关闭深度测试"></a>开启关闭深度测试</h5><p>深度测试默认是禁用的，所以如果要启用深度测试的话，我们需要用GL_DEPTH_TEST选项来启用它：</p><p><code>glEnable(GL_DEPTH_TEST);</code><br>当它启用的时候，如果一个片段通过了深度测试的话，OpenGL会在深度缓冲中储存该片段的z值；如果没有通过深度缓冲，则会丢弃该片段。如果你启用了深度缓冲，你还应该在每个渲染迭代之前使用GL_DEPTH_BUFFER_BIT来清除深度缓冲，否则你会仍在使用上一次渲染迭代中的写入的深度值：</p><p><code>glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</code><br>可以想象，在某些情况下你会需要对所有片段都执行深度测试并丢弃相应的片段，但不希望更新深度缓冲。基本上来说，你在使用一个只读的(Read-only)深度缓冲。OpenGL允许我们禁用深度缓冲的写入，只需要设置它的深度掩码(Depth Mask)设置为GL_FALSE就可以了：</p><p><code>glDepthMask(GL_FALSE);</code><br>注意这只在深度测试被启用的时候才有效果。</p><h5 id="深度测试函数"><a href="#深度测试函数" class="headerlink" title="深度测试函数"></a>深度测试函数</h5><p>OpenGL允许我们修改深度测试中使用的比较运算符。这允许我们来控制OpenGL什么时候该通过或丢弃一个片段，什么时候去更新深度缓冲。我们可以调用glDepthFunc函数来设置比较运算符（或者说深度函数(Depth Function)）：</p><p><code>glDepthFunc(GL_LESS);</code><br>这个函数接受下面表格中的比较运算符：</p><p>函数    描述<br>GL_ALWAYS    永远通过深度测试<br>GL_NEVER    永远不通过深度测试<br>GL_LESS    在片段深度值小于缓冲的深度值时通过测试<br>GL_EQUAL    在片段深度值等于缓冲区的深度值时通过测试<br>GL_LEQUAL    在片段深度值小于等于缓冲区的深度值时通过测试<br>GL_GREATER    在片段深度值大于缓冲区的深度值时通过测试<br>GL_NOTEQUAL    在片段深度值不等于缓冲区的深度值时通过测试<br>GL_GEQUAL    在片段深度值大于等于缓冲区的深度值时通过测试<br>默认情况下使用的深度函数是GL_LESS，它将会丢弃深度值大于等于当前深度缓冲值的所有片段。</p><h4 id="模板测试"><a href="#模板测试" class="headerlink" title="模板测试"></a>模板测试</h4><p>当片段着色器处理完一个片段之后，模板测试(Stencil Test)会开始执行，和深度测试一样，它也可能会丢弃片段。接下来，被保留的片段会进入深度测试，它可能会丢弃更多的片段。模板测试是根据又一个缓冲来进行的，它叫做模板缓冲(Stencil Buffer)，我们可以在渲染的时候更新它来获得一些很有意思的效果。</p><p>一个模板缓冲中，（通常）每个模板值(Stencil Value)是8位的。所以每个像素/片段一共能有256种不同的模板值。我们可以将这些模板值设置为我们想要的值，然后当某一个片段有某一个模板值的时候，我们就可以选择丢弃或是保留这个片段了。</p><p>模板缓冲的一个简单的例子如下：<br><img src="https://img-blog.csdnimg.cn/20190104173216959.png" alt="模板测试"></p><p>模板缓冲首先会被清除为0，之后在模板缓冲中使用1填充了一个空心矩形。场景中的片段将会只在片段的模板值为1的时候会被渲染（其它的都被丢弃了）。</p><p>模板缓冲操作允许我们在渲染片段时将模板缓冲设定为一个特定的值。通过在渲染时修改模板缓冲的内容，我们写入了模板缓冲。在同一个（或者接下来的）渲染迭代中，我们可以读取这些值，来决定丢弃还是保留某个片段。使用模板缓冲的时候你可以尽情发挥，但大体的步骤如下：</p><ul><li>启用模板缓冲的写入。</li><li>渲染物体，更新模板缓冲的内容。</li><li>禁用模板缓冲的写入。</li><li>渲染（其它）物体，这次根据模板缓冲的内容丢弃特定的片段。<br>所以，通过使用模板缓冲，我们可以根据场景中已绘制的其它物体的片段，来决定是否丢弃特定的片段。</li></ul><h5 id="开启关闭模板测试"><a href="#开启关闭模板测试" class="headerlink" title="开启关闭模板测试"></a>开启关闭模板测试</h5><p>你可以启用GL_STENCIL_TEST来启用模板测试。在这一行代码之后，所有的渲染调用都会以某种方式影响着模板缓冲。</p><p><code>glEnable(GL_STENCIL_TEST);</code><br>注意，和颜色和深度缓冲一样，你也需要在每次迭代之前清除模板缓冲。</p><p><code>glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT);</code><br>和深度测试的glDepthMask函数一样，模板缓冲也有一个类似的函数。glStencilMask允许我们设置一个位掩码(Bitmask)，它会与将要写入缓冲的模板值进行与(AND)运算。默认情况下设置的位掩码所有位都为1，不影响输出，但如果我们将它设置为0x00，写入缓冲的所有模板值最后都会变成0.这与深度测试中的glDepthMask(GL_FALSE)是等价的。</p><pre><code>glStencilMask(0xFF); // 每一位写入模板缓冲时都保持原样glStencilMask(0x00); // 每一位在写入模板缓冲时都会变成0（禁用写入）</code></pre><p>大部分情况下你都只会使用0x00或者0xFF作为模板掩码(Stencil Mask)，但是知道有选项可以设置自定义的位掩码总是好的。</p><h5 id="模板测试函数"><a href="#模板测试函数" class="headerlink" title="模板测试函数"></a>模板测试函数</h5><p>和深度测试一样，我们对模板缓冲应该通过还是失败，以及它应该如何影响模板缓冲，也是有一定控制的。一共有两个函数能够用来配置模板测试：glStencilFunc和glStencilOp。</p><p><code>glStencilFunc(GLenum func, GLint ref, GLuint mask)</code><br>一共包含三个参数：</p><ul><li>func：设置模板测试函数(Stencil Test Function)。这个测试函数将会应用到已储存的模板值上和glStencilFunc函数的ref值上。可用的选项有：GL_NEVER、GL_LESS、GL_LEQUAL、GL_GREATER、GL_GEQUAL、GL_EQUAL、GL_NOTEQUAL和GL_ALWAYS。它们的语义和深度缓冲的函数类似。</li><li>ref：设置了模板测试的参考值(Reference Value)。模板缓冲的内容将会与这个值进行比较。</li><li>mask：设置一个掩码，它将会与参考值和储存的模板值在测试比较它们之前进行与(AND)运算。初始情况下所有位都为1。</li></ul><p>在一开始的那个简单的模板例子中，函数被设置为：</p><p><code>glStencilFunc(GL_EQUAL, 1, 0xFF)</code><br>这会告诉OpenGL，只要一个片段的模板值等于(GL_EQUAL)参考值1，片段将会通过测试并被绘制，否则会被丢弃。</p><p>但是glStencilFunc仅仅描述了OpenGL应该对模板缓冲内容做什么，而不是我们应该如何更新缓冲。这就需要glStencilOp这个函数了。</p><p><code>glStencilOp(GLenum sfail, GLenum dpfail, GLenum dppass)</code><br>一共包含三个选项，我们能够设定每个选项应该采取的行为：</p><ul><li>sfail：模板测试失败时采取的行为。</li><li>dpfail：模板测试通过，但深度测试失败时采取的行为。</li><li>dppass：模板测试和深度测试都通过时采取的行为。<br>每个选项都可以选用以下的其中一种行为：</li></ul><p>行为    描述<br>GL_KEEP    保持当前储存的模板值<br>GL_ZERO    将模板值设置为0<br>GL_REPLACE    将模板值设置为glStencilFunc函数设置的ref值<br>GL_INCR    如果模板值小于最大值则将模板值加1<br>GL_INCR_WRAP    与GL_INCR一样，但如果模板值超过了最大值则归零<br>GL_DECR    如果模板值大于最小值则将模板值减1<br>GL_DECR_WRAP    与GL_DECR一样，但如果模板值小于0则将其设置为最大值<br>GL_INVERT    按位翻转当前的模板缓冲值<br>默认情况下glStencilOp是设置为(GL_KEEP, GL_KEEP, GL_KEEP)的，所以不论任何测试的结果是如何，模板缓冲都会保留它的值。默认的行为不会更新模板缓冲，所以如果你想写入模板缓冲的话，你需要至少对其中一个选项设置不同的值。</p><p>所以，通过使用glStencilFunc和glStencilOp，我们可以<strong>精确地指定更新模板缓冲的时机与行为了，我们也可以指定什么时候该让模板缓冲通过，即什么时候片段需要被丢弃</strong>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;深度测试&quot;&gt;&lt;a href=&quot;#深度测试&quot; class=&quot;headerlink&quot; title=&quot;深度测试&quot;&gt;&lt;/a&gt;深度测试&lt;/h4&gt;&lt;p&gt;深度缓冲(Depth Buffer)来防止被阻挡的面渲染到其它面的前面。在这一节中，我们将会更加深入地讨论这些储存在深度缓冲
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl光照</title>
    <link href="https://bytemode.github.io/2019/01/04/opengl%E5%85%89%E7%85%A7/"/>
    <id>https://bytemode.github.io/2019/01/04/opengl光照/</id>
    <published>2019-01-04T08:59:45.000Z</published>
    <updated>2019-01-04T09:18:38.849Z</updated>
    
    <content type="html"><![CDATA[<h4 id="基础光照"><a href="#基础光照" class="headerlink" title="基础光照"></a>基础光照</h4><p>这些光照模型都是基于我们对光的物理特性的理解。其中一个模型被称为冯氏光照模型(Phong Lighting Model)。冯氏光照模型的主要结构由3个分量组成：环境(Ambient)、漫反射(Diffuse)和镜面(Specular)光照。下面这张图展示了这些光照分量看起来的样子：<br><img src="https://img-blog.csdnimg.cn/2019010417032766.png" alt="基础光照"></p><ul><li>环境光照(Ambient Lighting)：即使在黑暗的情况下，世界上通常也仍然有一些光亮（月亮、远处的光），所以物体几乎永远不会是完全黑暗的。为了模拟这个，我们会使用一个环境光照常量，它永远会给物体一些颜色。</li><li>漫反射光照(Diffuse Lighting)：模拟光源对物体的方向性影响(Directional Impact)。它是冯氏光照模型中视觉上最显著的分量。物体的某一部分越是正对着光源，它就会越亮。</li><li>镜面光照(Specular Lighting)：模拟有光泽物体上面出现的亮点。镜面光照的颜色相比于物体的颜色会更倾向于光的颜色。</li></ul><h4 id="材质"><a href="#材质" class="headerlink" title="材质"></a>材质</h4><p>在现实世界里，每个物体会对光产生不同的反应。比如说，钢看起来通常会比陶瓷花瓶更闪闪发光，木头箱子也不会像钢制箱子那样对光产生很强的反射。每个物体对镜面高光也有不同的反应。有些物体反射光的时候不会有太多的散射(Scatter)，因而产生一个较小的高光点，而有些物体则会散射很多，产生一个有着更大半径的高光点。如果我们想要在OpenGL中模拟多种类型的物体，我们必须为每个物体分别定义一个材质(Material)属性。</p><p>我们指定了一个物体和光的颜色，以及结合环境光和镜面强度分量，来定义物体的视觉输出。当描述一个物体的时候，我们可以用这三个分量来定义一个材质颜色(Material Color)：环境光照(Ambient Lighting)、漫反射光照(Diffuse Lighting)和镜面光照(Specular Lighting)。通过为每个分量指定一个颜色，我们就能够对物体的颜色输出有着精细的控制了。现在，我们再添加反光度(Shininess)这个分量到上述的三个颜色中，这就有我们需要的所有材质属性了.</p><h4 id="光照贴图"><a href="#光照贴图" class="headerlink" title="光照贴图"></a>光照贴图</h4><p>漫反射和镜面光贴图(Map)。这允许我们对物体的漫反射分量（以及间接地对环境光分量，它们几乎总是一样的）和镜面光分量有着更精确的控制。</p><h4 id="投光物"><a href="#投光物" class="headerlink" title="投光物"></a>投光物</h4><h5 id="平行光"><a href="#平行光" class="headerlink" title="平行光"></a>平行光</h5><p>当一个光源处于很远的地方时，来自光源的每条光线就会近似于互相平行。不论物体和/或者观察者的位置，看起来好像所有的光都来自于同一个方向。当我们使用一个假设光源处于无限远处的模型时，它就被称为定向光，因为它的所有光线都有着相同的方向，它与光源的位置是没有关系的。</p><p>定向光非常好的一个例子就是太阳。太阳距离我们并不是无限远，但它已经远到在光照计算中可以把它视为无限远了。所以来自太阳的所有光线将被模拟为平行光线，我们可以在下图看到：</p><p><img src="https://img-blog.csdnimg.cn/20190104171451975.png" alt="平行光"></p><p>因为所有的光线都是平行的，所以物体与光源的相对位置是不重要的，因为对场景中每一个物体光的方向都是一致的。由于光的位置向量保持一致，场景中每个物体的光照计算将会是类似的。</p><h5 id="点光源"><a href="#点光源" class="headerlink" title="点光源"></a>点光源</h5><p>定向光对于照亮整个场景的全局光源是非常棒的，但除了定向光之外我们也需要一些分散在场景中的点光源(Point Light)。点光源是处于世界中某一个位置的光源，它会朝着所有方向发光，但光线会随着距离逐渐衰减。想象作为投光物的灯泡和火把，它们都是点光源。<br><img src="https://img-blog.csdnimg.cn/20190104171517360.png" alt="点光源"></p><h5 id="聚光源"><a href="#聚光源" class="headerlink" title="聚光源"></a>聚光源</h5><p>聚光是位于环境中某个位置的光源，它只朝一个特定方向而不是所有方向照射光线。这样的结果就是只有在聚光方向的特定半径内的物体才会被照亮，其它的物体都会保持黑暗。聚光很好的例子就是路灯或手电筒。</p><p>OpenGL中聚光是用一个世界空间位置、一个方向和一个切光角(Cutoff Angle)来表示的，切光角指定了聚光的半径（译注：是圆锥的半径不是距光源距离那个半径）。对于每个片段，我们会计算片段是否位于聚光的切光方向之间（也就是在锥形内），如果是的话，我们就会相应地照亮片段。下面这张图会让你明白聚光是如何工作的：</p><p><img src="https://img-blog.csdnimg.cn/20190104171634805.png" alt="聚光源"></p><p>LightDir：从片段指向光源的向量。<br>SpotDir：聚光所指向的方向。<br>Phiϕ：指定了聚光半径的切光角。落在这个角度之外的物体都不会被这个聚光所照亮。<br>Thetaθ：LightDir向量和SpotDir向量之间的夹角。在聚光内部的话θ值应该比ϕ值小。<br>所以我们要做的就是计算LightDir向量和SpotDir向量之间的点积（还记得它会返回两个单位向量夹角的余弦值吗？），并将它与切光角ϕ值对比。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;基础光照&quot;&gt;&lt;a href=&quot;#基础光照&quot; class=&quot;headerlink&quot; title=&quot;基础光照&quot;&gt;&lt;/a&gt;基础光照&lt;/h4&gt;&lt;p&gt;这些光照模型都是基于我们对光的物理特性的理解。其中一个模型被称为冯氏光照模型(Phong Lighting Model)。冯
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl摄像机</title>
    <link href="https://bytemode.github.io/2019/01/04/opengl%E6%91%84%E5%83%8F%E6%9C%BA/"/>
    <id>https://bytemode.github.io/2019/01/04/opengl摄像机/</id>
    <published>2019-01-04T08:35:12.000Z</published>
    <updated>2019-01-04T08:52:23.234Z</updated>
    
    <content type="html"><![CDATA[<h4 id="摄像机-观察空间"><a href="#摄像机-观察空间" class="headerlink" title="摄像机/观察空间"></a>摄像机/观察空间</h4><p>当我们讨论摄像机/观察空间(Camera/View Space)的时候，是在讨论以摄像机的视角作为场景原点时场景中所有的顶点坐标：观察矩阵把所有的世界坐标变换为相对于摄像机位置与方向的观察坐标。要定义一个摄像机，我们需要它在世界空间中的位置、观察的方向、一个指向它右测的向量以及一个指向它上方的向量。细心的读者可能已经注意到我们实际上创建了一个三个单位轴相互垂直的、以摄像机的位置为原点的坐标系。</p><ol><li>摄像机位置</li></ol><p>获取摄像机位置很简单。摄像机位置简单来说就是世界空间中一个指向摄像机位置的向量。我们把摄像机位置设置为上一节中的那个相同的位置：</p><p><code>glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f);</code><br>不要忘记正z轴是从屏幕指向你的，如果我们希望摄像机向后移动，我们就沿着z轴的正方向移动。</p><ol start="2"><li>摄像机方向</li></ol><p>下一个需要的向量是摄像机的方向，这里指的是摄像机指向哪个方向。现在我们让摄像机指向场景原点：(0, 0, 0)。还记得如果将两个矢量相减，我们就能得到这两个矢量的差吗？用场景原点向量减去摄像机位置向量的结果就是摄像机的指向向量。由于我们知道摄像机指向z轴负方向，但我们希望方向向量(Direction Vector)指向摄像机的z轴正方向。如果我们交换相减的顺序，我们就会获得一个指向摄像机正z轴方向的向量：</p><pre><code>glm::vec3 cameraTarget = glm::vec3(0.0f, 0.0f, 0.0f);glm::vec3 cameraDirection = glm::normalize(cameraPos - cameraTarget);</code></pre><p>方向向量(Direction Vector)并不是最好的名字，因为它实际上指向从它到目标向量的相反方向（译注：注意看前面的那个图，蓝色的方向向量大概指向z轴的正方向，与摄像机实际指向的方向是正好相反的）。</p><ol start="3"><li>右轴<br>我们需要的另一个向量是一个右向量(Right Vector)，它代表摄像机空间的x轴的正方向。为获取右向量我们需要先使用一个小技巧：先定义一个上向量(Up Vector)。接下来把上向量和第二步得到的方向向量进行叉乘。两个向量叉乘的结果会同时垂直于两向量，因此我们会得到指向x轴正方向的那个向量（如果我们交换两个向量叉乘的顺序就会得到相反的指向x轴负方向的向量）：</li></ol><pre><code>glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection));</code></pre><ol start="4"><li>上轴<br>现在我们已经有了x轴向量和z轴向量，获取一个指向摄像机的正y轴向量就相对简单了：我们把右向量和方向向量进行叉乘：</li></ol><pre><code>glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight);</code></pre><h4 id="LookAt"><a href="#LookAt" class="headerlink" title="LookAt"></a>LookAt</h4><p>你可以用这3个轴外加一个平移向量来创建一个矩阵，并且你可以用这个矩阵乘以任何向量来将其变换到那个坐标空间。这正是LookAt矩阵所做的，现在我们有了3个相互垂直的轴和一个定义摄像机空间的位置坐标，我们可以创建我们自己的LookAt矩阵了：<br><img src="https://img-blog.csdnimg.cn/20190104164558286.png" alt="lookat矩阵"></p><p>其中R是右向量，U是上向量，D是方向向量P是摄像机位置向量。注意，位置向量是相反的，因为我们最终希望把世界平移到与我们自身移动的相反方向。把这个LookAt矩阵作为观察矩阵可以很高效地把所有世界坐标变换到刚刚定义的观察空间。LookAt矩阵就像它的名字表达的那样：它会创建一个看着(Look at)给定目标的观察矩阵。</p><p>接着GLM就会创建一个LookAt矩阵，我们可以把它当作我们的观察矩阵：</p><pre><code>glm::mat4 view;view = glm::lookAt(glm::vec3(0.0f, 0.0f, 3.0f),            glm::vec3(0.0f, 0.0f, 0.0f),            glm::vec3(0.0f, 1.0f, 0.0f));</code></pre><p>glm::LookAt函数需要一个位置、目标和上向量。它会创建一个和在上面使用的一样的观察矩阵。</p><h4 id="摄像机移动"><a href="#摄像机移动" class="headerlink" title="摄像机移动"></a>摄像机移动</h4><p>让摄像机绕着场景转的确很有趣，但是让我们自己移动摄像机会更有趣！首先我们必须设置一个摄像机系统，所以在我们的程序前面定义一些摄像机变量很有用：</p><pre><code>glm::vec3 cameraPos   = glm::vec3(0.0f, 0.0f,  3.0f);glm::vec3 cameraFront = glm::vec3(0.0f, 0.0f, -1.0f);glm::vec3 cameraUp    = glm::vec3(0.0f, 1.0f,  0.0f);view = glm::lookAt(cameraPos, cameraPos + cameraFront, cameraUp);</code></pre><p>我们首先将摄像机位置设置为之前定义的cameraPos。方向是当前的位置加上我们刚刚定义的方向向量。这样能保证无论我们怎么移动，摄像机都会注视着目标方向。让我们摆弄一下这些向量，在按下某些按钮时更新cameraPos向量。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;摄像机-观察空间&quot;&gt;&lt;a href=&quot;#摄像机-观察空间&quot; class=&quot;headerlink&quot; title=&quot;摄像机/观察空间&quot;&gt;&lt;/a&gt;摄像机/观察空间&lt;/h4&gt;&lt;p&gt;当我们讨论摄像机/观察空间(Camera/View Space)的时候，是在讨论以摄像机的视
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl坐标系统</title>
    <link href="https://bytemode.github.io/2019/01/04/%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F/"/>
    <id>https://bytemode.github.io/2019/01/04/坐标系统/</id>
    <published>2019-01-04T03:44:40.000Z</published>
    <updated>2019-01-04T08:22:14.599Z</updated>
    
    <content type="html"><![CDATA[<h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>为了将坐标从一个坐标系变换到另一个坐标系，我们需要用到几个变换矩阵，最重要的几个分别是模型(Model)、观察(View)、投影(Projection)三个矩阵。我们的顶点坐标起始于局部空间(Local Space)，在这里它称为局部坐标(Local Coordinate)，它在之后会变为世界坐标(World Coordinate)，观察坐标(View Coordinate)，裁剪坐标(Clip Coordinate)，并最后以屏幕坐标(Screen Coordinate)的形式结束。下面的这张图展示了整个流程以及各个变换过程做了什么：</p><p><img src="https://img-blog.csdnimg.cn/20190104114754479.png" alt="坐标系统"></p><ol><li>局部坐标是对象相对于局部原点的坐标，也是物体起始的坐标。</li><li>下一步是将局部坐标变换为世界空间坐标，世界空间坐标是处于一个更大的空间范围的。这些坐标相对于世界的全局原点，它们会和其它物体一起相对于世界的原点进行摆放。</li><li>接下来我们将世界坐标变换为观察空间坐标，使得每个坐标都是从摄像机或者说观察者的角度进行观察的。</li><li>坐标到达观察空间之后，我们需要将其投影到裁剪坐标。裁剪坐标会被处理至-1.0到1.0的范围内，并判断哪些顶点将会出现在屏幕上。</li><li>最后，我们将裁剪坐标变换为屏幕坐标，我们将使用一个叫做视口变换(Viewport Transform)的过程。视口变换将位于-1.0到1.0范围的坐标变换到由glViewport函数所定义的坐标范围内。最后变换出来的坐标将会送到光栅器，将其转化为片段。</li></ol><p>局部空间<br>局部空间是指物体所在的坐标空间，即对象最开始所在的地方。想象你在一个建模软件（比如说Blender）中创建了一个立方体。你创建的立方体的原点有可能位于(0, 0, 0)，即便它有可能最后在程序中处于完全不同的位置。甚至有可能你创建的所有模型都以(0, 0, 0)为初始位置（译注：然而它们会最终出现在世界的不同位置）。所以，你的模型的所有顶点都是在局部空间中：它们相对于你的物体来说都是局部的。</p><p>我们一直使用的那个箱子的顶点是被设定在-0.5到0.5的坐标范围中，(0, 0)是它的原点。这些都是局部坐标。</p><h5 id="世界空间"><a href="#世界空间" class="headerlink" title="世界空间"></a>世界空间</h5><p>如果我们将我们所有的物体导入到程序当中，它们有可能会全挤在世界的原点(0, 0, 0)上，这并不是我们想要的结果。我们想为每一个物体定义一个位置，从而能在更大的世界当中放置它们。世界空间中的坐标正如其名：是指顶点相对于（游戏）世界的坐标。如果你希望将物体分散在世界上摆放（特别是非常真实的那样），这就是你希望物体变换到的空间。<strong>物体的坐标将会从局部变换到世界空间；该变换是由模型矩阵(Model Matrix)实现的</strong>。</p><p><strong>模型矩阵是一种变换矩阵，它能通过对物体进行位移、缩放、旋转来将它置于它本应该在的位置或朝向</strong>。你可以将它想像为变换一个房子，你需要先将它缩小（它在局部空间中太大了），并将其位移至郊区的一个小镇，然后在y轴上往左旋转一点以搭配附近的房子。</p><h5 id="观察空间"><a href="#观察空间" class="headerlink" title="观察空间"></a>观察空间</h5><p>观察空间经常被人们称之OpenGL的摄像机(Camera)（所以有时也称为摄像机空间(Camera Space)或视觉空间(Eye Space)）。<strong>观察空间是将世界空间坐标转化为用户视野前方的坐标而产生的结果。因此观察空间就是从摄像机的视角所观察到的空间</strong>。而这通常是由一系列的位移和旋转的组合来完成，平移/旋转场景从而使得特定的对象被变换到摄像机的前方。<strong>这些组合在一起的变换通常存储在一个观察矩阵(View Matrix)里，它被用来将世界坐标变换到观察空间</strong>。</p><h5 id="裁剪空间"><a href="#裁剪空间" class="headerlink" title="裁剪空间"></a>裁剪空间</h5><p>在一个顶点着色器运行的最后，OpenGL期望所有的坐标都能落在一个特定的范围内，且任何在这个范围之外的点都应该被裁剪掉(Clipped)。被裁剪掉的坐标就会被忽略，所以剩下的坐标就将变为屏幕上可见的片段。这也就是裁剪空间(Clip Space)名字的由来。</p><p>因为将所有可见的坐标都指定在-1.0到1.0的范围内不是很直观，所以我们会指定自己的坐标集(Coordinate Set)并将它变换回标准化设备坐标系，就像OpenGL期望的那样。</p><p><strong>为了将顶点坐标从观察变换到裁剪空间，我们需要定义一个投影矩阵(Projection Matrix)</strong>，它指定了一个范围的坐标，比如在每个维度上的-1000到1000。<strong>投影矩阵接着会将在这个指定的范围内的坐标变换为标准化设备坐标的范围(-1.0, 1.0)</strong>。所有在范围外的坐标不会被映射到在-1.0到1.0的范围之间，所以会被裁剪掉。在上面这个投影矩阵所指定的范围内，坐标(1250, 500, 750)将是不可见的，这是由于它的x坐标超出了范围，它被转化为一个大于1.0的标准化设备坐标，所以被裁剪掉了。</p><p>如果只是图元(Primitive)，例如三角形，的一部分超出了裁剪体积(Clipping Volume)，则OpenGL会重新构建这个三角形为一个或多个三角形让其能够适合这个裁剪范围。</p><p>由投影矩阵创建的观察箱(Viewing Box)被称为平截头体(Frustum)，每个出现在平截头体范围内的坐标都会最终出现在用户的屏幕上。将特定范围内的坐标转化到标准化设备坐标系的过程（而且它很容易被映射到2D观察空间坐标）被称之为投影(Projection)，因为使用投影矩阵能将3D坐标投影(Project)到很容易映射到2D的标准化设备坐标系中。</p><p>一旦所有顶点被变换到裁剪空间，最终的操作——透视除法(Perspective Division)将会执行，在这个过程中我们将位置向量的x，y，z分量分别除以向量的齐次w分量；透视除法是将4D裁剪空间坐标变换为3D标准化设备坐标的过程。这一步会在每一个顶点着色器运行的最后被自动执行。</p><p>在这一阶段之后，最终的坐标将会被映射到屏幕空间中（使用glViewport中的设定），并被变换成片段。</p><blockquote><p>将观察坐标变换为裁剪坐标的投影矩阵可以为两种不同的形式，每种形式都定义了不同的平截头体。我们可以选择创建一个正射投影矩阵(Orthographic Projection Matrix)或一个透视投影矩阵(Perspective Projection Matrix)。</p></blockquote><h6 id="正射投影"><a href="#正射投影" class="headerlink" title="正射投影"></a>正射投影</h6><p>正射投影矩阵定义了一个类似立方体的平截头箱，它定义了一个裁剪空间，在这空间之外的顶点都会被裁剪掉。创建一个正射投影矩阵需要指定可见平截头体的宽、高和长度。在使用正射投影矩阵变换至裁剪空间之后处于这个平截头体内的所有坐标将不会被裁剪掉。它的平截头体看起来像一个容器：</p><p><img src="https://img-blog.csdnimg.cn/20190104120203150.png" alt="正射投影"></p><p>上面的平截头体定义了可见的坐标，它由由宽、高、近(Near)平面和远(Far)平面所指定。任何出现在近平面之前或远平面之后的坐标都会被裁剪掉。正射平截头体直接将平截头体内部的所有坐标映射为标准化设备坐标，因为每个向量的w分量都没有进行改变；如果w分量等于1.0，透视除法则不会改变这个坐标。</p><p>要创建一个正射投影矩阵，我们可以使用GLM的内置函数glm::ortho：</p><p><code>glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);</code><br>前两个参数指定了平截头体的左右坐标，第三和第四参数指定了平截头体的底部和顶部。通过这四个参数我们定义了近平面和远平面的大小，然后第五和第六个参数则定义了近平面和远平面的距离。这个投影矩阵会将处于这些x，y，z值范围内的坐标变换为标准化设备坐标。</p><p>正射投影矩阵直接将坐标映射到2D平面中，即你的屏幕，但实际上一个直接的投影矩阵会产生不真实的结果，因为这个投影没有将透视(Perspective)考虑进去。所以我们需要透视投影矩阵来解决这个问题。</p><h6 id="透视投影"><a href="#透视投影" class="headerlink" title="透视投影"></a>透视投影</h6><p>如果你曾经体验过实际生活给你带来的景象，你就会注意到离你越远的东西看起来更小。这个奇怪的效果称之为透视(Perspective)。透视的效果在我们看一条无限长的高速公路或铁路时尤其明显，正如下面图片显示的那样：</p><p><img src="https://img-blog.csdnimg.cn/20190104120423164.png" alt="透视投影"></p><p>正如你看到的那样，由于透视，这两条线在很远的地方看起来会相交。这正是透视投影想要模仿的效果，它是使用透视投影矩阵来完成的。这个投影矩阵将给定的平截头体范围映射到裁剪空间，除此之外还修改了每个顶点坐标的w值，从而使得离观察者越远的顶点坐标w分量越大。被变换到裁剪空间的坐标都会在-w到w的范围之间（任何大于这个范围的坐标都会被裁剪掉）。OpenGL要求所有可见的坐标都落在-1.0到1.0范围内，作为顶点着色器最后的输出，因此，一旦坐标在裁剪空间内之后，透视除法就会被应用到裁剪空间坐标上：</p><p><img src="https://img-blog.csdnimg.cn/20190104160059276.png" alt="w"><br>顶点坐标的每个分量都会除以它的w分量，距离观察者越远顶点坐标就会越小。这是也是w分量非常重要的另一个原因，它能够帮助我们进行透视投影。最后的结果坐标就是处于标准化设备空间中的。</p><p>在GLM中可以这样创建一个透视投影矩阵：</p><pre><code>glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f);</code></pre><p>同样，glm::perspective所做的其实就是创建了一个定义了可视空间的大平截头体，任何在这个平截头体以外的东西最后都不会出现在裁剪空间体积内，并且将会受到裁剪。一个透视平截头体可以被看作一个不均匀形状的箱子，在这个箱子内部的每个坐标都会被映射到裁剪空间上的一个点。下面是一张透视平截头体的图片：</p><p><img src="https://img-blog.csdnimg.cn/20190104160139427.png" alt="视椎体"></p><p>它的第一个参数定义了fov的值，它表示的是视野(Field of View)，并且设置了观察空间的大小。如果想要一个真实的观察效果，它的值通常设置为45.0f，但想要一个末日风格的结果你可以将其设置一个更大的值。第二个参数设置了宽高比，由视口的宽除以高所得。第三和第四个参数设置了平截头体的近和远平面。我们通常设置近距离为0.1f，而远距离设为100.0f。所有在近平面和远平面内且处于平截头体内的顶点都会被渲染。</p><p>当你把透视矩阵的 near 值设置太大时（如10.0f），OpenGL会将靠近摄像机的坐标（在0.0f和10.0f之间）都裁剪掉，这会导致一个你在游戏中很熟悉的视觉效果：在太过靠近一个物体的时候你的视线会直接穿过去。</p><p>当使用正射投影时，<strong>每一个顶点坐标都会直接映射到裁剪空间中而不经过任何精细的透视除法（它仍然会进行透视除法，只是w分量没有被改变（它保持为1），因此没有起作用）。因为正射投影没有使用透视，远处的物体不会显得更小，所以产生奇怪的视觉效果。</strong>由于这个原因，正射投影主要用于二维渲染以及一些建筑或工程的程序，在这些场景中我们更希望顶点不会被透视所干扰。某些如 Blender 等进行三维建模的软件有时在建模时也会使用正射投影，因为它在各个维度下都更准确地描绘了每个物体。下面你能够看到在Blender里面使用两种投影方式的对比：</p><p><img src="https://img-blog.csdnimg.cn/20190104160431753.png" alt="透视投影正交投影"></p><p>你可以看到，使用透视投影的话，远处的顶点看起来比较小，而在正射投影中每个顶点距离观察者的距离都是一样的。</p><h4 id="模型视图投影矩阵"><a href="#模型视图投影矩阵" class="headerlink" title="模型视图投影矩阵"></a>模型视图投影矩阵</h4><p>我们为上述的每一个步骤都创建了一个变换矩阵：模型矩阵、观察矩阵和投影矩阵。一个顶点坐标将会根据以下过程被变换到裁剪坐标：</p><p><img src="https://img-blog.csdnimg.cn/20190104160510251.png" alt="模型视图投影矩阵"><br>注意矩阵运算的顺序是相反的（记住我们需要从右往左阅读矩阵的乘法）。最后的顶点应该被赋值到顶点着色器中的gl_Position，OpenGL将会自动进行透视除法和裁剪。</p><p><strong>顶点着色器的输出要求所有的顶点都在裁剪空间内，这正是我们刚才使用变换矩阵所做的。OpenGL然后对裁剪坐标执行透视除法从而将它们变换到标准化设备坐标。OpenGL会使用glViewPort内部的参数来将标准化设备坐标映射到屏幕坐标，每个坐标都关联了一个屏幕上的点。这个过程称为视口变换。</strong></p><h4 id="右手坐标系-Right-handed-System"><a href="#右手坐标系-Right-handed-System" class="headerlink" title="右手坐标系(Right-handed System)"></a>右手坐标系(Right-handed System)</h4><p>OpenGL是一个右手坐标系。简单来说，就是正x轴在你的右手边，正y轴朝上，而正z轴是朝向后方的。想象你的屏幕处于三个轴的中心，则正z轴穿过你的屏幕朝向你。坐标系画起来如下：</p><p><img src="https://img-blog.csdnimg.cn/20190104161222624.png" alt="右手坐标系"></p><p>为了理解为什么被称为右手坐标系，按如下的步骤做：</p><ul><li>沿着正y轴方向伸出你的右臂，手指着上方。</li><li>大拇指指向右方。</li><li>食指指向上方。</li><li>中指向下弯曲90度。<br>如果你的动作正确，那么你的大拇指指向正x轴方向，食指指向正y轴方向，中指指向正z轴方向。如果你用左臂来做这些动作，你会发现z轴的方向是相反的。这个叫做左手坐标系，它被DirectX广泛地使用。注意在标准化设备坐标系中OpenGL实际上使用的是左手坐标系（投影矩阵交换了左右手）。</li></ul><h4 id="Z缓冲"><a href="#Z缓冲" class="headerlink" title="Z缓冲"></a>Z缓冲</h4><p>OpenGL存储它的所有深度信息于一个Z缓冲(Z-buffer)中，也被称为深度缓冲(Depth Buffer)。GLFW会自动为你生成这样一个缓冲（就像它也有一个颜色缓冲来存储输出图像的颜色）。深度值存储在每个片段里面（作为片段的z值），当片段想要输出它的颜色时，OpenGL会将它的深度值和z缓冲进行比较，如果当前的片段在其它片段之后，它将会被丢弃，否则将会覆盖。这个过程称为深度测试(Depth Testing)，它是由OpenGL自动完成的。</p><p>然而，如果我们想要确定OpenGL真的执行了深度测试，首先我们要告诉OpenGL我们想要启用深度测试；它默认是关闭的。我们可以通过glEnable函数来开启深度测试。glEnable和glDisable函数允许我们启用或禁用某个OpenGL功能。这个功能会一直保持启用/禁用状态，直到另一个调用来禁用/启用它。现在我们想启用深度测试，需要开启GL_DEPTH_TEST：</p><p><code>glEnable(GL_DEPTH_TEST);</code><br>因为我们使用了深度测试，我们也想要在每次渲染迭代之前清除深度缓冲（否则前一帧的深度信息仍然保存在缓冲中）。就像清除颜色缓冲一样，我们可以通过在glClear函数中指定DEPTH_BUFFER_BIT位来清除深度缓冲：</p><p><code>glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</code></p>]]></content>
    
    <summary type="html">
    
      顶点着色器的输出要求所有的顶点都在裁剪空间内，这正是模型视图投影矩阵使用变换矩阵所做的。OpenGL然后对裁剪坐标执行透视除法从而将它们变换到标准化设备坐标。OpenGL会使用glViewPort内部的参数来将标准化设备坐标映射到屏幕坐标，每个坐标都关联了一个屏幕上的点。这个过程称为视口变换。
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl矩阵向量</title>
    <link href="https://bytemode.github.io/2019/01/03/opengl%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F/"/>
    <id>https://bytemode.github.io/2019/01/03/opengl矩阵向量/</id>
    <published>2019-01-03T10:03:43.000Z</published>
    <updated>2019-01-04T03:32:23.033Z</updated>
    
    <content type="html"><![CDATA[<p>如何创建一个物体、着色、加入纹理，给它们一些细节的表现，但因为它们都还是静态的物体，仍是不够有趣。我们可以尝试着在每一帧改变物体的顶点并且重配置缓冲区从而使它们移动，但这太繁琐了，而且会消耗很多的处理时间。我们现在有一个更好的解决方案，使用（多个）矩阵(Matrix)对象可以更好的变换(Transform)一个物体。</p><h4 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h4><p>向量最基本的定义就是一个方向。或者更正式的说，向量有一个方向(Direction)和大小(Magnitude，也叫做强度或长度)。你可以把向量想像成一个藏宝图上的指示：“向左走10步，向北走3步，然后向右走5步”；“左”就是方向，“10步”就是向量的长度。那么这个藏宝图的指示一共有3个向量。向量可以在任意维度(Dimension)上，但是我们通常只使用2至4维。如果一个向量有2个维度，它表示一个平面的方向(想象一下2D的图像)，当它有3个维度的时候它可以表达一个3D世界的方向。</p><p>下面你会看到3个向量，每个向量在2D图像中都用一个箭头(x, y)表示。我们在2D图片中展示这些向量，因为这样子会更直观一点。你可以把这些2D向量当做z坐标为0的3D向量。由于向量表示的是方向，起始于何处并不会改变它的值。下图我们可以看到向量v¯和w¯是相等的，尽管他们的起始点不同：<br><img src="https://img-blog.csdnimg.cn/20190103180830580.png" alt="向量"></p><p>数学家喜欢在字母上面加一横表示向量，比如说v¯。当用在公式中时它们通常是这样的：<br><img src="https://img-blog.csdnimg.cn/2019010318094392.png" alt="向量"><br>由于向量是一个方向，所以有些时候会很难形象地将它们用位置(Position)表示出来。为了让其更为直观，我们通常设定这个方向的原点为(0, 0, 0)，然后指向一个方向，对应一个点，使其变为位置向量(Position Vector)（你也可以把起点设置为其他的点，然后说：这个向量从这个点起始指向另一个点）。比如说位置向量(3, 5)在图像中的起点会是(0, 0)，并会指向(3, 5)。我们可以使用向量在2D或3D空间中表示方向与位置.</p><p>和普通数字一样，我们也可以用向量进行多种运算（其中一些你可能已经看到过了）。</p><h5 id="向量与标量运算"><a href="#向量与标量运算" class="headerlink" title="向量与标量运算"></a>向量与标量运算</h5><p>标量(Scalar)只是一个数字（或者说是仅有一个分量的向量）。当把一个向量加/减/乘/除一个标量，我们可以简单的把向量的每个分量分别进行该运算。对于加法来说会像这样:</p><p><img src="https://img-blog.csdnimg.cn/20190103181142306.png" alt="向量加标量运算"><br>其中的+可以是+，-，·或÷，其中·是乘号。注意－和÷运算时不能颠倒（标量-/÷向量），因为颠倒的运算是没有定义的。</p><h5 id="向量取反"><a href="#向量取反" class="headerlink" title="向量取反"></a>向量取反</h5><p>对一个向量取反(Negate)会将其方向逆转。一个指向东北的向量取反后就指向西南方向了。我们在一个向量的每个分量前加负号就可以实现取反了（或者说用-1数乘该向量）:</p><p><img src="https://img-blog.csdnimg.cn/20190103181524341.png" alt="向量取反"></p><h5 id="向量加减"><a href="#向量加减" class="headerlink" title="向量加减"></a>向量加减</h5><p>向量的加法可以被定义为是分量的(Component-wise)相加，即将一个向量中的每一个分量加上另一个向量的对应分量：</p><p><img src="https://img-blog.csdnimg.cn/201901031817369.png" alt="向量加法"><br>向量v = (4, 2)和k = (1, 2)可以直观地表示为：</p><p><img src="https://img-blog.csdnimg.cn/20190103182013546.png" alt="向量加法"></p><p>就像普通数字的加减一样，向量的减法等于加上第二个向量的相反向量：</p><p><img src="https://img-blog.csdnimg.cn/20190103182208215.png" alt="向量减法"><br>两个向量的相减会得到这两个向量指向位置的差。这在我们想要获取两点的差会非常有用。<br><img src="https://img-blog.csdnimg.cn/201901031823044.png" alt="向量减法"></p><h5 id="长度"><a href="#长度" class="headerlink" title="长度"></a>长度</h5><p>我们使用勾股定理(Pythagoras Theorem)来获取向量的长度(Length)/大小(Magnitude)。如果你把向量的x与y分量画出来，该向量会和x与y分量为边形成一个三角形:</p><p><img src="https://img-blog.csdnimg.cn/20190103182415227.png" alt="向量长度"></p><p>因为两条边（x和y）是已知的，如果希望知道斜边v¯的长度，我们可以直接通过勾股定理来计算：</p><p><img src="https://img-blog.csdnimg.cn/20190103182540618.png" alt="向量长度"><br>||v¯||表示向量v¯的长度，我们也可以加上z2把这个公式拓展到三维空间。</p><p>例子中向量(4, 2)的长度等于：</p><p><img src="https://img-blog.csdnimg.cn/20190103182607589.png" alt="向量长度"><br>结果是4.47。</p><p>有一个特殊类型的向量叫做单位向量(Unit Vector)。单位向量有一个特别的性质——它的长度是1。我们可以用任意向量的每个分量除以向量的长度得到它的单位向量n̂ ：</p><p><img src="https://img-blog.csdnimg.cn/20190103182653355.png" alt="单位向量"><br>我们把这种方法叫做一个向量的标准化(Normalizing)。单位向量头上有一个^样子的记号。通常单位向量会变得很有用，特别是在我们只关心方向不关心长度的时候（如果改变向量的长度，它的方向并不会改变）。</p><h5 id="向量相乘"><a href="#向量相乘" class="headerlink" title="向量相乘"></a>向量相乘</h5><p>两个向量相乘是一种很奇怪的情况。普通的乘法在向量上是没有定义的，因为它在视觉上是没有意义的。但是在相乘的时候我们有两种特定情况可以选择：一个是点乘(Dot Product)，记作v¯⋅k¯，另一个是叉乘(Cross Product)，记作v¯×k¯。<br><img src="https://img-blog.csdnimg.cn/2019010411131463.png" alt="点乘和叉乘"></p><h5 id="点乘"><a href="#点乘" class="headerlink" title="点乘"></a>点乘</h5><p>两个向量的点乘等于它们的<strong>数乘结果乘以两个向量之间夹角的余弦值</strong>。可能听起来有点费解，我们来看一下公式：</p><p><img src="https://img-blog.csdnimg.cn/20190103183110702.png" alt="点乘"><br>它们之间的夹角记作θ。为什么这很有用？想象如果v¯和k¯都是单位向量，它们的长度会等于1。这样公式会有效简化成：</p><p><img src="https://img-blog.csdnimg.cn/20190103183133651.png" alt="点乘法"><br>现在点积只定义了两个向量的夹角。你也许记得90度的余弦值是0，0度的余弦值是1。使用点乘可以很容易测试两个向量是否正交(Orthogonal)或平行（正交意味着两个向量互为直角）。</p><p>所以，我们该如何计算点乘呢？<strong>点乘是通过将对应分量逐个相乘，然后再把所得积相加来计算的</strong>。两个单位向量的（你可以验证它们的长度都为1）点乘会像是这样：</p><p><img src="https://img-blog.csdnimg.cn/20190103183710476.png" alt="点乘计算"><br>点乘会在计算光照的时候非常有用。</p><h5 id="叉乘"><a href="#叉乘" class="headerlink" title="叉乘"></a>叉乘</h5><p>叉乘只在3D空间中有定义，它需要两个不平行向量作为输入，生成一个正交于两个输入向量的第三个向量。如果输入的两个向量也是正交的，那么叉乘之后将会产生3个互相正交的向量。接下来的教程中这会非常有用。下面的图片展示了3D空间中叉乘的样子：<br><img src="https://img-blog.csdnimg.cn/20190103201407188.png" alt="3D空间叉乘"></p><p>下面你会看到两个正交向量A和B叉积：<br><img src="https://img-blog.csdnimg.cn/20190103194846505.png" alt="向量叉乘"></p><h4 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h4><p>现在我们已经讨论了向量的全部内容，是时候看看矩阵了！简单来说矩阵就是一个矩形的数字、符号或表达式数组。矩阵中每一项叫做矩阵的元素(Element)。下面是一个2×3矩阵的例子：</p><p><img src="https://img-blog.csdnimg.cn/20190103201516114.png" alt="2*3矩阵"><br>矩阵可以通过(i, j)进行索引，i是行，j是列，这就是上面的矩阵叫做2×3矩阵的原因（3列2行，也叫做矩阵的维度(Dimension)）。这与你在索引2D图像时的(x, y)相反，获取4的索引是(2, 1)（第二行，第一列）（译注：如果是图像索引应该是(1, 2)，先算列，再算行）。</p><p>矩阵基本也就是这些了，它就是一个矩形的数学表达式阵列。和向量一样，矩阵也有非常漂亮的数学属性。矩阵有几个运算，分别是：矩阵加法、减法和乘法。</p><h5 id="矩阵的加减"><a href="#矩阵的加减" class="headerlink" title="矩阵的加减"></a>矩阵的加减</h5><p>矩阵与标量之间的加减定义如下：</p><p><img src="https://img-blog.csdnimg.cn/20190103213154595.png" alt="矩阵和标量加"><br>标量值要加到矩阵的每一个元素上。矩阵与标量的减法也相似：</p><p><img src="https://img-blog.csdnimg.cn/20190103213235298.png" alt="矩阵和标量减"><br>矩阵与矩阵之间的加减就是两个矩阵对应元素的加减运算，所以总体的规则和与标量运算是差不多的，只不过在相同索引下的元素才能进行运算。这也就是说加法和减法只对同维度的矩阵才是有定义的。一个3×2矩阵和一个2×3矩阵（或一个3×3矩阵与4×4矩阵）是不能进行加减的。我们看看两个2×2矩阵是怎样相加的：</p><p><img src="https://img-blog.csdnimg.cn/20190103213305827.png" alt="矩阵加法"><br>同样的法则也适用于减法：</p><p><img src="https://img-blog.csdnimg.cn/20190103213358321.png" alt="矩阵减法"></p><h5 id="矩阵的数乘"><a href="#矩阵的数乘" class="headerlink" title="矩阵的数乘"></a>矩阵的数乘</h5><p>和矩阵与标量的加减一样，矩阵与标量之间的乘法也是矩阵的每一个元素分别乘以该标量。下面的例子展示了乘法的过程：<br><img src="https://img-blog.csdnimg.cn/20190103213505740.png" alt="矩阵数乘"></p><p>现在我们也就能明白为什么这些单独的数字要叫做标量(Scalar)了。简单来说，标量就是用它的值缩放(Scale)矩阵的所有元素（译注：注意Scalar是由Scale + -ar演变过来的）。前面那个例子中，所有的元素都被放大了2倍。</p><h5 id="矩阵相乘"><a href="#矩阵相乘" class="headerlink" title="矩阵相乘"></a>矩阵相乘</h5><p>矩阵之间的乘法不见得有多复杂，但的确很难让人适应。矩阵乘法基本上意味着遵照规定好的法则进行相乘。当然，相乘还有一些限制：</p><ol><li>只有当左侧矩阵的列数与右侧矩阵的行数相等，两个矩阵才能相乘。</li><li>矩阵相乘不遵守交换律(Commutative)，也就是说A⋅B≠B⋅A。<br>我们先看一个两个2×2矩阵相乘的例子：<br><img src="https://img-blog.csdnimg.cn/20190103213856187.png" alt="矩阵乘法"></li></ol><p><img src="https://img-blog.csdnimg.cn/20190103214041908.png" alt="矩阵乘法"></p><p>结果矩阵的维度是(n, m)，n等于左侧矩阵的行数，m等于右侧矩阵的列数。</p><h5 id="矩阵与向量相乘"><a href="#矩阵与向量相乘" class="headerlink" title="矩阵与向量相乘"></a>矩阵与向量相乘</h5><p>我们用向量来表示位置，表示颜色，甚至是纹理坐标。向量和矩阵一样都是一个数字序列，但它只有1列。那么，这个新的定义对我们有什么帮助呢？如果我们有一个M×N矩阵，我们可以用这个矩阵乘以我们的N×1向量，因为这个矩阵的列数等于向量的行数，所以它们就能相乘。</p><p>很多有趣的2D/3D变换都可以放在一个矩阵中，用这个矩阵乘以我们的向量将变换(Transform)这个向量。</p><h6 id="单位矩阵"><a href="#单位矩阵" class="headerlink" title="单位矩阵"></a>单位矩阵</h6><p>在OpenGL中，由于某些原因我们通常使用4×4的变换矩阵，而其中最重要的原因就是大部分的向量都是4分量的。我们能想到的最简单的变换矩阵就是单位矩阵(Identity Matrix)。单位矩阵是一个除了对角线以外都是0的N×N矩阵。在下式中可以看到，这种变换矩阵使一个向量完全不变：</p><p><img src="https://img-blog.csdnimg.cn/20190103214452829.png" alt="单位矩阵"><br>向量看起来完全没变。从乘法法则来看就很容易理解来：第一个结果元素是矩阵的第一行的每个元素乘以向量的每个对应元素。因为每行的元素除了第一个都是0，可得：1⋅1+0⋅2+0⋅3+0⋅4=1，向量的其他3个元素同理。</p><h5 id="缩放"><a href="#缩放" class="headerlink" title="缩放"></a>缩放</h5><p>对一个向量进行缩放(Scaling)就是对向量的长度进行缩放，而保持它的方向不变。由于我们进行的是2维或3维操作，我们可以分别定义一个有2或3个缩放变量的向量，每个变量缩放一个轴(x、y或z)。</p><p>我们先来尝试缩放向量v¯=(3,2)。我们可以把向量沿着x轴缩放0.5，使它的宽度缩小为原来的二分之一；我们将沿着y轴把向量的高度缩放为原来的两倍。我们看看把向量缩放(0.5, 2)倍所获得的s¯是什么样的：<br><img src="https://img-blog.csdnimg.cn/20190104105421976.png" alt="向量缩放"></p><p>记住，OpenGL通常是在3D空间进行操作的，对于2D的情况我们可以把z轴缩放1倍，这样z轴的值就不变了。我们刚刚的缩放操作是不均匀(Non-uniform)缩放，因为每个轴的缩放因子(Scaling Factor)都不一样。如果每个轴的缩放因子都一样那么就叫均匀缩放(Uniform Scale)。</p><p>我们下面会构造一个变换矩阵来为我们提供缩放功能。我们从单位矩阵了解到，每个对角线元素会分别与向量的对应元素相乘。如果我们把1变为3会怎样？这样子的话，我们就把向量的每个元素乘以3了，这事实上就把向量缩放3倍。如果我们把缩放变量表示为(S1,S2,S3)我们可以为任意向量(x,y,z)定义一个缩放矩阵：</p><p><img src="https://img-blog.csdnimg.cn/20190104105548246.png" alt="向量缩放"><br>注意，第四个缩放向量仍然是1，因为在3D空间中缩放w分量是无意义的。w分量另有其他用途，在后面我们会看到。</p><h5 id="位移"><a href="#位移" class="headerlink" title="位移"></a>位移</h5><p>位移(Translation)是在原始向量的基础上加上另一个向量从而获得一个在不同位置的新向量的过程，从而在位移向量基础上移动了原始向量。我们已经讨论了向量加法，所以这应该不会太陌生。</p><p>和缩放矩阵一样，在4×4矩阵上有几个特别的位置用来执行特定的操作，对于位移来说它们是第四列最上面的3个值。如果我们把位移向量表示为(Tx,Ty,Tz)，我们就能把位移矩阵定义为：</p><p><img src="https://img-blog.csdnimg.cn/20190104111509624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jsb2dzdW4=,size_16,color_FFFFFF,t_70" alt="向量位移"><br>这样是能工作的，因为所有的位移值都要乘以向量的w行，所以位移值会加到向量的原始值上（想想矩阵乘法法则）。而如果你用3x3矩阵我们的位移值就没地方放也没地方乘了，所以是不行的。</p><h5 id="齐次坐标-Homogeneous-Coordinates"><a href="#齐次坐标-Homogeneous-Coordinates" class="headerlink" title="齐次坐标(Homogeneous Coordinates)"></a>齐次坐标(Homogeneous Coordinates)</h5><p>向量的w分量也叫齐次坐标。想要从齐次向量得到3D向量，我们可以把x、y和z坐标分别除以w坐标。我们通常不会注意这个问题，因为w分量通常是1.0。使用齐次坐标有几点好处：它允许我们在3D向量上进行位移（如果没有w分量我们是不能位移向量的），而且下一章我们会用w值创建3D视觉效果。</p><p>如果一个向量的齐次坐标是0，这个坐标就是方向向量(Direction Vector)，因为w坐标是0，这个向量就不能位移（译注：这也就是我们说的不能位移一个方向）。</p><p>有了位移矩阵我们就可以在3个方向(x、y、z)上移动物体，它是我们的变换工具箱中非常有用的一个变换矩阵。</p><h5 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h5><p>上面几个的变换内容相对容易理解，在2D或3D空间中也容易表示出来，但旋转(Rotation)稍复杂些。如果你想知道旋转矩阵是如何构造出来的，我推荐你去看可汗学院线性代数的视频。</p><p>首先我们来定义一个向量的旋转到底是什么。2D或3D空间中的旋转用角(Angle)来表示。角可以是角度制或弧度制的，周角是360角度或2 PI弧度。我个人更喜欢用角度，因为它们看起来更直观。</p><ul><li>弧度转角度：角度 = 弧度 * (180.0f / PI)</li><li>角度转弧度：弧度 = 角度 * (PI / 180.0f)</li><li>PI约等于3.14159265359。</li></ul><p>转半圈会旋转360/2 = 180度，向右旋转1/5圈表示向右旋转360/5 = 72度。下图中展示的2D向量v¯是由k¯向右旋转72度所得的：<br><img src="https://img-blog.csdnimg.cn/20190104112227528.png" alt="向量旋转"></p><p>在3D空间中旋转需要定义一个角和一个旋转轴(Rotation Axis)。物体会沿着给定的旋转轴旋转特定角度。如果你想要更形象化的感受，可以试试向下看着一个特定的旋转轴，同时将你的头部旋转一定角度。当2D向量在3D空间中旋转时，我们把旋转轴设为z轴（尝试想象这种情况）。</p><p>使用三角学，给定一个角度，可以把一个向量变换为一个经过旋转的新向量。这通常是使用一系列正弦和余弦函数（一般简称sin和cos）各种巧妙的组合得到的。当然，讨论如何生成变换矩阵超出了这个教程的范围。</p><p>旋转矩阵在3D空间中每个单位轴都有不同定义，旋转角度用θ表示：</p><p>沿x轴旋转：</p><p><img src="https://img-blog.csdnimg.cn/20190104112559960.png" alt="x轴旋转"><br>沿y轴旋转：</p><p><img src="https://img-blog.csdnimg.cn/20190104112627759.png" alt="y轴旋转"><br>沿z轴旋转：</p><p><img src="https://img-blog.csdnimg.cn/20190104112655708.png" alt="z轴旋转"><br>利用旋转矩阵我们可以把任意位置向量沿一个单位旋转轴进行旋转。也可以将多个矩阵复合，比如先沿着x轴旋转再沿着y轴旋转。但是这会很快导致一个问题——万向节死锁（Gimbal Lock，可以看看这个视频（优酷）来了解）。在这里我们不会讨论它的细节，但是对于3D空间中的旋转，一个更好的模型是沿着任意的一个轴，比如单位向量$(0.662, 0.2, 0.7222)$旋转，而不是对一系列旋转矩阵进行复合。这样的一个（超级麻烦的）矩阵是存在的，见下面这个公式，其中(Rx,Ry,Rz)代表任意旋转轴：</p><p><img src="https://img-blog.csdnimg.cn/20190104112754727.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jsb2dzdW4=,size_16,color_FFFFFF,t_70" alt="任意轴旋转"><br>在数学上讨论如何生成这样的矩阵仍然超出了本节内容。但是记住，即使这样一个矩阵也不能完全解决万向节死锁问题（尽管会极大地避免）。避免万向节死锁的真正解决方案是使用四元数(Quaternion)，它不仅更安全，而且计算会更有效率。</p><p>矩阵的组合<br>使用矩阵进行变换的真正力量在于，根据矩阵之间的乘法，我们可以把多个变换组合到一个矩阵中。让我们看看我们是否能生成一个变换矩阵，让它组合多个变换。假设我们有一个顶点(x, y, z)，我们希望将其缩放2倍，然后位移(1, 2, 3)个单位。我们需要一个位移和缩放矩阵来完成这些变换。结果的变换矩阵看起来像这样：</p><p><img src="https://img-blog.csdnimg.cn/20190104112941824.png" alt="矩阵组合"><br>注意，当矩阵相乘时我们先写位移再写缩放变换的。矩阵乘法是不遵守交换律的，这意味着它们的顺序很重要。当矩阵相乘时，在最右边的矩阵是第一个与向量相乘的，所以你应该从右向左读这个乘法。建议您在组合矩阵时，先进行缩放操作，然后是旋转，最后才是位移，否则它们会（消极地）互相影响。比如，如果你先位移再缩放，位移的向量也会同样被缩放（译注：比如向某方向移动2米，2米也许会被缩放成1米）！</p><p>用最终的变换矩阵左乘我们的向量会得到以下结果：</p><p><img src="https://img-blog.csdnimg.cn/20190104113004789.png" alt="组合运算"><br>不错！向量先缩放2倍，然后位移了(1, 2, 3)个单位。</p><h4 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h4><p>OpenGL没有自带任何的矩阵和向量知识，所以我们必须定义自己的数学类和函数。在教程中我们更希望抽象所有的数学细节，使用已经做好了的数学库。幸运的是，有个易于使用，专门为OpenGL量身定做的数学库，那就是GLM。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如何创建一个物体、着色、加入纹理，给它们一些细节的表现，但因为它们都还是静态的物体，仍是不够有趣。我们可以尝试着在每一帧改变物体的顶点并且重配置缓冲区从而使它们移动，但这太繁琐了，而且会消耗很多的处理时间。我们现在有一个更好的解决方案，使用（多个）矩阵(Matrix)对象可
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
</feed>
