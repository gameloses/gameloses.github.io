<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小工知识库</title>
  
  <subtitle>coding wiki</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://bytemode.github.io/"/>
  <updated>2019-01-05T09:14:58.008Z</updated>
  <id>https://bytemode.github.io/</id>
  
  <author>
    <name>sunfeng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>cocos2d分辨率适配</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2d%E5%88%86%E8%BE%A8%E7%8E%87%E9%80%82%E9%85%8D/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2d分辨率适配/</id>
    <published>2019-01-04T10:56:53.000Z</published>
    <updated>2019-01-05T09:14:58.008Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx接入sdk方案</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E6%8E%A5%E5%85%A5sdk%E6%96%B9%E6%A1%88/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx接入sdk方案/</id>
    <published>2019-01-04T10:55:46.000Z</published>
    <updated>2019-01-05T09:14:46.427Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx网络模块</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9D%97/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx网络模块/</id>
    <published>2019-01-04T10:55:15.000Z</published>
    <updated>2019-01-05T09:14:17.539Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx热更新机制</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E7%83%AD%E6%9B%B4%E6%96%B0%E6%9C%BA%E5%88%B6/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx热更新机制/</id>
    <published>2019-01-04T10:55:04.000Z</published>
    <updated>2019-01-05T09:14:30.582Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx资源管理</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx资源管理/</id>
    <published>2019-01-04T10:54:51.000Z</published>
    <updated>2019-01-05T09:13:49.068Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx中使用ecs框架</title>
    <link href="https://bytemode.github.io/2019/01/04/cocos2dx%E4%B8%AD%E4%BD%BF%E7%94%A8ecs%E6%A1%86%E6%9E%B6/"/>
    <id>https://bytemode.github.io/2019/01/04/cocos2dx中使用ecs框架/</id>
    <published>2019-01-04T10:37:14.000Z</published>
    <updated>2019-01-04T10:37:44.850Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
      <category term="ecs" scheme="https://bytemode.github.io/tags/ecs/"/>
    
  </entry>
  
  <entry>
    <title>opengl帧缓冲</title>
    <link href="https://bytemode.github.io/2019/01/04/opengl%E5%B8%A7%E7%BC%93%E5%86%B2/"/>
    <id>https://bytemode.github.io/2019/01/04/opengl帧缓冲/</id>
    <published>2019-01-04T09:45:27.000Z</published>
    <updated>2019-01-04T09:59:58.636Z</updated>
    
    <content type="html"><![CDATA[<h4 id="缓冲区"><a href="#缓冲区" class="headerlink" title="缓冲区"></a>缓冲区</h4><p>用于写入颜色值的颜色缓冲、用于写入深度信息的深度缓冲和允许我们根据一些条件丢弃特定片段的模板缓冲。这些缓冲结合起来叫做帧缓冲(Framebuffer)，它被储存在内存中。OpenGL允许我们定义我们自己的帧缓冲，也就是说我们能够定义我们自己的颜色缓冲，甚至是深度缓冲和模板缓冲。</p><p>我们目前所做的所有操作都是在默认帧缓冲的渲染缓冲上进行的。默认的帧缓冲是在你创建窗口的时候生成和配置的（GLFW帮我们做了这些）。有了我们自己的帧缓冲，我们就能够有更多方式来渲染了。</p><h4 id="创建缓冲区"><a href="#创建缓冲区" class="headerlink" title="创建缓冲区"></a>创建缓冲区</h4><p>和OpenGL中的其它对象一样，我们会使用一个叫做glGenFramebuffers的函数来创建一个帧缓冲对象(Framebuffer Object, FBO)：</p><pre><code>unsigned int fbo;glGenFramebuffers(1, &amp;fbo);</code></pre><p>这种创建和使用对象的方式我们已经见过很多次了，所以它的使用函数也和其它的对象类似。首先我们创建一个帧缓冲对象，将它绑定为激活的(Active)帧缓冲，做一些操作，之后解绑帧缓冲。我们使用glBindFramebuffer来绑定帧缓冲。</p><pre><code>glBindFramebuffer(GL_FRAMEBUFFER, fbo);</code></pre><p>在绑定到GL_FRAMEBUFFER目标之后，所有的读取和写入帧缓冲的操作将会影响当前绑定的帧缓冲。</p><p>一个完整的帧缓冲需要满足以下的条件：</p><ul><li>附加至少一个缓冲（颜色、深度或模板缓冲）。</li><li>至少有一个颜色附件(Attachment)。</li><li>所有的附件都必须是完整的（保留了内存）。</li><li>每个缓冲都应该有相同的样本数。</li></ul><p>从上面的条件中可以知道，我们需要为帧缓冲创建一些附件，并将附件附加到帧缓冲上。在完成所有的条件之后，我们可以以GL_FRAMEBUFFER为参数调用glCheckFramebufferStatus，检查帧缓冲是否完整。它将会检测当前绑定的帧缓冲，并返回规范中这些值的其中之一。如果它返回的是GL_FRAMEBUFFER_COMPLETE，帧缓冲就是完整的了。</p><p>之后所有的渲染操作将会渲染到当前绑定帧缓冲的附件中。由于我们的帧缓冲不是默认帧缓冲，渲染指令将不会对窗口的视觉输出有任何影响。出于这个原因，渲染到一个不同的帧缓冲被叫做离屏渲染(Off-screen Rendering)。要保证所有的渲染操作在主窗口中有视觉效果，我们需要再次激活默认帧缓冲，将它绑定到0。</p><p><code>glBindFramebuffer(GL_FRAMEBUFFER, 0);</code></p><p>在完成所有的帧缓冲操作之后，不要忘记删除这个帧缓冲对象：</p><p><code>glDeleteFramebuffers(1, &amp;fbo);</code><br>在完整性检查执行之前，我们需要给帧缓冲附加一个附件。附件是一个内存位置，它能够作为帧缓冲的一个缓冲，可以将它想象为一个图像。当创建一个附件的时候我们有两个选项：<br><strong>纹理或渲染缓冲对象(Renderbuffer Object)</strong></p><h4 id="纹理附件"><a href="#纹理附件" class="headerlink" title="纹理附件"></a>纹理附件</h4><p>当把一个纹理附加到帧缓冲的时候，所有的渲染指令将会写入到这个纹理中，就想它是一个普通的颜色/深度或模板缓冲一样。使用纹理的优点是，所有渲染操作的结果将会被储存在一个纹理图像中，我们之后可以在着色器中很方便地使用它。</p><h5 id="为帧缓冲创建一个纹理和创建一个普通的纹理差不多："><a href="#为帧缓冲创建一个纹理和创建一个普通的纹理差不多：" class="headerlink" title="为帧缓冲创建一个纹理和创建一个普通的纹理差不多："></a>为帧缓冲创建一个纹理和创建一个普通的纹理差不多：</h5><pre><code>unsigned int texture;glGenTextures(1, &amp;texture);glBindTexture(GL_TEXTURE_2D, texture);glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);</code></pre><p>主要的区别就是，我们将维度设置为了屏幕大小（，并且我们给纹理的data参数传递了NULL。对于这个纹理，我们仅仅分配了内存而没有填充它。填充这个纹理将会在我们渲染到帧缓冲之后来进行。同样注意我们并不关心环绕方式或多级渐远纹理，我们在大多数情况下都不会需要它们。</p><p>如果你想将你的屏幕渲染到一个更小或更大的纹理上，你需要（在渲染到你的帧缓冲之前）再次调用glViewport，使用纹理的新维度作为参数，否则只有一小部分的纹理或屏幕会被渲染到这个纹理上。</p><h5 id="现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了"><a href="#现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了" class="headerlink" title="现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了"></a>现在我们已经创建好一个纹理了，要做的最后一件事就是将它附加到帧缓冲上了</h5><pre><code>glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texture, 0);</code></pre><p>glFrameBufferTexture2D有以下的参数：</p><p>target：帧缓冲的目标（绘制、读取或者两者皆有）<br>attachment：我们想要附加的附件类型。当前我们正在附加一个颜色附件。注意最后的0意味着我们可以附加多个颜色附件。我们将在之后的教程中提到。<br>textarget：你希望附加的纹理类型<br>texture：要附加的纹理本身<br>level：多级渐远纹理的级别。我们将它保留为0。<br>除了颜色附件之外，我们还可以附加一个深度和模板缓冲纹理到帧缓冲对象中。要附加深度缓冲的话，我们将附件类型设置为GL_DEPTH_ATTACHMENT。注意纹理的格式(Format)和内部格式(Internalformat)类型将变为GL_DEPTH_COMPONENT，来反映深度缓冲的储存格式。要附加模板缓冲的话，你要将第二个参数设置为GL_STENCIL_ATTACHMENT，并将纹理的格式设定为GL_STENCIL_INDEX。</p><h5 id="也可以将深度缓冲和模板缓冲附加为一个单独的纹理。"><a href="#也可以将深度缓冲和模板缓冲附加为一个单独的纹理。" class="headerlink" title="也可以将深度缓冲和模板缓冲附加为一个单独的纹理。"></a>也可以将深度缓冲和模板缓冲附加为一个单独的纹理。</h5><p>纹理的每32位数值将包含24位的深度信息和8位的模板信息。要将深度和模板缓冲附加为一个纹理的话，我们使用GL_DEPTH_STENCIL_ATTACHMENT类型，并配置纹理的格式，让它包含合并的深度和模板值。将一个深度和模板缓冲附加为一个纹理到帧缓冲的例子可以在下面找到：</p><pre><code>glTexImage2D(  GL_TEXTURE_2D, 0, GL_DEPTH24_STENCIL8, 800, 600, 0,   GL_DEPTH_STENCIL, GL_UNSIGNED_INT_24_8, NULL);glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_TEXTURE_2D, texture, 0);</code></pre><h4 id="渲染缓冲对象附件"><a href="#渲染缓冲对象附件" class="headerlink" title="渲染缓冲对象附件"></a>渲染缓冲对象附件</h4><p>渲染缓冲对象(Renderbuffer Object)是在纹理之后引入到OpenGL中，作为一个可用的帧缓冲附件类型的，所以在过去纹理是唯一可用的附件。和纹理图像一样，渲染缓冲对象是一个真正的缓冲，即一系列的字节、整数、像素等。渲染缓冲对象附加的好处是，它会将数据储存为OpenGL原生的渲染格式，它是为离屏渲染到帧缓冲优化过的。</p><p>渲染缓冲对象直接将所有的渲染数据储存到它的缓冲中，不会做任何针对纹理格式的转换，让它变为一个更快的可写储存介质。然而，渲染缓冲对象通常都是只写的，所以你不能读取它们（比如使用纹理访问）。当然你仍然还是能够使用glReadPixels来读取它，这会从当前绑定的帧缓冲，而不是附件本身，中返回特定区域的像素。</p><p>因为它的数据已经是原生的格式了，当写入或者复制它的数据到其它缓冲中时是非常快的。所以，交换缓冲这样的操作在使用渲染缓冲对象时会非常快。我们在每个渲染迭代最后使用的glfwSwapBuffers，也可以通过渲染缓冲对象实现：只需要写入一个渲染缓冲图像，并在最后交换到另外一个渲染缓冲就可以了。渲染缓冲对象对这种操作非常完美。</p><p>创建一个渲染缓冲对象的代码和帧缓冲的代码很类似：</p><pre><code>unsigned int rbo;glGenRenderbuffers(1, &amp;rbo);</code></pre><p>类似，我们需要绑定这个渲染缓冲对象，让之后所有的渲染缓冲操作影响当前的rbo：</p><pre><code>glBindRenderbuffer(GL_RENDERBUFFER, rbo);</code></pre><p>由于渲染缓冲对象通常都是只写的，它们会经常用于深度和模板附件，因为大部分时间我们都不需要从深度和模板缓冲中读取值，只关心深度和模板测试。我们需要深度和模板值用于测试，但不需要对它们进行采样，所以渲染缓冲对象非常适合它们。当我们不需要从这些缓冲中采样的时候，通常都会选择渲染缓冲对象，因为它会更优化一点。</p><p>创建一个深度和模板渲染缓冲对象可以通过调用glRenderbufferStorage函数来完成：</p><pre><code>glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, 800, 600);</code></pre><p>创建一个渲染缓冲对象和纹理对象类似，不同的是这个对象是专门被设计作为图像使用的，而不是纹理那样的通用数据缓冲(General Purpose Data Buffer)。这里我们选择GL_DEPTH24_STENCIL8作为内部格式，它封装了24位的深度和8位的模板缓冲。</p><p>最后一件事就是附加这个渲染缓冲对象：</p><pre><code>glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo);</code></pre><p>渲染缓冲对象能为你的帧缓冲对象提供一些优化，但知道什么时候使用渲染缓冲对象，什么时候使用纹理是很重要的。通常的规则是，如果你不需要从一个缓冲中采样数据，那么对这个缓冲使用渲染缓冲对象会是明智的选择。如果你需要从缓冲中采样颜色或深度值等数据，那么你应该选择纹理附件。性能方面它不会产生非常大的影响的。</p><h4 id="渲染到纹理"><a href="#渲染到纹理" class="headerlink" title="渲染到纹理"></a>渲染到纹理</h4><p>既然我们已经知道帧缓冲（大概）是怎么工作的了，是时候实践它们了。我们将会将场景渲染到一个附加到帧缓冲对象上的颜色纹理中，之后将在一个横跨整个屏幕的四边形上绘制这个纹理。这样视觉输出和没使用帧缓冲时是完全一样的，但这次是打印到了一个四边形上。这为什么很有用呢？我们会在下一部分中知道原因。</p><ol><li>首先要创建一个帧缓冲对象，并绑定它，这些都很直观：</li></ol><pre><code>unsigned int framebuffer;glGenFramebuffers(1, &amp;framebuffer);glBindFramebuffer(GL_FRAMEBUFFER, framebuffer);</code></pre><ol start="2"><li>接下来我们需要创建一个纹理图像，我们将它作为一个颜色附件附加到帧缓冲上。<br>我们将纹理的维度设置为窗口的宽度和高度，并且不初始化它的数据：</li></ol><pre><code>// 生成纹理unsigned int texColorBuffer;glGenTextures(1, &amp;texColorBuffer);glBindTexture(GL_TEXTURE_2D, texColorBuffer);glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 800, 600, 0, GL_RGB, GL_UNSIGNED_BYTE, NULL);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR );glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);glBindTexture(GL_TEXTURE_2D, 0);// 将它附加到当前绑定的帧缓冲对象glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texColorBuffer, 0);  </code></pre><ol start="3"><li>添加一个深度（和模板）附件到帧缓冲中。<br>由于我们只希望采样颜色缓冲，而不是其它的缓冲，我们可以为它们创建一个渲染缓冲对象。</li></ol><p>创建一个渲染缓冲对象不是非常复杂。我们需要记住的唯一事情是，我们将它创建为一个深度和模板附件渲染缓冲对象。我们将它的内部格式设置为GL_DEPTH24_STENCIL8。</p><pre><code>unsigned int rbo;glGenRenderbuffers(1, &amp;rbo);glBindRenderbuffer(GL_RENDERBUFFER, rbo); glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH24_STENCIL8, 800, 600);  glBindRenderbuffer(GL_RENDERBUFFER, 0);</code></pre><p>当我们为渲染缓冲对象分配了足够的内存之后，我们可以解绑这个渲染缓冲。</p><ol start="4"><li>将渲染缓冲对象附加到帧缓冲的深度和模板附件上：</li></ol><pre><code>glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_RENDERBUFFER, rbo);</code></pre><p>要想绘制场景到一个纹理上，我们需要采取以下的步骤：</p><ul><li>将新的帧缓冲绑定为激活的帧缓冲，和往常一样渲染场景</li><li>绑定默认的帧缓冲</li><li>绘制一个横跨整个屏幕的四边形，将帧缓冲的颜色缓冲作为它的纹理。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;缓冲区&quot;&gt;&lt;a href=&quot;#缓冲区&quot; class=&quot;headerlink&quot; title=&quot;缓冲区&quot;&gt;&lt;/a&gt;缓冲区&lt;/h4&gt;&lt;p&gt;用于写入颜色值的颜色缓冲、用于写入深度信息的深度缓冲和允许我们根据一些条件丢弃特定片段的模板缓冲。这些缓冲结合起来叫做帧缓冲(Fra
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl测试操作</title>
    <link href="https://bytemode.github.io/2019/01/04/opengl%E6%B5%8B%E8%AF%95%E6%93%8D%E4%BD%9C/"/>
    <id>https://bytemode.github.io/2019/01/04/opengl测试操作/</id>
    <published>2019-01-04T09:19:45.000Z</published>
    <updated>2019-01-04T09:38:05.122Z</updated>
    
    <content type="html"><![CDATA[<h4 id="深度测试"><a href="#深度测试" class="headerlink" title="深度测试"></a>深度测试</h4><p>深度缓冲(Depth Buffer)来防止被阻挡的面渲染到其它面的前面。在这一节中，我们将会更加深入地讨论这些储存在深度缓冲（或z缓冲(z-buffer)）中的深度值(Depth Value)，以及它们是如何确定一个片段是处于其它片段后方的。</p><p>深度缓冲就像颜色缓冲(Color Buffer)（储存所有的片段颜色：视觉输出）一样，在每个片段中储存了信息，并且（通常）和颜色缓冲有着一样的宽度和高度。深度缓冲是由窗口系统自动创建的，它会以16、24或32位float的形式储存它的深度值。在大部分的系统中，深度缓冲的精度都是24位的。</p><p>当深度测试(Depth Testing)被启用的时候，OpenGL会将一个片段的的深度值与深度缓冲的内容进行对比。OpenGL会执行一个深度测试，如果这个测试通过了的话，深度缓冲将会更新为新的深度值。如果深度测试失败了，片段将会被丢弃。</p><p>深度缓冲是在片段着色器运行之后（以及模板测试(Stencil Testing)运行之后，我们将在下一节中讨论）在屏幕空间中运行的。屏幕空间坐标与通过OpenGL的glViewport所定义的视口密切相关，并且可以直接使用GLSL内建变量gl_FragCoord从片段着色器中直接访问。gl_FragCoord的x和y分量代表了片段的屏幕空间坐标（其中(0, 0)位于左下角）。gl_FragCoord中也包含了一个z分量，它包含了片段真正的深度值。z值就是需要与深度缓冲内容所对比的那个值。</p><h5 id="开启关闭深度测试"><a href="#开启关闭深度测试" class="headerlink" title="开启关闭深度测试"></a>开启关闭深度测试</h5><p>深度测试默认是禁用的，所以如果要启用深度测试的话，我们需要用GL_DEPTH_TEST选项来启用它：</p><p><code>glEnable(GL_DEPTH_TEST);</code><br>当它启用的时候，如果一个片段通过了深度测试的话，OpenGL会在深度缓冲中储存该片段的z值；如果没有通过深度缓冲，则会丢弃该片段。如果你启用了深度缓冲，你还应该在每个渲染迭代之前使用GL_DEPTH_BUFFER_BIT来清除深度缓冲，否则你会仍在使用上一次渲染迭代中的写入的深度值：</p><p><code>glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</code><br>可以想象，在某些情况下你会需要对所有片段都执行深度测试并丢弃相应的片段，但不希望更新深度缓冲。基本上来说，你在使用一个只读的(Read-only)深度缓冲。OpenGL允许我们禁用深度缓冲的写入，只需要设置它的深度掩码(Depth Mask)设置为GL_FALSE就可以了：</p><p><code>glDepthMask(GL_FALSE);</code><br>注意这只在深度测试被启用的时候才有效果。</p><h5 id="深度测试函数"><a href="#深度测试函数" class="headerlink" title="深度测试函数"></a>深度测试函数</h5><p>OpenGL允许我们修改深度测试中使用的比较运算符。这允许我们来控制OpenGL什么时候该通过或丢弃一个片段，什么时候去更新深度缓冲。我们可以调用glDepthFunc函数来设置比较运算符（或者说深度函数(Depth Function)）：</p><p><code>glDepthFunc(GL_LESS);</code><br>这个函数接受下面表格中的比较运算符：</p><p>函数    描述<br>GL_ALWAYS    永远通过深度测试<br>GL_NEVER    永远不通过深度测试<br>GL_LESS    在片段深度值小于缓冲的深度值时通过测试<br>GL_EQUAL    在片段深度值等于缓冲区的深度值时通过测试<br>GL_LEQUAL    在片段深度值小于等于缓冲区的深度值时通过测试<br>GL_GREATER    在片段深度值大于缓冲区的深度值时通过测试<br>GL_NOTEQUAL    在片段深度值不等于缓冲区的深度值时通过测试<br>GL_GEQUAL    在片段深度值大于等于缓冲区的深度值时通过测试<br>默认情况下使用的深度函数是GL_LESS，它将会丢弃深度值大于等于当前深度缓冲值的所有片段。</p><h4 id="模板测试"><a href="#模板测试" class="headerlink" title="模板测试"></a>模板测试</h4><p>当片段着色器处理完一个片段之后，模板测试(Stencil Test)会开始执行，和深度测试一样，它也可能会丢弃片段。接下来，被保留的片段会进入深度测试，它可能会丢弃更多的片段。模板测试是根据又一个缓冲来进行的，它叫做模板缓冲(Stencil Buffer)，我们可以在渲染的时候更新它来获得一些很有意思的效果。</p><p>一个模板缓冲中，（通常）每个模板值(Stencil Value)是8位的。所以每个像素/片段一共能有256种不同的模板值。我们可以将这些模板值设置为我们想要的值，然后当某一个片段有某一个模板值的时候，我们就可以选择丢弃或是保留这个片段了。</p><p>模板缓冲的一个简单的例子如下：<br><img src="https://img-blog.csdnimg.cn/20190104173216959.png" alt="模板测试"></p><p>模板缓冲首先会被清除为0，之后在模板缓冲中使用1填充了一个空心矩形。场景中的片段将会只在片段的模板值为1的时候会被渲染（其它的都被丢弃了）。</p><p>模板缓冲操作允许我们在渲染片段时将模板缓冲设定为一个特定的值。通过在渲染时修改模板缓冲的内容，我们写入了模板缓冲。在同一个（或者接下来的）渲染迭代中，我们可以读取这些值，来决定丢弃还是保留某个片段。使用模板缓冲的时候你可以尽情发挥，但大体的步骤如下：</p><ul><li>启用模板缓冲的写入。</li><li>渲染物体，更新模板缓冲的内容。</li><li>禁用模板缓冲的写入。</li><li>渲染（其它）物体，这次根据模板缓冲的内容丢弃特定的片段。<br>所以，通过使用模板缓冲，我们可以根据场景中已绘制的其它物体的片段，来决定是否丢弃特定的片段。</li></ul><h5 id="开启关闭模板测试"><a href="#开启关闭模板测试" class="headerlink" title="开启关闭模板测试"></a>开启关闭模板测试</h5><p>你可以启用GL_STENCIL_TEST来启用模板测试。在这一行代码之后，所有的渲染调用都会以某种方式影响着模板缓冲。</p><p><code>glEnable(GL_STENCIL_TEST);</code><br>注意，和颜色和深度缓冲一样，你也需要在每次迭代之前清除模板缓冲。</p><p><code>glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT);</code><br>和深度测试的glDepthMask函数一样，模板缓冲也有一个类似的函数。glStencilMask允许我们设置一个位掩码(Bitmask)，它会与将要写入缓冲的模板值进行与(AND)运算。默认情况下设置的位掩码所有位都为1，不影响输出，但如果我们将它设置为0x00，写入缓冲的所有模板值最后都会变成0.这与深度测试中的glDepthMask(GL_FALSE)是等价的。</p><pre><code>glStencilMask(0xFF); // 每一位写入模板缓冲时都保持原样glStencilMask(0x00); // 每一位在写入模板缓冲时都会变成0（禁用写入）</code></pre><p>大部分情况下你都只会使用0x00或者0xFF作为模板掩码(Stencil Mask)，但是知道有选项可以设置自定义的位掩码总是好的。</p><h5 id="模板测试函数"><a href="#模板测试函数" class="headerlink" title="模板测试函数"></a>模板测试函数</h5><p>和深度测试一样，我们对模板缓冲应该通过还是失败，以及它应该如何影响模板缓冲，也是有一定控制的。一共有两个函数能够用来配置模板测试：glStencilFunc和glStencilOp。</p><p><code>glStencilFunc(GLenum func, GLint ref, GLuint mask)</code><br>一共包含三个参数：</p><ul><li>func：设置模板测试函数(Stencil Test Function)。这个测试函数将会应用到已储存的模板值上和glStencilFunc函数的ref值上。可用的选项有：GL_NEVER、GL_LESS、GL_LEQUAL、GL_GREATER、GL_GEQUAL、GL_EQUAL、GL_NOTEQUAL和GL_ALWAYS。它们的语义和深度缓冲的函数类似。</li><li>ref：设置了模板测试的参考值(Reference Value)。模板缓冲的内容将会与这个值进行比较。</li><li>mask：设置一个掩码，它将会与参考值和储存的模板值在测试比较它们之前进行与(AND)运算。初始情况下所有位都为1。</li></ul><p>在一开始的那个简单的模板例子中，函数被设置为：</p><p><code>glStencilFunc(GL_EQUAL, 1, 0xFF)</code><br>这会告诉OpenGL，只要一个片段的模板值等于(GL_EQUAL)参考值1，片段将会通过测试并被绘制，否则会被丢弃。</p><p>但是glStencilFunc仅仅描述了OpenGL应该对模板缓冲内容做什么，而不是我们应该如何更新缓冲。这就需要glStencilOp这个函数了。</p><p><code>glStencilOp(GLenum sfail, GLenum dpfail, GLenum dppass)</code><br>一共包含三个选项，我们能够设定每个选项应该采取的行为：</p><ul><li>sfail：模板测试失败时采取的行为。</li><li>dpfail：模板测试通过，但深度测试失败时采取的行为。</li><li>dppass：模板测试和深度测试都通过时采取的行为。<br>每个选项都可以选用以下的其中一种行为：</li></ul><p>行为    描述<br>GL_KEEP    保持当前储存的模板值<br>GL_ZERO    将模板值设置为0<br>GL_REPLACE    将模板值设置为glStencilFunc函数设置的ref值<br>GL_INCR    如果模板值小于最大值则将模板值加1<br>GL_INCR_WRAP    与GL_INCR一样，但如果模板值超过了最大值则归零<br>GL_DECR    如果模板值大于最小值则将模板值减1<br>GL_DECR_WRAP    与GL_DECR一样，但如果模板值小于0则将其设置为最大值<br>GL_INVERT    按位翻转当前的模板缓冲值<br>默认情况下glStencilOp是设置为(GL_KEEP, GL_KEEP, GL_KEEP)的，所以不论任何测试的结果是如何，模板缓冲都会保留它的值。默认的行为不会更新模板缓冲，所以如果你想写入模板缓冲的话，你需要至少对其中一个选项设置不同的值。</p><p>所以，通过使用glStencilFunc和glStencilOp，我们可以<strong>精确地指定更新模板缓冲的时机与行为了，我们也可以指定什么时候该让模板缓冲通过，即什么时候片段需要被丢弃</strong>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;深度测试&quot;&gt;&lt;a href=&quot;#深度测试&quot; class=&quot;headerlink&quot; title=&quot;深度测试&quot;&gt;&lt;/a&gt;深度测试&lt;/h4&gt;&lt;p&gt;深度缓冲(Depth Buffer)来防止被阻挡的面渲染到其它面的前面。在这一节中，我们将会更加深入地讨论这些储存在深度缓冲
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl光照</title>
    <link href="https://bytemode.github.io/2019/01/04/opengl%E5%85%89%E7%85%A7/"/>
    <id>https://bytemode.github.io/2019/01/04/opengl光照/</id>
    <published>2019-01-04T08:59:45.000Z</published>
    <updated>2019-01-04T09:18:38.849Z</updated>
    
    <content type="html"><![CDATA[<h4 id="基础光照"><a href="#基础光照" class="headerlink" title="基础光照"></a>基础光照</h4><p>这些光照模型都是基于我们对光的物理特性的理解。其中一个模型被称为冯氏光照模型(Phong Lighting Model)。冯氏光照模型的主要结构由3个分量组成：环境(Ambient)、漫反射(Diffuse)和镜面(Specular)光照。下面这张图展示了这些光照分量看起来的样子：<br><img src="https://img-blog.csdnimg.cn/2019010417032766.png" alt="基础光照"></p><ul><li>环境光照(Ambient Lighting)：即使在黑暗的情况下，世界上通常也仍然有一些光亮（月亮、远处的光），所以物体几乎永远不会是完全黑暗的。为了模拟这个，我们会使用一个环境光照常量，它永远会给物体一些颜色。</li><li>漫反射光照(Diffuse Lighting)：模拟光源对物体的方向性影响(Directional Impact)。它是冯氏光照模型中视觉上最显著的分量。物体的某一部分越是正对着光源，它就会越亮。</li><li>镜面光照(Specular Lighting)：模拟有光泽物体上面出现的亮点。镜面光照的颜色相比于物体的颜色会更倾向于光的颜色。</li></ul><h4 id="材质"><a href="#材质" class="headerlink" title="材质"></a>材质</h4><p>在现实世界里，每个物体会对光产生不同的反应。比如说，钢看起来通常会比陶瓷花瓶更闪闪发光，木头箱子也不会像钢制箱子那样对光产生很强的反射。每个物体对镜面高光也有不同的反应。有些物体反射光的时候不会有太多的散射(Scatter)，因而产生一个较小的高光点，而有些物体则会散射很多，产生一个有着更大半径的高光点。如果我们想要在OpenGL中模拟多种类型的物体，我们必须为每个物体分别定义一个材质(Material)属性。</p><p>我们指定了一个物体和光的颜色，以及结合环境光和镜面强度分量，来定义物体的视觉输出。当描述一个物体的时候，我们可以用这三个分量来定义一个材质颜色(Material Color)：环境光照(Ambient Lighting)、漫反射光照(Diffuse Lighting)和镜面光照(Specular Lighting)。通过为每个分量指定一个颜色，我们就能够对物体的颜色输出有着精细的控制了。现在，我们再添加反光度(Shininess)这个分量到上述的三个颜色中，这就有我们需要的所有材质属性了.</p><h4 id="光照贴图"><a href="#光照贴图" class="headerlink" title="光照贴图"></a>光照贴图</h4><p>漫反射和镜面光贴图(Map)。这允许我们对物体的漫反射分量（以及间接地对环境光分量，它们几乎总是一样的）和镜面光分量有着更精确的控制。</p><h4 id="投光物"><a href="#投光物" class="headerlink" title="投光物"></a>投光物</h4><h5 id="平行光"><a href="#平行光" class="headerlink" title="平行光"></a>平行光</h5><p>当一个光源处于很远的地方时，来自光源的每条光线就会近似于互相平行。不论物体和/或者观察者的位置，看起来好像所有的光都来自于同一个方向。当我们使用一个假设光源处于无限远处的模型时，它就被称为定向光，因为它的所有光线都有着相同的方向，它与光源的位置是没有关系的。</p><p>定向光非常好的一个例子就是太阳。太阳距离我们并不是无限远，但它已经远到在光照计算中可以把它视为无限远了。所以来自太阳的所有光线将被模拟为平行光线，我们可以在下图看到：</p><p><img src="https://img-blog.csdnimg.cn/20190104171451975.png" alt="平行光"></p><p>因为所有的光线都是平行的，所以物体与光源的相对位置是不重要的，因为对场景中每一个物体光的方向都是一致的。由于光的位置向量保持一致，场景中每个物体的光照计算将会是类似的。</p><h5 id="点光源"><a href="#点光源" class="headerlink" title="点光源"></a>点光源</h5><p>定向光对于照亮整个场景的全局光源是非常棒的，但除了定向光之外我们也需要一些分散在场景中的点光源(Point Light)。点光源是处于世界中某一个位置的光源，它会朝着所有方向发光，但光线会随着距离逐渐衰减。想象作为投光物的灯泡和火把，它们都是点光源。<br><img src="https://img-blog.csdnimg.cn/20190104171517360.png" alt="点光源"></p><h5 id="聚光源"><a href="#聚光源" class="headerlink" title="聚光源"></a>聚光源</h5><p>聚光是位于环境中某个位置的光源，它只朝一个特定方向而不是所有方向照射光线。这样的结果就是只有在聚光方向的特定半径内的物体才会被照亮，其它的物体都会保持黑暗。聚光很好的例子就是路灯或手电筒。</p><p>OpenGL中聚光是用一个世界空间位置、一个方向和一个切光角(Cutoff Angle)来表示的，切光角指定了聚光的半径（译注：是圆锥的半径不是距光源距离那个半径）。对于每个片段，我们会计算片段是否位于聚光的切光方向之间（也就是在锥形内），如果是的话，我们就会相应地照亮片段。下面这张图会让你明白聚光是如何工作的：</p><p><img src="https://img-blog.csdnimg.cn/20190104171634805.png" alt="聚光源"></p><p>LightDir：从片段指向光源的向量。<br>SpotDir：聚光所指向的方向。<br>Phiϕ：指定了聚光半径的切光角。落在这个角度之外的物体都不会被这个聚光所照亮。<br>Thetaθ：LightDir向量和SpotDir向量之间的夹角。在聚光内部的话θ值应该比ϕ值小。<br>所以我们要做的就是计算LightDir向量和SpotDir向量之间的点积（还记得它会返回两个单位向量夹角的余弦值吗？），并将它与切光角ϕ值对比。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;基础光照&quot;&gt;&lt;a href=&quot;#基础光照&quot; class=&quot;headerlink&quot; title=&quot;基础光照&quot;&gt;&lt;/a&gt;基础光照&lt;/h4&gt;&lt;p&gt;这些光照模型都是基于我们对光的物理特性的理解。其中一个模型被称为冯氏光照模型(Phong Lighting Model)。冯
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl摄像机</title>
    <link href="https://bytemode.github.io/2019/01/04/opengl%E6%91%84%E5%83%8F%E6%9C%BA/"/>
    <id>https://bytemode.github.io/2019/01/04/opengl摄像机/</id>
    <published>2019-01-04T08:35:12.000Z</published>
    <updated>2019-01-04T08:52:23.234Z</updated>
    
    <content type="html"><![CDATA[<h4 id="摄像机-观察空间"><a href="#摄像机-观察空间" class="headerlink" title="摄像机/观察空间"></a>摄像机/观察空间</h4><p>当我们讨论摄像机/观察空间(Camera/View Space)的时候，是在讨论以摄像机的视角作为场景原点时场景中所有的顶点坐标：观察矩阵把所有的世界坐标变换为相对于摄像机位置与方向的观察坐标。要定义一个摄像机，我们需要它在世界空间中的位置、观察的方向、一个指向它右测的向量以及一个指向它上方的向量。细心的读者可能已经注意到我们实际上创建了一个三个单位轴相互垂直的、以摄像机的位置为原点的坐标系。</p><ol><li>摄像机位置</li></ol><p>获取摄像机位置很简单。摄像机位置简单来说就是世界空间中一个指向摄像机位置的向量。我们把摄像机位置设置为上一节中的那个相同的位置：</p><p><code>glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f);</code><br>不要忘记正z轴是从屏幕指向你的，如果我们希望摄像机向后移动，我们就沿着z轴的正方向移动。</p><ol start="2"><li>摄像机方向</li></ol><p>下一个需要的向量是摄像机的方向，这里指的是摄像机指向哪个方向。现在我们让摄像机指向场景原点：(0, 0, 0)。还记得如果将两个矢量相减，我们就能得到这两个矢量的差吗？用场景原点向量减去摄像机位置向量的结果就是摄像机的指向向量。由于我们知道摄像机指向z轴负方向，但我们希望方向向量(Direction Vector)指向摄像机的z轴正方向。如果我们交换相减的顺序，我们就会获得一个指向摄像机正z轴方向的向量：</p><pre><code>glm::vec3 cameraTarget = glm::vec3(0.0f, 0.0f, 0.0f);glm::vec3 cameraDirection = glm::normalize(cameraPos - cameraTarget);</code></pre><p>方向向量(Direction Vector)并不是最好的名字，因为它实际上指向从它到目标向量的相反方向（译注：注意看前面的那个图，蓝色的方向向量大概指向z轴的正方向，与摄像机实际指向的方向是正好相反的）。</p><ol start="3"><li>右轴<br>我们需要的另一个向量是一个右向量(Right Vector)，它代表摄像机空间的x轴的正方向。为获取右向量我们需要先使用一个小技巧：先定义一个上向量(Up Vector)。接下来把上向量和第二步得到的方向向量进行叉乘。两个向量叉乘的结果会同时垂直于两向量，因此我们会得到指向x轴正方向的那个向量（如果我们交换两个向量叉乘的顺序就会得到相反的指向x轴负方向的向量）：</li></ol><pre><code>glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection));</code></pre><ol start="4"><li>上轴<br>现在我们已经有了x轴向量和z轴向量，获取一个指向摄像机的正y轴向量就相对简单了：我们把右向量和方向向量进行叉乘：</li></ol><pre><code>glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight);</code></pre><h4 id="LookAt"><a href="#LookAt" class="headerlink" title="LookAt"></a>LookAt</h4><p>你可以用这3个轴外加一个平移向量来创建一个矩阵，并且你可以用这个矩阵乘以任何向量来将其变换到那个坐标空间。这正是LookAt矩阵所做的，现在我们有了3个相互垂直的轴和一个定义摄像机空间的位置坐标，我们可以创建我们自己的LookAt矩阵了：<br><img src="https://img-blog.csdnimg.cn/20190104164558286.png" alt="lookat矩阵"></p><p>其中R是右向量，U是上向量，D是方向向量P是摄像机位置向量。注意，位置向量是相反的，因为我们最终希望把世界平移到与我们自身移动的相反方向。把这个LookAt矩阵作为观察矩阵可以很高效地把所有世界坐标变换到刚刚定义的观察空间。LookAt矩阵就像它的名字表达的那样：它会创建一个看着(Look at)给定目标的观察矩阵。</p><p>接着GLM就会创建一个LookAt矩阵，我们可以把它当作我们的观察矩阵：</p><pre><code>glm::mat4 view;view = glm::lookAt(glm::vec3(0.0f, 0.0f, 3.0f),            glm::vec3(0.0f, 0.0f, 0.0f),            glm::vec3(0.0f, 1.0f, 0.0f));</code></pre><p>glm::LookAt函数需要一个位置、目标和上向量。它会创建一个和在上面使用的一样的观察矩阵。</p><h4 id="摄像机移动"><a href="#摄像机移动" class="headerlink" title="摄像机移动"></a>摄像机移动</h4><p>让摄像机绕着场景转的确很有趣，但是让我们自己移动摄像机会更有趣！首先我们必须设置一个摄像机系统，所以在我们的程序前面定义一些摄像机变量很有用：</p><pre><code>glm::vec3 cameraPos   = glm::vec3(0.0f, 0.0f,  3.0f);glm::vec3 cameraFront = glm::vec3(0.0f, 0.0f, -1.0f);glm::vec3 cameraUp    = glm::vec3(0.0f, 1.0f,  0.0f);view = glm::lookAt(cameraPos, cameraPos + cameraFront, cameraUp);</code></pre><p>我们首先将摄像机位置设置为之前定义的cameraPos。方向是当前的位置加上我们刚刚定义的方向向量。这样能保证无论我们怎么移动，摄像机都会注视着目标方向。让我们摆弄一下这些向量，在按下某些按钮时更新cameraPos向量。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;摄像机-观察空间&quot;&gt;&lt;a href=&quot;#摄像机-观察空间&quot; class=&quot;headerlink&quot; title=&quot;摄像机/观察空间&quot;&gt;&lt;/a&gt;摄像机/观察空间&lt;/h4&gt;&lt;p&gt;当我们讨论摄像机/观察空间(Camera/View Space)的时候，是在讨论以摄像机的视
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl坐标系统</title>
    <link href="https://bytemode.github.io/2019/01/04/%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F/"/>
    <id>https://bytemode.github.io/2019/01/04/坐标系统/</id>
    <published>2019-01-04T03:44:40.000Z</published>
    <updated>2019-01-04T08:22:14.599Z</updated>
    
    <content type="html"><![CDATA[<h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>为了将坐标从一个坐标系变换到另一个坐标系，我们需要用到几个变换矩阵，最重要的几个分别是模型(Model)、观察(View)、投影(Projection)三个矩阵。我们的顶点坐标起始于局部空间(Local Space)，在这里它称为局部坐标(Local Coordinate)，它在之后会变为世界坐标(World Coordinate)，观察坐标(View Coordinate)，裁剪坐标(Clip Coordinate)，并最后以屏幕坐标(Screen Coordinate)的形式结束。下面的这张图展示了整个流程以及各个变换过程做了什么：</p><p><img src="https://img-blog.csdnimg.cn/20190104114754479.png" alt="坐标系统"></p><ol><li>局部坐标是对象相对于局部原点的坐标，也是物体起始的坐标。</li><li>下一步是将局部坐标变换为世界空间坐标，世界空间坐标是处于一个更大的空间范围的。这些坐标相对于世界的全局原点，它们会和其它物体一起相对于世界的原点进行摆放。</li><li>接下来我们将世界坐标变换为观察空间坐标，使得每个坐标都是从摄像机或者说观察者的角度进行观察的。</li><li>坐标到达观察空间之后，我们需要将其投影到裁剪坐标。裁剪坐标会被处理至-1.0到1.0的范围内，并判断哪些顶点将会出现在屏幕上。</li><li>最后，我们将裁剪坐标变换为屏幕坐标，我们将使用一个叫做视口变换(Viewport Transform)的过程。视口变换将位于-1.0到1.0范围的坐标变换到由glViewport函数所定义的坐标范围内。最后变换出来的坐标将会送到光栅器，将其转化为片段。</li></ol><p>局部空间<br>局部空间是指物体所在的坐标空间，即对象最开始所在的地方。想象你在一个建模软件（比如说Blender）中创建了一个立方体。你创建的立方体的原点有可能位于(0, 0, 0)，即便它有可能最后在程序中处于完全不同的位置。甚至有可能你创建的所有模型都以(0, 0, 0)为初始位置（译注：然而它们会最终出现在世界的不同位置）。所以，你的模型的所有顶点都是在局部空间中：它们相对于你的物体来说都是局部的。</p><p>我们一直使用的那个箱子的顶点是被设定在-0.5到0.5的坐标范围中，(0, 0)是它的原点。这些都是局部坐标。</p><h5 id="世界空间"><a href="#世界空间" class="headerlink" title="世界空间"></a>世界空间</h5><p>如果我们将我们所有的物体导入到程序当中，它们有可能会全挤在世界的原点(0, 0, 0)上，这并不是我们想要的结果。我们想为每一个物体定义一个位置，从而能在更大的世界当中放置它们。世界空间中的坐标正如其名：是指顶点相对于（游戏）世界的坐标。如果你希望将物体分散在世界上摆放（特别是非常真实的那样），这就是你希望物体变换到的空间。<strong>物体的坐标将会从局部变换到世界空间；该变换是由模型矩阵(Model Matrix)实现的</strong>。</p><p><strong>模型矩阵是一种变换矩阵，它能通过对物体进行位移、缩放、旋转来将它置于它本应该在的位置或朝向</strong>。你可以将它想像为变换一个房子，你需要先将它缩小（它在局部空间中太大了），并将其位移至郊区的一个小镇，然后在y轴上往左旋转一点以搭配附近的房子。</p><h5 id="观察空间"><a href="#观察空间" class="headerlink" title="观察空间"></a>观察空间</h5><p>观察空间经常被人们称之OpenGL的摄像机(Camera)（所以有时也称为摄像机空间(Camera Space)或视觉空间(Eye Space)）。<strong>观察空间是将世界空间坐标转化为用户视野前方的坐标而产生的结果。因此观察空间就是从摄像机的视角所观察到的空间</strong>。而这通常是由一系列的位移和旋转的组合来完成，平移/旋转场景从而使得特定的对象被变换到摄像机的前方。<strong>这些组合在一起的变换通常存储在一个观察矩阵(View Matrix)里，它被用来将世界坐标变换到观察空间</strong>。</p><h5 id="裁剪空间"><a href="#裁剪空间" class="headerlink" title="裁剪空间"></a>裁剪空间</h5><p>在一个顶点着色器运行的最后，OpenGL期望所有的坐标都能落在一个特定的范围内，且任何在这个范围之外的点都应该被裁剪掉(Clipped)。被裁剪掉的坐标就会被忽略，所以剩下的坐标就将变为屏幕上可见的片段。这也就是裁剪空间(Clip Space)名字的由来。</p><p>因为将所有可见的坐标都指定在-1.0到1.0的范围内不是很直观，所以我们会指定自己的坐标集(Coordinate Set)并将它变换回标准化设备坐标系，就像OpenGL期望的那样。</p><p><strong>为了将顶点坐标从观察变换到裁剪空间，我们需要定义一个投影矩阵(Projection Matrix)</strong>，它指定了一个范围的坐标，比如在每个维度上的-1000到1000。<strong>投影矩阵接着会将在这个指定的范围内的坐标变换为标准化设备坐标的范围(-1.0, 1.0)</strong>。所有在范围外的坐标不会被映射到在-1.0到1.0的范围之间，所以会被裁剪掉。在上面这个投影矩阵所指定的范围内，坐标(1250, 500, 750)将是不可见的，这是由于它的x坐标超出了范围，它被转化为一个大于1.0的标准化设备坐标，所以被裁剪掉了。</p><p>如果只是图元(Primitive)，例如三角形，的一部分超出了裁剪体积(Clipping Volume)，则OpenGL会重新构建这个三角形为一个或多个三角形让其能够适合这个裁剪范围。</p><p>由投影矩阵创建的观察箱(Viewing Box)被称为平截头体(Frustum)，每个出现在平截头体范围内的坐标都会最终出现在用户的屏幕上。将特定范围内的坐标转化到标准化设备坐标系的过程（而且它很容易被映射到2D观察空间坐标）被称之为投影(Projection)，因为使用投影矩阵能将3D坐标投影(Project)到很容易映射到2D的标准化设备坐标系中。</p><p>一旦所有顶点被变换到裁剪空间，最终的操作——透视除法(Perspective Division)将会执行，在这个过程中我们将位置向量的x，y，z分量分别除以向量的齐次w分量；透视除法是将4D裁剪空间坐标变换为3D标准化设备坐标的过程。这一步会在每一个顶点着色器运行的最后被自动执行。</p><p>在这一阶段之后，最终的坐标将会被映射到屏幕空间中（使用glViewport中的设定），并被变换成片段。</p><blockquote><p>将观察坐标变换为裁剪坐标的投影矩阵可以为两种不同的形式，每种形式都定义了不同的平截头体。我们可以选择创建一个正射投影矩阵(Orthographic Projection Matrix)或一个透视投影矩阵(Perspective Projection Matrix)。</p></blockquote><h6 id="正射投影"><a href="#正射投影" class="headerlink" title="正射投影"></a>正射投影</h6><p>正射投影矩阵定义了一个类似立方体的平截头箱，它定义了一个裁剪空间，在这空间之外的顶点都会被裁剪掉。创建一个正射投影矩阵需要指定可见平截头体的宽、高和长度。在使用正射投影矩阵变换至裁剪空间之后处于这个平截头体内的所有坐标将不会被裁剪掉。它的平截头体看起来像一个容器：</p><p><img src="https://img-blog.csdnimg.cn/20190104120203150.png" alt="正射投影"></p><p>上面的平截头体定义了可见的坐标，它由由宽、高、近(Near)平面和远(Far)平面所指定。任何出现在近平面之前或远平面之后的坐标都会被裁剪掉。正射平截头体直接将平截头体内部的所有坐标映射为标准化设备坐标，因为每个向量的w分量都没有进行改变；如果w分量等于1.0，透视除法则不会改变这个坐标。</p><p>要创建一个正射投影矩阵，我们可以使用GLM的内置函数glm::ortho：</p><p><code>glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);</code><br>前两个参数指定了平截头体的左右坐标，第三和第四参数指定了平截头体的底部和顶部。通过这四个参数我们定义了近平面和远平面的大小，然后第五和第六个参数则定义了近平面和远平面的距离。这个投影矩阵会将处于这些x，y，z值范围内的坐标变换为标准化设备坐标。</p><p>正射投影矩阵直接将坐标映射到2D平面中，即你的屏幕，但实际上一个直接的投影矩阵会产生不真实的结果，因为这个投影没有将透视(Perspective)考虑进去。所以我们需要透视投影矩阵来解决这个问题。</p><h6 id="透视投影"><a href="#透视投影" class="headerlink" title="透视投影"></a>透视投影</h6><p>如果你曾经体验过实际生活给你带来的景象，你就会注意到离你越远的东西看起来更小。这个奇怪的效果称之为透视(Perspective)。透视的效果在我们看一条无限长的高速公路或铁路时尤其明显，正如下面图片显示的那样：</p><p><img src="https://img-blog.csdnimg.cn/20190104120423164.png" alt="透视投影"></p><p>正如你看到的那样，由于透视，这两条线在很远的地方看起来会相交。这正是透视投影想要模仿的效果，它是使用透视投影矩阵来完成的。这个投影矩阵将给定的平截头体范围映射到裁剪空间，除此之外还修改了每个顶点坐标的w值，从而使得离观察者越远的顶点坐标w分量越大。被变换到裁剪空间的坐标都会在-w到w的范围之间（任何大于这个范围的坐标都会被裁剪掉）。OpenGL要求所有可见的坐标都落在-1.0到1.0范围内，作为顶点着色器最后的输出，因此，一旦坐标在裁剪空间内之后，透视除法就会被应用到裁剪空间坐标上：</p><p><img src="https://img-blog.csdnimg.cn/20190104160059276.png" alt="w"><br>顶点坐标的每个分量都会除以它的w分量，距离观察者越远顶点坐标就会越小。这是也是w分量非常重要的另一个原因，它能够帮助我们进行透视投影。最后的结果坐标就是处于标准化设备空间中的。</p><p>在GLM中可以这样创建一个透视投影矩阵：</p><pre><code>glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f);</code></pre><p>同样，glm::perspective所做的其实就是创建了一个定义了可视空间的大平截头体，任何在这个平截头体以外的东西最后都不会出现在裁剪空间体积内，并且将会受到裁剪。一个透视平截头体可以被看作一个不均匀形状的箱子，在这个箱子内部的每个坐标都会被映射到裁剪空间上的一个点。下面是一张透视平截头体的图片：</p><p><img src="https://img-blog.csdnimg.cn/20190104160139427.png" alt="视椎体"></p><p>它的第一个参数定义了fov的值，它表示的是视野(Field of View)，并且设置了观察空间的大小。如果想要一个真实的观察效果，它的值通常设置为45.0f，但想要一个末日风格的结果你可以将其设置一个更大的值。第二个参数设置了宽高比，由视口的宽除以高所得。第三和第四个参数设置了平截头体的近和远平面。我们通常设置近距离为0.1f，而远距离设为100.0f。所有在近平面和远平面内且处于平截头体内的顶点都会被渲染。</p><p>当你把透视矩阵的 near 值设置太大时（如10.0f），OpenGL会将靠近摄像机的坐标（在0.0f和10.0f之间）都裁剪掉，这会导致一个你在游戏中很熟悉的视觉效果：在太过靠近一个物体的时候你的视线会直接穿过去。</p><p>当使用正射投影时，<strong>每一个顶点坐标都会直接映射到裁剪空间中而不经过任何精细的透视除法（它仍然会进行透视除法，只是w分量没有被改变（它保持为1），因此没有起作用）。因为正射投影没有使用透视，远处的物体不会显得更小，所以产生奇怪的视觉效果。</strong>由于这个原因，正射投影主要用于二维渲染以及一些建筑或工程的程序，在这些场景中我们更希望顶点不会被透视所干扰。某些如 Blender 等进行三维建模的软件有时在建模时也会使用正射投影，因为它在各个维度下都更准确地描绘了每个物体。下面你能够看到在Blender里面使用两种投影方式的对比：</p><p><img src="https://img-blog.csdnimg.cn/20190104160431753.png" alt="透视投影正交投影"></p><p>你可以看到，使用透视投影的话，远处的顶点看起来比较小，而在正射投影中每个顶点距离观察者的距离都是一样的。</p><h4 id="模型视图投影矩阵"><a href="#模型视图投影矩阵" class="headerlink" title="模型视图投影矩阵"></a>模型视图投影矩阵</h4><p>我们为上述的每一个步骤都创建了一个变换矩阵：模型矩阵、观察矩阵和投影矩阵。一个顶点坐标将会根据以下过程被变换到裁剪坐标：</p><p><img src="https://img-blog.csdnimg.cn/20190104160510251.png" alt="模型视图投影矩阵"><br>注意矩阵运算的顺序是相反的（记住我们需要从右往左阅读矩阵的乘法）。最后的顶点应该被赋值到顶点着色器中的gl_Position，OpenGL将会自动进行透视除法和裁剪。</p><p><strong>顶点着色器的输出要求所有的顶点都在裁剪空间内，这正是我们刚才使用变换矩阵所做的。OpenGL然后对裁剪坐标执行透视除法从而将它们变换到标准化设备坐标。OpenGL会使用glViewPort内部的参数来将标准化设备坐标映射到屏幕坐标，每个坐标都关联了一个屏幕上的点。这个过程称为视口变换。</strong></p><h4 id="右手坐标系-Right-handed-System"><a href="#右手坐标系-Right-handed-System" class="headerlink" title="右手坐标系(Right-handed System)"></a>右手坐标系(Right-handed System)</h4><p>OpenGL是一个右手坐标系。简单来说，就是正x轴在你的右手边，正y轴朝上，而正z轴是朝向后方的。想象你的屏幕处于三个轴的中心，则正z轴穿过你的屏幕朝向你。坐标系画起来如下：</p><p><img src="https://img-blog.csdnimg.cn/20190104161222624.png" alt="右手坐标系"></p><p>为了理解为什么被称为右手坐标系，按如下的步骤做：</p><ul><li>沿着正y轴方向伸出你的右臂，手指着上方。</li><li>大拇指指向右方。</li><li>食指指向上方。</li><li>中指向下弯曲90度。<br>如果你的动作正确，那么你的大拇指指向正x轴方向，食指指向正y轴方向，中指指向正z轴方向。如果你用左臂来做这些动作，你会发现z轴的方向是相反的。这个叫做左手坐标系，它被DirectX广泛地使用。注意在标准化设备坐标系中OpenGL实际上使用的是左手坐标系（投影矩阵交换了左右手）。</li></ul><h4 id="Z缓冲"><a href="#Z缓冲" class="headerlink" title="Z缓冲"></a>Z缓冲</h4><p>OpenGL存储它的所有深度信息于一个Z缓冲(Z-buffer)中，也被称为深度缓冲(Depth Buffer)。GLFW会自动为你生成这样一个缓冲（就像它也有一个颜色缓冲来存储输出图像的颜色）。深度值存储在每个片段里面（作为片段的z值），当片段想要输出它的颜色时，OpenGL会将它的深度值和z缓冲进行比较，如果当前的片段在其它片段之后，它将会被丢弃，否则将会覆盖。这个过程称为深度测试(Depth Testing)，它是由OpenGL自动完成的。</p><p>然而，如果我们想要确定OpenGL真的执行了深度测试，首先我们要告诉OpenGL我们想要启用深度测试；它默认是关闭的。我们可以通过glEnable函数来开启深度测试。glEnable和glDisable函数允许我们启用或禁用某个OpenGL功能。这个功能会一直保持启用/禁用状态，直到另一个调用来禁用/启用它。现在我们想启用深度测试，需要开启GL_DEPTH_TEST：</p><p><code>glEnable(GL_DEPTH_TEST);</code><br>因为我们使用了深度测试，我们也想要在每次渲染迭代之前清除深度缓冲（否则前一帧的深度信息仍然保存在缓冲中）。就像清除颜色缓冲一样，我们可以通过在glClear函数中指定DEPTH_BUFFER_BIT位来清除深度缓冲：</p><p><code>glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);</code></p>]]></content>
    
    <summary type="html">
    
      顶点着色器的输出要求所有的顶点都在裁剪空间内，这正是模型视图投影矩阵使用变换矩阵所做的。OpenGL然后对裁剪坐标执行透视除法从而将它们变换到标准化设备坐标。OpenGL会使用glViewPort内部的参数来将标准化设备坐标映射到屏幕坐标，每个坐标都关联了一个屏幕上的点。这个过程称为视口变换。
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl矩阵向量</title>
    <link href="https://bytemode.github.io/2019/01/03/opengl%E7%9F%A9%E9%98%B5%E5%90%91%E9%87%8F/"/>
    <id>https://bytemode.github.io/2019/01/03/opengl矩阵向量/</id>
    <published>2019-01-03T10:03:43.000Z</published>
    <updated>2019-01-04T03:32:23.033Z</updated>
    
    <content type="html"><![CDATA[<p>如何创建一个物体、着色、加入纹理，给它们一些细节的表现，但因为它们都还是静态的物体，仍是不够有趣。我们可以尝试着在每一帧改变物体的顶点并且重配置缓冲区从而使它们移动，但这太繁琐了，而且会消耗很多的处理时间。我们现在有一个更好的解决方案，使用（多个）矩阵(Matrix)对象可以更好的变换(Transform)一个物体。</p><h4 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h4><p>向量最基本的定义就是一个方向。或者更正式的说，向量有一个方向(Direction)和大小(Magnitude，也叫做强度或长度)。你可以把向量想像成一个藏宝图上的指示：“向左走10步，向北走3步，然后向右走5步”；“左”就是方向，“10步”就是向量的长度。那么这个藏宝图的指示一共有3个向量。向量可以在任意维度(Dimension)上，但是我们通常只使用2至4维。如果一个向量有2个维度，它表示一个平面的方向(想象一下2D的图像)，当它有3个维度的时候它可以表达一个3D世界的方向。</p><p>下面你会看到3个向量，每个向量在2D图像中都用一个箭头(x, y)表示。我们在2D图片中展示这些向量，因为这样子会更直观一点。你可以把这些2D向量当做z坐标为0的3D向量。由于向量表示的是方向，起始于何处并不会改变它的值。下图我们可以看到向量v¯和w¯是相等的，尽管他们的起始点不同：<br><img src="https://img-blog.csdnimg.cn/20190103180830580.png" alt="向量"></p><p>数学家喜欢在字母上面加一横表示向量，比如说v¯。当用在公式中时它们通常是这样的：<br><img src="https://img-blog.csdnimg.cn/2019010318094392.png" alt="向量"><br>由于向量是一个方向，所以有些时候会很难形象地将它们用位置(Position)表示出来。为了让其更为直观，我们通常设定这个方向的原点为(0, 0, 0)，然后指向一个方向，对应一个点，使其变为位置向量(Position Vector)（你也可以把起点设置为其他的点，然后说：这个向量从这个点起始指向另一个点）。比如说位置向量(3, 5)在图像中的起点会是(0, 0)，并会指向(3, 5)。我们可以使用向量在2D或3D空间中表示方向与位置.</p><p>和普通数字一样，我们也可以用向量进行多种运算（其中一些你可能已经看到过了）。</p><h5 id="向量与标量运算"><a href="#向量与标量运算" class="headerlink" title="向量与标量运算"></a>向量与标量运算</h5><p>标量(Scalar)只是一个数字（或者说是仅有一个分量的向量）。当把一个向量加/减/乘/除一个标量，我们可以简单的把向量的每个分量分别进行该运算。对于加法来说会像这样:</p><p><img src="https://img-blog.csdnimg.cn/20190103181142306.png" alt="向量加标量运算"><br>其中的+可以是+，-，·或÷，其中·是乘号。注意－和÷运算时不能颠倒（标量-/÷向量），因为颠倒的运算是没有定义的。</p><h5 id="向量取反"><a href="#向量取反" class="headerlink" title="向量取反"></a>向量取反</h5><p>对一个向量取反(Negate)会将其方向逆转。一个指向东北的向量取反后就指向西南方向了。我们在一个向量的每个分量前加负号就可以实现取反了（或者说用-1数乘该向量）:</p><p><img src="https://img-blog.csdnimg.cn/20190103181524341.png" alt="向量取反"></p><h5 id="向量加减"><a href="#向量加减" class="headerlink" title="向量加减"></a>向量加减</h5><p>向量的加法可以被定义为是分量的(Component-wise)相加，即将一个向量中的每一个分量加上另一个向量的对应分量：</p><p><img src="https://img-blog.csdnimg.cn/201901031817369.png" alt="向量加法"><br>向量v = (4, 2)和k = (1, 2)可以直观地表示为：</p><p><img src="https://img-blog.csdnimg.cn/20190103182013546.png" alt="向量加法"></p><p>就像普通数字的加减一样，向量的减法等于加上第二个向量的相反向量：</p><p><img src="https://img-blog.csdnimg.cn/20190103182208215.png" alt="向量减法"><br>两个向量的相减会得到这两个向量指向位置的差。这在我们想要获取两点的差会非常有用。<br><img src="https://img-blog.csdnimg.cn/201901031823044.png" alt="向量减法"></p><h5 id="长度"><a href="#长度" class="headerlink" title="长度"></a>长度</h5><p>我们使用勾股定理(Pythagoras Theorem)来获取向量的长度(Length)/大小(Magnitude)。如果你把向量的x与y分量画出来，该向量会和x与y分量为边形成一个三角形:</p><p><img src="https://img-blog.csdnimg.cn/20190103182415227.png" alt="向量长度"></p><p>因为两条边（x和y）是已知的，如果希望知道斜边v¯的长度，我们可以直接通过勾股定理来计算：</p><p><img src="https://img-blog.csdnimg.cn/20190103182540618.png" alt="向量长度"><br>||v¯||表示向量v¯的长度，我们也可以加上z2把这个公式拓展到三维空间。</p><p>例子中向量(4, 2)的长度等于：</p><p><img src="https://img-blog.csdnimg.cn/20190103182607589.png" alt="向量长度"><br>结果是4.47。</p><p>有一个特殊类型的向量叫做单位向量(Unit Vector)。单位向量有一个特别的性质——它的长度是1。我们可以用任意向量的每个分量除以向量的长度得到它的单位向量n̂ ：</p><p><img src="https://img-blog.csdnimg.cn/20190103182653355.png" alt="单位向量"><br>我们把这种方法叫做一个向量的标准化(Normalizing)。单位向量头上有一个^样子的记号。通常单位向量会变得很有用，特别是在我们只关心方向不关心长度的时候（如果改变向量的长度，它的方向并不会改变）。</p><h5 id="向量相乘"><a href="#向量相乘" class="headerlink" title="向量相乘"></a>向量相乘</h5><p>两个向量相乘是一种很奇怪的情况。普通的乘法在向量上是没有定义的，因为它在视觉上是没有意义的。但是在相乘的时候我们有两种特定情况可以选择：一个是点乘(Dot Product)，记作v¯⋅k¯，另一个是叉乘(Cross Product)，记作v¯×k¯。<br><img src="https://img-blog.csdnimg.cn/2019010411131463.png" alt="点乘和叉乘"></p><h5 id="点乘"><a href="#点乘" class="headerlink" title="点乘"></a>点乘</h5><p>两个向量的点乘等于它们的<strong>数乘结果乘以两个向量之间夹角的余弦值</strong>。可能听起来有点费解，我们来看一下公式：</p><p><img src="https://img-blog.csdnimg.cn/20190103183110702.png" alt="点乘"><br>它们之间的夹角记作θ。为什么这很有用？想象如果v¯和k¯都是单位向量，它们的长度会等于1。这样公式会有效简化成：</p><p><img src="https://img-blog.csdnimg.cn/20190103183133651.png" alt="点乘法"><br>现在点积只定义了两个向量的夹角。你也许记得90度的余弦值是0，0度的余弦值是1。使用点乘可以很容易测试两个向量是否正交(Orthogonal)或平行（正交意味着两个向量互为直角）。</p><p>所以，我们该如何计算点乘呢？<strong>点乘是通过将对应分量逐个相乘，然后再把所得积相加来计算的</strong>。两个单位向量的（你可以验证它们的长度都为1）点乘会像是这样：</p><p><img src="https://img-blog.csdnimg.cn/20190103183710476.png" alt="点乘计算"><br>点乘会在计算光照的时候非常有用。</p><h5 id="叉乘"><a href="#叉乘" class="headerlink" title="叉乘"></a>叉乘</h5><p>叉乘只在3D空间中有定义，它需要两个不平行向量作为输入，生成一个正交于两个输入向量的第三个向量。如果输入的两个向量也是正交的，那么叉乘之后将会产生3个互相正交的向量。接下来的教程中这会非常有用。下面的图片展示了3D空间中叉乘的样子：<br><img src="https://img-blog.csdnimg.cn/20190103201407188.png" alt="3D空间叉乘"></p><p>下面你会看到两个正交向量A和B叉积：<br><img src="https://img-blog.csdnimg.cn/20190103194846505.png" alt="向量叉乘"></p><h4 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h4><p>现在我们已经讨论了向量的全部内容，是时候看看矩阵了！简单来说矩阵就是一个矩形的数字、符号或表达式数组。矩阵中每一项叫做矩阵的元素(Element)。下面是一个2×3矩阵的例子：</p><p><img src="https://img-blog.csdnimg.cn/20190103201516114.png" alt="2*3矩阵"><br>矩阵可以通过(i, j)进行索引，i是行，j是列，这就是上面的矩阵叫做2×3矩阵的原因（3列2行，也叫做矩阵的维度(Dimension)）。这与你在索引2D图像时的(x, y)相反，获取4的索引是(2, 1)（第二行，第一列）（译注：如果是图像索引应该是(1, 2)，先算列，再算行）。</p><p>矩阵基本也就是这些了，它就是一个矩形的数学表达式阵列。和向量一样，矩阵也有非常漂亮的数学属性。矩阵有几个运算，分别是：矩阵加法、减法和乘法。</p><h5 id="矩阵的加减"><a href="#矩阵的加减" class="headerlink" title="矩阵的加减"></a>矩阵的加减</h5><p>矩阵与标量之间的加减定义如下：</p><p><img src="https://img-blog.csdnimg.cn/20190103213154595.png" alt="矩阵和标量加"><br>标量值要加到矩阵的每一个元素上。矩阵与标量的减法也相似：</p><p><img src="https://img-blog.csdnimg.cn/20190103213235298.png" alt="矩阵和标量减"><br>矩阵与矩阵之间的加减就是两个矩阵对应元素的加减运算，所以总体的规则和与标量运算是差不多的，只不过在相同索引下的元素才能进行运算。这也就是说加法和减法只对同维度的矩阵才是有定义的。一个3×2矩阵和一个2×3矩阵（或一个3×3矩阵与4×4矩阵）是不能进行加减的。我们看看两个2×2矩阵是怎样相加的：</p><p><img src="https://img-blog.csdnimg.cn/20190103213305827.png" alt="矩阵加法"><br>同样的法则也适用于减法：</p><p><img src="https://img-blog.csdnimg.cn/20190103213358321.png" alt="矩阵减法"></p><h5 id="矩阵的数乘"><a href="#矩阵的数乘" class="headerlink" title="矩阵的数乘"></a>矩阵的数乘</h5><p>和矩阵与标量的加减一样，矩阵与标量之间的乘法也是矩阵的每一个元素分别乘以该标量。下面的例子展示了乘法的过程：<br><img src="https://img-blog.csdnimg.cn/20190103213505740.png" alt="矩阵数乘"></p><p>现在我们也就能明白为什么这些单独的数字要叫做标量(Scalar)了。简单来说，标量就是用它的值缩放(Scale)矩阵的所有元素（译注：注意Scalar是由Scale + -ar演变过来的）。前面那个例子中，所有的元素都被放大了2倍。</p><h5 id="矩阵相乘"><a href="#矩阵相乘" class="headerlink" title="矩阵相乘"></a>矩阵相乘</h5><p>矩阵之间的乘法不见得有多复杂，但的确很难让人适应。矩阵乘法基本上意味着遵照规定好的法则进行相乘。当然，相乘还有一些限制：</p><ol><li>只有当左侧矩阵的列数与右侧矩阵的行数相等，两个矩阵才能相乘。</li><li>矩阵相乘不遵守交换律(Commutative)，也就是说A⋅B≠B⋅A。<br>我们先看一个两个2×2矩阵相乘的例子：<br><img src="https://img-blog.csdnimg.cn/20190103213856187.png" alt="矩阵乘法"></li></ol><p><img src="https://img-blog.csdnimg.cn/20190103214041908.png" alt="矩阵乘法"></p><p>结果矩阵的维度是(n, m)，n等于左侧矩阵的行数，m等于右侧矩阵的列数。</p><h5 id="矩阵与向量相乘"><a href="#矩阵与向量相乘" class="headerlink" title="矩阵与向量相乘"></a>矩阵与向量相乘</h5><p>我们用向量来表示位置，表示颜色，甚至是纹理坐标。向量和矩阵一样都是一个数字序列，但它只有1列。那么，这个新的定义对我们有什么帮助呢？如果我们有一个M×N矩阵，我们可以用这个矩阵乘以我们的N×1向量，因为这个矩阵的列数等于向量的行数，所以它们就能相乘。</p><p>很多有趣的2D/3D变换都可以放在一个矩阵中，用这个矩阵乘以我们的向量将变换(Transform)这个向量。</p><h6 id="单位矩阵"><a href="#单位矩阵" class="headerlink" title="单位矩阵"></a>单位矩阵</h6><p>在OpenGL中，由于某些原因我们通常使用4×4的变换矩阵，而其中最重要的原因就是大部分的向量都是4分量的。我们能想到的最简单的变换矩阵就是单位矩阵(Identity Matrix)。单位矩阵是一个除了对角线以外都是0的N×N矩阵。在下式中可以看到，这种变换矩阵使一个向量完全不变：</p><p><img src="https://img-blog.csdnimg.cn/20190103214452829.png" alt="单位矩阵"><br>向量看起来完全没变。从乘法法则来看就很容易理解来：第一个结果元素是矩阵的第一行的每个元素乘以向量的每个对应元素。因为每行的元素除了第一个都是0，可得：1⋅1+0⋅2+0⋅3+0⋅4=1，向量的其他3个元素同理。</p><h5 id="缩放"><a href="#缩放" class="headerlink" title="缩放"></a>缩放</h5><p>对一个向量进行缩放(Scaling)就是对向量的长度进行缩放，而保持它的方向不变。由于我们进行的是2维或3维操作，我们可以分别定义一个有2或3个缩放变量的向量，每个变量缩放一个轴(x、y或z)。</p><p>我们先来尝试缩放向量v¯=(3,2)。我们可以把向量沿着x轴缩放0.5，使它的宽度缩小为原来的二分之一；我们将沿着y轴把向量的高度缩放为原来的两倍。我们看看把向量缩放(0.5, 2)倍所获得的s¯是什么样的：<br><img src="https://img-blog.csdnimg.cn/20190104105421976.png" alt="向量缩放"></p><p>记住，OpenGL通常是在3D空间进行操作的，对于2D的情况我们可以把z轴缩放1倍，这样z轴的值就不变了。我们刚刚的缩放操作是不均匀(Non-uniform)缩放，因为每个轴的缩放因子(Scaling Factor)都不一样。如果每个轴的缩放因子都一样那么就叫均匀缩放(Uniform Scale)。</p><p>我们下面会构造一个变换矩阵来为我们提供缩放功能。我们从单位矩阵了解到，每个对角线元素会分别与向量的对应元素相乘。如果我们把1变为3会怎样？这样子的话，我们就把向量的每个元素乘以3了，这事实上就把向量缩放3倍。如果我们把缩放变量表示为(S1,S2,S3)我们可以为任意向量(x,y,z)定义一个缩放矩阵：</p><p><img src="https://img-blog.csdnimg.cn/20190104105548246.png" alt="向量缩放"><br>注意，第四个缩放向量仍然是1，因为在3D空间中缩放w分量是无意义的。w分量另有其他用途，在后面我们会看到。</p><h5 id="位移"><a href="#位移" class="headerlink" title="位移"></a>位移</h5><p>位移(Translation)是在原始向量的基础上加上另一个向量从而获得一个在不同位置的新向量的过程，从而在位移向量基础上移动了原始向量。我们已经讨论了向量加法，所以这应该不会太陌生。</p><p>和缩放矩阵一样，在4×4矩阵上有几个特别的位置用来执行特定的操作，对于位移来说它们是第四列最上面的3个值。如果我们把位移向量表示为(Tx,Ty,Tz)，我们就能把位移矩阵定义为：</p><p><img src="https://img-blog.csdnimg.cn/20190104111509624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jsb2dzdW4=,size_16,color_FFFFFF,t_70" alt="向量位移"><br>这样是能工作的，因为所有的位移值都要乘以向量的w行，所以位移值会加到向量的原始值上（想想矩阵乘法法则）。而如果你用3x3矩阵我们的位移值就没地方放也没地方乘了，所以是不行的。</p><h5 id="齐次坐标-Homogeneous-Coordinates"><a href="#齐次坐标-Homogeneous-Coordinates" class="headerlink" title="齐次坐标(Homogeneous Coordinates)"></a>齐次坐标(Homogeneous Coordinates)</h5><p>向量的w分量也叫齐次坐标。想要从齐次向量得到3D向量，我们可以把x、y和z坐标分别除以w坐标。我们通常不会注意这个问题，因为w分量通常是1.0。使用齐次坐标有几点好处：它允许我们在3D向量上进行位移（如果没有w分量我们是不能位移向量的），而且下一章我们会用w值创建3D视觉效果。</p><p>如果一个向量的齐次坐标是0，这个坐标就是方向向量(Direction Vector)，因为w坐标是0，这个向量就不能位移（译注：这也就是我们说的不能位移一个方向）。</p><p>有了位移矩阵我们就可以在3个方向(x、y、z)上移动物体，它是我们的变换工具箱中非常有用的一个变换矩阵。</p><h5 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h5><p>上面几个的变换内容相对容易理解，在2D或3D空间中也容易表示出来，但旋转(Rotation)稍复杂些。如果你想知道旋转矩阵是如何构造出来的，我推荐你去看可汗学院线性代数的视频。</p><p>首先我们来定义一个向量的旋转到底是什么。2D或3D空间中的旋转用角(Angle)来表示。角可以是角度制或弧度制的，周角是360角度或2 PI弧度。我个人更喜欢用角度，因为它们看起来更直观。</p><ul><li>弧度转角度：角度 = 弧度 * (180.0f / PI)</li><li>角度转弧度：弧度 = 角度 * (PI / 180.0f)</li><li>PI约等于3.14159265359。</li></ul><p>转半圈会旋转360/2 = 180度，向右旋转1/5圈表示向右旋转360/5 = 72度。下图中展示的2D向量v¯是由k¯向右旋转72度所得的：<br><img src="https://img-blog.csdnimg.cn/20190104112227528.png" alt="向量旋转"></p><p>在3D空间中旋转需要定义一个角和一个旋转轴(Rotation Axis)。物体会沿着给定的旋转轴旋转特定角度。如果你想要更形象化的感受，可以试试向下看着一个特定的旋转轴，同时将你的头部旋转一定角度。当2D向量在3D空间中旋转时，我们把旋转轴设为z轴（尝试想象这种情况）。</p><p>使用三角学，给定一个角度，可以把一个向量变换为一个经过旋转的新向量。这通常是使用一系列正弦和余弦函数（一般简称sin和cos）各种巧妙的组合得到的。当然，讨论如何生成变换矩阵超出了这个教程的范围。</p><p>旋转矩阵在3D空间中每个单位轴都有不同定义，旋转角度用θ表示：</p><p>沿x轴旋转：</p><p><img src="https://img-blog.csdnimg.cn/20190104112559960.png" alt="x轴旋转"><br>沿y轴旋转：</p><p><img src="https://img-blog.csdnimg.cn/20190104112627759.png" alt="y轴旋转"><br>沿z轴旋转：</p><p><img src="https://img-blog.csdnimg.cn/20190104112655708.png" alt="z轴旋转"><br>利用旋转矩阵我们可以把任意位置向量沿一个单位旋转轴进行旋转。也可以将多个矩阵复合，比如先沿着x轴旋转再沿着y轴旋转。但是这会很快导致一个问题——万向节死锁（Gimbal Lock，可以看看这个视频（优酷）来了解）。在这里我们不会讨论它的细节，但是对于3D空间中的旋转，一个更好的模型是沿着任意的一个轴，比如单位向量$(0.662, 0.2, 0.7222)$旋转，而不是对一系列旋转矩阵进行复合。这样的一个（超级麻烦的）矩阵是存在的，见下面这个公式，其中(Rx,Ry,Rz)代表任意旋转轴：</p><p><img src="https://img-blog.csdnimg.cn/20190104112754727.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Jsb2dzdW4=,size_16,color_FFFFFF,t_70" alt="任意轴旋转"><br>在数学上讨论如何生成这样的矩阵仍然超出了本节内容。但是记住，即使这样一个矩阵也不能完全解决万向节死锁问题（尽管会极大地避免）。避免万向节死锁的真正解决方案是使用四元数(Quaternion)，它不仅更安全，而且计算会更有效率。</p><p>矩阵的组合<br>使用矩阵进行变换的真正力量在于，根据矩阵之间的乘法，我们可以把多个变换组合到一个矩阵中。让我们看看我们是否能生成一个变换矩阵，让它组合多个变换。假设我们有一个顶点(x, y, z)，我们希望将其缩放2倍，然后位移(1, 2, 3)个单位。我们需要一个位移和缩放矩阵来完成这些变换。结果的变换矩阵看起来像这样：</p><p><img src="https://img-blog.csdnimg.cn/20190104112941824.png" alt="矩阵组合"><br>注意，当矩阵相乘时我们先写位移再写缩放变换的。矩阵乘法是不遵守交换律的，这意味着它们的顺序很重要。当矩阵相乘时，在最右边的矩阵是第一个与向量相乘的，所以你应该从右向左读这个乘法。建议您在组合矩阵时，先进行缩放操作，然后是旋转，最后才是位移，否则它们会（消极地）互相影响。比如，如果你先位移再缩放，位移的向量也会同样被缩放（译注：比如向某方向移动2米，2米也许会被缩放成1米）！</p><p>用最终的变换矩阵左乘我们的向量会得到以下结果：</p><p><img src="https://img-blog.csdnimg.cn/20190104113004789.png" alt="组合运算"><br>不错！向量先缩放2倍，然后位移了(1, 2, 3)个单位。</p><h4 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h4><p>OpenGL没有自带任何的矩阵和向量知识，所以我们必须定义自己的数学类和函数。在教程中我们更希望抽象所有的数学细节，使用已经做好了的数学库。幸运的是，有个易于使用，专门为OpenGL量身定做的数学库，那就是GLM。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如何创建一个物体、着色、加入纹理，给它们一些细节的表现，但因为它们都还是静态的物体，仍是不够有趣。我们可以尝试着在每一帧改变物体的顶点并且重配置缓冲区从而使它们移动，但这太繁琐了，而且会消耗很多的处理时间。我们现在有一个更好的解决方案，使用（多个）矩阵(Matrix)对象可
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl GLSL</title>
    <link href="https://bytemode.github.io/2019/01/01/openglGLSL/"/>
    <id>https://bytemode.github.io/2019/01/01/openglGLSL/</id>
    <published>2019-01-01T13:53:34.000Z</published>
    <updated>2019-01-03T09:11:00.460Z</updated>
    
    <content type="html"><![CDATA[<h4 id="GLSL"><a href="#GLSL" class="headerlink" title="GLSL"></a>GLSL</h4><p>着色器是使用一种叫GLSL的类C语言写成的。GLSL是为图形计算量身定制的，它包含一些针对向量和矩阵操作的有用特性。</p><p>着色器的开头总是要声明版本，接着是输入和输出变量、uniform和main函数。每个着色器的入口点都是main函数，在这个函数中我们处理所有的输入变量，并将结果输出到输出变量中。</p><p>一个典型的着色器有下面的结构：</p><pre><code>#version version_numberin type in_variable_name;in type in_variable_name;out type out_variable_name;uniform type uniform_name;int main(){  // 处理输入并进行一些图形操作  ...  // 输出处理过的结果到输出变量  out_variable_name = weird_stuff_we_processed;}</code></pre><p>谈论到顶点着色器的时候，每个输入变量也叫顶点属性(Vertex Attribute)。我们能声明的顶点属性是有上限的，它一般由硬件来决定。OpenGL确保至少有16个包含4分量的顶点属性可用，但是有些硬件或许允许更多的顶点属性，你可以查询GL_MAX_VERTEX_ATTRIBS来获取具体的上限：</p><pre><code>int nrAttributes;glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &amp;nrAttributes);</code></pre><p>通常情况下它至少会返回16个，大部分情况下是够用了。</p><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p>和其他编程语言一样，GLSL有数据类型可以来指定变量的种类。GLSL中包含C等其它语言大部分的默认基础数据类型：int、float、double、uint和bool。GLSL也有两种容器类型，它们会在这个教程中使用很多，分别是向量(Vector)和矩阵(Matrix).</p><h5 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h5><p>GLSL中的向量是一个可以包含有1、2、3或者4个分量的容器，分量的类型可以是前面默认基础类型的任意一个。它们可以是下面的形式（n代表分量的数量）：</p><p>类型    含义<br>vecn    包含n个float分量的默认向量<br>bvecn    包含n个bool分量的向量<br>ivecn    包含n个int分量的向量<br>uvecn    包含n个unsigned int分量的向量<br>dvecn    包含n个double分量的向量<br>大多数时候我们使用vecn，因为float足够满足大多数要求了。</p><p>一个向量的分量可以通过vec.x这种方式获取，这里x是指这个向量的第一个分量。你可以分别使用.x、.y、.z和.w来获取它们的第1、2、3、4个分量。GLSL也允许你对颜色使用rgba，或是对纹理坐标使用stpq访问相同的分量。</p><p>向量这一数据类型也允许一些有趣而灵活的分量选择方式，叫做重组(Swizzling)。重组允许这样的语法：</p><pre><code>vec2 someVec;vec4 differentVec = someVec.xyxx;vec3 anotherVec = differentVec.zyw;vec4 otherVec = someVec.xxxx + anotherVec.yxzy;</code></pre><p>你可以使用上面4个字母任意组合来创建一个和原来向量一样长的（同类型）新向量，只要原来向量有那些分量即可；然而，你不允许在一个vec2向量中去获取.z元素。我们也可以把一个向量作为一个参数传给不同的向量构造函数，以减少需求参数的数量：</p><pre><code>vec2 vect = vec2(0.5, 0.7);vec4 result = vec4(vect, 0.0, 0.0);vec4 otherResult = vec4(result.xyz, 1.0);</code></pre><p>向量是一种灵活的数据类型，我们可以把用在各种输入和输出上。</p><h4 id="输入与输出"><a href="#输入与输出" class="headerlink" title="输入与输出"></a>输入与输出</h4><p>虽然着色器是各自独立的小程序，但是它们都是一个整体的一部分，出于这样的原因，我们希望每个着色器都有输入和输出，这样才能进行数据交流和传递。GLSL定义了in和out关键字专门来实现这个目的。每个着色器使用这两个关键字设定输入和输出，只要一个输出变量与下一个着色器阶段的输入匹配，它就会传递下去。但在顶点和片段着色器中会有点不同。</p><p>顶点着色器应该接收的是一种特殊形式的输入，否则就会效率低下。顶点着色器的输入特殊在，它从顶点数据中直接接收输入。为了定义顶点数据该如何管理，我们使用location这一元数据指定输入变量，这样我们才可以在CPU上配置顶点属性。我们已经在前面的教程看过这个了，layout (location = 0)。顶点着色器需要为它的输入提供一个额外的layout标识，这样我们才能把它链接到顶点数据。</p><p>你也可以忽略layout (location = 0)标识符，通过在OpenGL代码中使用glGetAttribLocation查询属性位置值(Location)，但是我更喜欢在着色器中设置它们，这样会更容易理解而且节省你（和OpenGL）的工作量。</p><p>另一个例外是片段着色器，它需要一个vec4颜色输出变量，因为片段着色器需要生成一个最终输出的颜色。如果你在片段着色器没有定义输出颜色，OpenGL会把你的物体渲染为黑色（或白色）。</p><p>所以，如果我们打算从一个着色器向另一个着色器发送数据，我们必须在发送方着色器中声明一个输出，在接收方着色器中声明一个类似的输入。当类型和名字都一样的时候，OpenGL就会把两个变量链接到一起，它们之间就能发送数据了（这是在链接程序对象时完成的）。为了展示这是如何工作的，我们会稍微改动一下之前教程里的那个着色器，让顶点着色器为片段着色器决定颜色。</p><p>顶点着色器</p><pre><code>#version 330 corelayout (location = 0) in vec3 aPos; // 位置变量的属性位置值为0out vec4 vertexColor; // 为片段着色器指定一个颜色输出void main(){    gl_Position = vec4(aPos, 1.0); // 注意我们如何把一个vec3作为vec4的构造器的参数    vertexColor = vec4(0.5, 0.0, 0.0, 1.0); // 把输出变量设置为暗红色}</code></pre><p>片段着色器</p><pre><code>#version 330 coreout vec4 FragColor;in vec4 vertexColor; // 从顶点着色器传来的输入变量（名称相同、类型相同）void main(){    FragColor = vertexColor;}</code></pre><p>你可以看到我们在顶点着色器中声明了一个vertexColor变量作为vec4输出，并在片段着色器中声明了一个类似的vertexColor。由于它们名字相同且类型相同，片段着色器中的vertexColor就和顶点着色器中的vertexColor链接了。由于我们在顶点着色器中将颜色设置为深红色，最终的片段也是深红色的。</p><h4 id="Uniform"><a href="#Uniform" class="headerlink" title="Uniform"></a>Uniform</h4><p>Uniform是一种从CPU中的应用向GPU中的着色器发送数据的方式，但uniform和顶点属性有些不同。</p><ul><li>uniform是全局的(Global)。全局意味着uniform变量必须在每个着色器程序对象中都是独一无二的，而且它可以被着色器程序的任意着色器在任意阶段访问。</li><li>无论你把uniform值设置成什么，uniform会一直保存它们的数据，直到它们被重置或更新。</li></ul><p>我们可以在一个着色器中添加uniform关键字至类型和变量名前来声明一个GLSL的uniform。从此处开始我们就可以在着色器中使用新声明的uniform了。我们来看看这次是否能通过uniform设置三角形的颜色：</p><pre><code>#version 330 coreout vec4 FragColor;uniform vec4 ourColor; // 在OpenGL程序代码中设定这个变量void main(){    FragColor = ourColor;}</code></pre><p>我们在片段着色器中声明了一个uniform vec4的ourColor，并把片段着色器的输出颜色设置为uniform值的内容。因为uniform是全局变量，我们可以在任何着色器中定义它们，而无需通过顶点着色器作为中介。顶点着色器中不需要这个uniform，所以我们不用在那里定义它。</p><p>如果你声明了一个uniform却在GLSL代码中没用过，编译器会静默移除这个变量，导致最后编译出的版本中并不会包含它，这可能导致几个非常麻烦的错误.</p><p>这个uniform现在还是空的；我们还没有给它添加任何数据，所以下面我们就做这件事。我们首先需要找到着色器中uniform属性的索引/位置值。当我们得到uniform的索引/位置值后，我们就可以更新它的值了</p><pre><code>int vertexColorLocation = glGetUniformLocation(shaderProgram, &quot;ourColor&quot;);glUseProgram(shaderProgram);glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f);</code></pre><p>接着，我们用glGetUniformLocation查询uniform ourColor的位置值。我们为查询函数提供着色器程序和uniform的名字（这是我们希望获得的位置值的来源）。如果glGetUniformLocation返回-1就代表没有找到这个位置值。最后，我们可以通过glUniform4f函数设置uniform值。注意，查询uniform地址不要求你之前使用过着色器程序，但是更新一个uniform之前你必须先使用程序（调用glUseProgram)，因为它是在当前激活的着色器程序中设置uniform的。</p><p>因为OpenGL在其核心是一个C库，所以它不支持类型重载，在函数参数不同的时候就要为其定义新的函数；glUniform是一个典型例子。这个函数有一个特定的后缀，标识设定的uniform的类型。可能的后缀有：</p><p>后缀    含义<br>f    函数需要一个float作为它的值<br>i    函数需要一个int作为它的值<br>ui    函数需要一个unsigned int作为它的值<br>3f    函数需要3个float作为它的值<br>fv    函数需要一个float向量/数组作为它的值<br>每当你打算配置一个OpenGL的选项时就可以简单地根据这些规则选择适合你的数据类型的重载函数。在我们的例子里，我们希望分别设定uniform的4个float值，所以我们通过glUniform4f传递我们的数据(注意，我们也可以使用fv版本)。</p><p>while(!glfwWindowShouldClose(window))<br>{<br>​    // 输入<br>​    processInput(window);</p><pre><code>// 渲染// 清除颜色缓冲glClearColor(0.2f, 0.3f, 0.3f, 1.0f);glClear(GL_COLOR_BUFFER_BIT);// 记得激活着色器glUseProgram(shaderProgram);// 更新uniform颜色float timeValue = glfwGetTime();float greenValue = sin(timeValue) / 2.0f + 0.5f;int vertexColorLocation = glGetUniformLocation(shaderProgram, &quot;ourColor&quot;);glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f);// 绘制三角形glBindVertexArray(VAO);glDrawArrays(GL_TRIANGLES, 0, 3);// 交换缓冲并查询IO事件glfwSwapBuffers(window);glfwPollEvents();</code></pre><p>}</p><p>可以看到，uniform对于设置一个在渲染迭代中会改变的属性是一个非常有用的工具，它也是一个在程序和着色器间数据交互的很好工具，但假如我们打算为每个顶点设置一个颜色的时候该怎么办？这种情况下，我们就不得不声明和顶点数目一样多的uniform了。在这一问题上更好的解决方案是在顶点属性中包含更多的数据，这是我们接下来要做的事情。</p><h3 id="更多属性"><a href="#更多属性" class="headerlink" title="更多属性"></a>更多属性</h3><p>了解了如何填充VBO、配置顶点属性指针以及如何把它们都储存到一个VAO里。这次，我们同样打算把颜色数据加进顶点数据中。我们将把颜色数据添加为3个float值至vertices数组。我们将把三角形的三个角分别指定为红色、绿色和蓝色：</p><pre><code>float vertices[] = {    // 位置                  // 颜色     0.5f, -0.5f, 0.0f,  1.0f, 0.0f, 0.0f,   // 右下    -0.5f, -0.5f, 0.0f,  0.0f, 1.0f, 0.0f,   // 左下     0.0f,  0.5f, 0.0f,  0.0f, 0.0f, 1.0f    // 顶部};</code></pre><p>由于现在有更多的数据要发送到顶点着色器，我们有必要去调整一下顶点着色器，使它能够接收颜色值作为一个顶点属性输入。需要注意的是我们用layout标识符来把aColor属性的位置值设置为1：</p><pre><code>#version 330 corelayout (location = 0) in vec3 aPos;   // 位置变量的属性位置值为 0 layout (location = 1) in vec3 aColor; // 颜色变量的属性位置值为 1out vec3 ourColor; // 向片段着色器输出一个颜色void main(){    gl_Position = vec4(aPos, 1.0);    ourColor = aColor; // 将ourColor设置为从顶点数据那里得到的输入颜色}</code></pre><p>由于我们不再使用uniform来传递片段的颜色了，现在使用ourColor输出变量，我们必须再修改一下片段着色器：</p><pre><code>#version 330 coreout vec4 FragColor;  in vec3 ourColor;void main(){    FragColor = vec4(ourColor, 1.0);}</code></pre><p>因为我们添加了另一个顶点属性，并且更新了VBO的内存，我们就必须重新配置顶点属性指针。更新后的VBO内存中的数据现在看起来像这样：</p><p><img src="https://img-blog.csdnimg.cn/20190103170814921.png" alt="vbo内存数据格式"></p><p>知道了现在使用的布局，我们就可以使用glVertexAttribPointer函数更新顶点格式，</p><pre><code>// 位置属性glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);// 颜色属性glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)(3* sizeof(float)));glEnableVertexAttribArray(1);</code></pre><p>glVertexAttribPointer函数的前几个参数比较明了。这次我们配置属性位置值为1的顶点属性。颜色值有3个float那么大，我们不去标准化这些值。</p><p>由于我们现在有了两个顶点属性，我们不得不重新计算步长值。为获得数据队列中下一个属性值（比如位置向量的下个x分量）我们必须向右移动6个float，其中3个是位置值，另外3个是颜色值。这使我们的步长值为6乘以float的字节数（=24字节）。<br>同样，这次我们必须指定一个偏移量。对于每个顶点来说，位置顶点属性在前，所以它的偏移量是0。颜色属性紧随位置数据之后，所以偏移量就是3 * sizeof(float)，用字节来计算就是12字节。</p><p>在片段着色器中进行的所谓片段插值(Fragment Interpolation)。当渲染一个三角形时，光栅化(Rasterization)阶段通常会造成比原指定顶点更多的片段。光栅会根据每个片段在三角形形状上所处相对位置决定这些片段的位置。<br>基于这些位置，它会插值(Interpolate)所有片段着色器的输入变量。比如说，我们有一个线段，上面的端点是绿色的，下面的端点是蓝色的。如果一个片段着色器在线段的70%的位置运行，它的颜色输入属性就会是一个绿色和蓝色的线性结合；更精确地说就是30%蓝 + 70%绿。</p><p>这正是在这个三角形中发生了什么。我们有3个顶点，和相应的3个颜色，从这个三角形的像素来看它可能包含50000左右的片段，片段着色器为这些像素进行插值颜色。如果你仔细看这些颜色就应该能明白了：红首先变成到紫再变为蓝色。片段插值会被应用到片段着色器的所有输入属性上。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;GLSL&quot;&gt;&lt;a href=&quot;#GLSL&quot; class=&quot;headerlink&quot; title=&quot;GLSL&quot;&gt;&lt;/a&gt;GLSL&lt;/h4&gt;&lt;p&gt;着色器是使用一种叫GLSL的类C语言写成的。GLSL是为图形计算量身定制的，它包含一些针对向量和矩阵操作的有用特性。&lt;/p&gt;
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>c++对象模型</title>
    <link href="https://bytemode.github.io/2018/12/31/c-%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B/"/>
    <id>https://bytemode.github.io/2018/12/31/c-对象模型/</id>
    <published>2018-12-31T08:47:44.000Z</published>
    <updated>2019-01-03T08:15:59.144Z</updated>
    
    <content type="html"><![CDATA[<h4 id="关于对象"><a href="#关于对象" class="headerlink" title="关于对象"></a>关于对象</h4><h5 id="加上封装后的布局成本"><a href="#加上封装后的布局成本" class="headerlink" title="加上封装后的布局成本"></a>加上封装后的布局成本</h5><p>c语言中如下声明一个结构体</p><pre><code>typedef struct point3d{ float x; float y; float z;}Point3d;</code></pre><p>struct point3d 转化为class Point3d之后</p><pre><code>class Point3d{    public:      Point3d(float x = 0.0f, float y = 0.0f; float z = 0.0f)        :_x(x),_y(y),_z(z){}    private:      float _x,_y,_y;}</code></pre><p>封装带来的布局成本增加了多少？实际是没有增加布局成本的。3个数据成员直接在class object内，member function在classs声明却不出现在class object中，所谓布局的成本主要由virtual引起的。</p><p>virtual function 机制用以支持运行时绑定（运行时多态）</p><p>virtual base class 机制支持多次出现在集成体系中的base class有一个单一的被共享的实例。</p><h5 id="基本c-对象模型"><a href="#基本c-对象模型" class="headerlink" title="基本c++对象模型"></a>基本c++对象模型</h5><p>nostatic data members 被配置在class object之内，static data member存放在class object之外.</p><p>static 和nostatic function memners放在class object之外</p><p>virtual function的处理步骤：</p><ol><li>每个class产生出一堆指向virtual functions的指针，放在表格中，这个表格称为虚表virtual table</li><li>每个class object 安插一个虚表指针vptr指向虚表（virtual table）.</li><li>vptr的设定和重置都由每个class的构造函数、拷贝赋值运算符、析构函数自动完成，每个class所关联的type_info object (用以支持runtime type identification, RTTI)也经由virtual table被指出，通常放在virtual table的第一个slot.</li></ol><p>声明一个class Point然后查看其对象模型</p><pre><code>class Point{    public:      Point(float x);      virtual ~Point();      float x() const;      static int PointCount();    protected:      virtual ostream&amp; print(ostream&amp; os) const;      float _x;      static int _point_count;}</code></pre><p><img src="https://img-blog.csdnimg.cn/20190102143720741.png" alt="Point对象模型"></p><h5 id="加上继承"><a href="#加上继承" class="headerlink" title="加上继承"></a>加上继承</h5><p>c++支持单一继承和多重继承.base class subobject的data members直接被放置在derived class object,也就是说子类对象中包含基类子对象.基类成员的改变都会导致继承类重新编译.对于虚基类则是扩展子类自己的vittual table维护virtual base class的位置。</p><pre><code>class istream : virtual public ios{...};class ostream : virtual public ios{...};class iostream : public istream, public ostream{...};</code></pre><p>在虚拟继承的情况下base class 不管在继承链中被派生多少次，永远只有一个实例存在即一个subobject.iostream之中只有virtual ios base class的一个实例.</p><h5 id="NRV优化"><a href="#NRV优化" class="headerlink" title="NRV优化"></a>NRV优化</h5><p>函数返回基本是数据类型或者指针类型是通过eax寄存器进行传递的，返回对象对象则会进行命名返回值优化.以外部引用传参的形式去掉函数内部的局部对象构造。</p><pre><code>X foo(){    X xx    X* px = new X();    xx.foo(); //func是一个虚函数    px-&gt;foo()    delete px;    rerurn xx}</code></pre><p>如上函数有可能内部转化为如下代码：</p><pre><code>void foo(X &amp;result){    _result.X::X();    px = _new(sizeof(X));    if(px != 0){ px-&gt;X::X(); }    func(&amp;_result);//这里涉及到成员函数的语义    (*px-&gt;vtbl[2])(px) //使用virtual机制扩展px-&gt;func()    if(px != 0) {        (*px-&gt;[1])(px); //扩展delete px        _delete(p)    }    return;   }</code></pre><p><img src="https://img-blog.csdnimg.cn/20190102143759346.png" alt="NRV优化和虚函数调用"></p><h5 id="指针类型"><a href="#指针类型" class="headerlink" title="指针类型"></a>指针类型</h5><ul><li>指针类型会指导编译器如何解释某个特定地址中内容及其大小</li><li>void*的指针只能够持有一个地址，而不能够通过他操作他所指向的object</li><li>cast是一种编译指令它不改变一个指针的内容，只影响被指出的大小和其内容的解释方式</li><li>c++通过引用或者指针的方式支持多态，是因为他们不会引发任何与类型有关的内存委托，</li><li>当一个基类对象直接被初始化为一个子类对象是，子类对象会被切割以放入base type的内存中</li></ul><h4 id="构造函数语义学"><a href="#构造函数语义学" class="headerlink" title="构造函数语义学"></a>构造函数语义学</h4><h5 id="默认构造函数被合成出来执行编译器的所需操作"><a href="#默认构造函数被合成出来执行编译器的所需操作" class="headerlink" title="默认构造函数被合成出来执行编译器的所需操作"></a>默认构造函数被合成出来执行编译器的所需操作</h5><p>如果类class A含有一个以上的类成员对象，编译器会扩张构造函数，在构造函数中安插代码，以成员类的声明顺序调用每个成员类的默认构造函数，这些代码被安插在用户代码之前.</p><p>有四种情况会造成编译器为未声明构造函数的类合成一个默认的构造函数，接着调用member object或者base class的默认构造函数，完成虚函数和虚基类机制。</p><ol><li>带有默认构造函数的成员类对象</li><li>带有默认构造函数的基类</li><li>带有virtual function的类，用来初始化vptr</li><li>带有virtual base class的类，用来初始化vptr</li></ol><h5 id="拷贝构造函数"><a href="#拷贝构造函数" class="headerlink" title="拷贝构造函数"></a>拷贝构造函数</h5><p>类中没有任何member或者base class object带有拷贝构造函数，也没有任何的虚函数和虚基类，默认情况下 对象的初始化会展示按位拷贝，这样效率很高且安全.</p><p>当对一个object做显示初始化或者object被当做参数交给函数时以及函数返回一个object时（传参、返回值、初始化）构造函数会被调用。</p><p>copy 构造函数不展现按位逐次拷贝的时候有编译器产生出来，有四种情况不展现：</p><ol><li>当成员类中生命有copy constructor</li><li>当基类中存在copy constructor</li><li>类中含有virtual function</li><li>类有virtual base class</li></ol><p>1、2中编译器讲member或者bass class的拷贝构造哈数的调用安插到合成的拷贝构造函数中；3，4是为了对vptr重新初始化.</p><h5 id="在构造函数中调用memset或者memcopy会使vptr设置为0"><a href="#在构造函数中调用memset或者memcopy会使vptr设置为0" class="headerlink" title="在构造函数中调用memset或者memcopy会使vptr设置为0"></a>在构造函数中调用memset或者memcopy会使vptr设置为0</h5><pre><code>class Shape{    public:        Shape(){ memset(this, 0, sizeof(Shape);)}        virtual ~Shape();}</code></pre><p>编译器扩充构造函数的内容如下：</p><pre><code>//扩充后的构造函数Shape::Shape(){    //vptr在用户代码之前被设定    __vptr__Shape = __vtbl__Shape;    //memset 会使vptr清0    memset(this, 0, sizeof(Shape));}</code></pre><h5 id="初始化成员列表"><a href="#初始化成员列表" class="headerlink" title="初始化成员列表"></a>初始化成员列表</h5><p>编译器会操作初始化列表，以成员的声明顺序子构造函数内部在用户代码之前安插初始化代码.<br>当类含有一下四种情况的时候会需要使用成员初始化列表：</p><ol><li>初始化一个引用成员</li><li>初始化一个constchengyuan </li><li>基类构造函数拥有参数</li><li>成员类构造函数拥有参数</li></ol><h4 id="Data语义学"><a href="#Data语义学" class="headerlink" title="Data语义学"></a>Data语义学</h4><h5 id="数据成员的布局"><a href="#数据成员的布局" class="headerlink" title="数据成员的布局"></a>数据成员的布局</h5><p><code>class X{};</code>一个空类它隐藏1byte的大小，他是被编译器安插进去的一个char,这使得这一class的两个object在内存中配置有独一无二的地址.</p><p>非静态的数据成员直接存放在每一个类对象中，对于继承而来的费静态成员也是如此。静态数据成员则放在程序的全局数据段，且只存在一份数据实例.</p><p>对成员函数的分析，会在整个class声明完成之后才会出现.</p><p>在同一个访问段中member的排列要符合较晚出现的成员在对象中有较高的地址，多个访问段中的数据成员是自由排列的.</p><h5 id="数据成员的访问"><a href="#数据成员的访问" class="headerlink" title="数据成员的访问"></a>数据成员的访问</h5><ol><li>静态数据成员只有一个实例放在程序的数据段，编译器会对每一个静态数据成员进行编码以获得一个独一无二的识别码</li><li>非静态数据成员，会使用隐式类对象机制访问数据（this指针）成员函数的参数中隐藏了一个隐式对象指针.</li><li>指向数据成员的指针，其offset值总是被加上1，这样可以使编译系统区分出“一个指向数据成员的指针，用以指出第一个成员”和“一个指向数据成员的指针，没有指出任何成员”.</li></ol><h5 id="单一继承无virtual-function下的内存布局"><a href="#单一继承无virtual-function下的内存布局" class="headerlink" title="单一继承无virtual function下的内存布局"></a>单一继承无virtual function下的内存布局</h5><p>单一继承下无布局情况下class和struct的布局是一样的.</p><p><img src="https://img-blog.csdnimg.cn/20190103114837430.png" alt="单一继承无virtual function下的数据布局"></p><h5 id="单一继承有virtaual-function下的内存布局"><a href="#单一继承有virtaual-function下的内存布局" class="headerlink" title="单一继承有virtaual function下的内存布局"></a>单一继承有virtaual function下的内存布局</h5><p><img src="https://img-blog.csdnimg.cn/20190103115054914.png" alt="单一继承有虚函数"></p><p>Point3d中含有基类的子对象Point2d subobject，子类数据成员放置在基类子对象之后。</p><h5 id="多重继承下的数据布局"><a href="#多重继承下的数据布局" class="headerlink" title="多重继承下的数据布局"></a>多重继承下的数据布局</h5><p>类体系如下</p><pre><code>class Point2d{    public:        virtual ~Point2d(){};    protected:        float _x,_y;};class Point3d : public Point2d{    public:     //...     protected:         float _z;};class Vertex{    public:        virtual ~Vertex(){};    protected:        Vertex *next;}class Vertex3d: public Point3d, public Vertex{    public:    //...    protected:        float mumble;}</code></pre><p><img src="https://img-blog.csdnimg.cn/20190103115456931.png" alt="多重继承体系下的数据布局"></p><p>要存取第二个基类中的数据成员，将会是怎样的情况需要付出额外的成本吗？不 ，成员的位置在编译期就时就固定了，因此存取数据成员知识一个简单的offset操作，就像单一继承一样简单–不管是经由一个指针或者引用或者是一个对象来存取.</p><h5 id="虚拟继承"><a href="#虚拟继承" class="headerlink" title="虚拟继承"></a>虚拟继承</h5><p>对于虚拟继承主要的问题是如何存取class的共享部分,虚拟继承使用两种策略来实现：指针策略和offset策略.</p><h6 id="指针策略"><a href="#指针策略" class="headerlink" title="指针策略"></a>指针策略</h6><p>为了指出共享类对象每个子类对象安插一些指针，每个指针指向虚基类。</p><p><img src="https://img-blog.csdnimg.cn/20190103130910339.png" alt="虚拟继承使用指针策略产生的布局"></p><p>进一步的优化策略的实现：每一个class object如果有一个或者多个virtual base classes，就会由编译器安插一个指针指向virtual base class table.真正的虚基类指针放在虚基类表中.</p><h6 id="offset策略"><a href="#offset策略" class="headerlink" title="offset策略"></a>offset策略</h6><p>在虚函数表中放置虚基类的offset.</p><p><img src="https://img-blog.csdnimg.cn/20190103132137522.png" alt="虚拟继承offset策略"></p><h4 id="Function语义学"><a href="#Function语义学" class="headerlink" title="Function语义学"></a>Function语义学</h4><h5 id="虚函数"><a href="#虚函数" class="headerlink" title="虚函数"></a>虚函数</h5><p>基类的指针或者引用寻址出一个子类对象，虚函数分配表格索引，vptr指向virtual table, virtual table中存放虚函数指针.</p><h5 id="inline函数"><a href="#inline函数" class="headerlink" title="inline函数"></a>inline函数</h5><p>inline是一个请求，编译器解说就必须认为它用一个表达式合理的将这个函数扩展开来，扩展期间使用实参代替形参，局部变量在封装的区域内名字唯一.</p><h5 id="函数的调用方式"><a href="#函数的调用方式" class="headerlink" title="函数的调用方式"></a>函数的调用方式</h5><ol><li>非静态成员函数</li></ol><ul><li>改函数签名安插this指针，变为一个非成员函数，可以使类对象调用.</li><li>调用对非静态成员的存取有this指针完成</li><li>通过name-maping 改为一个外部函数</li></ul><pre><code>float Point3d::getX()const{...}extern getX_Point3dFv(const Point3d* this)obj.getX()等价于 getX_Point3dFv(&amp;obj)ptr-&gt;getX()等价于getX_Point3dFv(ptr)</code></pre><ol start="2"><li>静态成员函数<br>被转为非成员函数，不能访问非静态成员没有this指针</li><li>虚成员函数<br>(*ptr-&gt;vptr[1])(ptr) 通过拿到徐表中虚函数地址传入this指针来调用</li></ol><h4 id="构造、拷贝、析构语义学"><a href="#构造、拷贝、析构语义学" class="headerlink" title="构造、拷贝、析构语义学"></a>构造、拷贝、析构语义学</h4><h5 id="构造函数的扩充"><a href="#构造函数的扩充" class="headerlink" title="构造函数的扩充"></a>构造函数的扩充</h5><p>顺序： 先父类后成员最后自己的调用方式.</p><p>vptr的初始化在所有base 类构造之后，初始化列表之前（程序代码）</p><ol><li>虚基类的构造函数被调用从左到右从深到浅</li><li>基类的构造函数被调用，按照基类的生命顺序</li><li>设置vptr的指针初值，初始化虚函数表</li><li>成员函数的初始化列表被放在构造偶函数内部以成员类的声明顺序,么有构造函数则调用合成的默认的构造函数</li><li>构造自己，执行user code</li></ol><h5 id="析构函数"><a href="#析构函数" class="headerlink" title="析构函数"></a>析构函数</h5><p>按照上面相反的顺序调用<br>先自己析构然后类成员对象析构然后重置vptr然后基类析构然后虚基类析构</p><h4 id="拷贝构造"><a href="#拷贝构造" class="headerlink" title="拷贝构造"></a>拷贝构造</h4><p>拷贝构造函数和拷贝复制运算符</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;关于对象&quot;&gt;&lt;a href=&quot;#关于对象&quot; class=&quot;headerlink&quot; title=&quot;关于对象&quot;&gt;&lt;/a&gt;关于对象&lt;/h4&gt;&lt;h5 id=&quot;加上封装后的布局成本&quot;&gt;&lt;a href=&quot;#加上封装后的布局成本&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="c++" scheme="https://bytemode.github.io/categories/c/"/>
    
    
      <category term="c++" scheme="https://bytemode.github.io/tags/c/"/>
    
  </entry>
  
  <entry>
    <title>opengl绘制三角形</title>
    <link href="https://bytemode.github.io/2018/12/28/opengl%E7%BB%98%E5%88%B6%E4%B8%89%E8%A7%92%E5%BD%A2/"/>
    <id>https://bytemode.github.io/2018/12/28/opengl绘制三角形/</id>
    <published>2018-12-28T07:15:06.000Z</published>
    <updated>2018-12-31T07:50:12.394Z</updated>
    
    <content type="html"><![CDATA[<blockquote><ul><li>顶点数组对象：Vertex Array Object，VAO</li><li>顶点缓冲对象：Vertex Buffer Object，VBO</li><li>索引缓冲对象：Element Buffer Object，EBO或Index Buffer Object，IBO</li></ul></blockquote><h4 id="渲染管线"><a href="#渲染管线" class="headerlink" title="渲染管线"></a>渲染管线</h4><p>在OpenGL中，任何事物都在3D空间中，而屏幕和窗口却是2D像素数组，这导致OpenGL的大部分工作都是关于把3D坐标转变为适应你屏幕的2D像素。3D坐标转为2D坐标的处理过程是由OpenGL的图形渲染管线管理的。图形渲染管线可以被划分为两个主要部分：第一部分把你的3D坐标转换为2D坐标，第二部分是把2D坐标转变为实际的有颜色的像素。</p><p>2D坐标和像素也是不同的，2D坐标精确表示一个点在2D空间中的位置，而2D像素是这个点的近似值，2D像素受到你的屏幕/窗口分辨率的限制。</p><p>图形渲染管线接受一组3D坐标，然后把它们转变为你屏幕上的有色2D像素输出。图形渲染管线可以被划分为几个阶段，每个阶段将会把前一个阶段的输出作为输入。所有这些阶段都是高度专门化的（它们都有一个特定的函数），并且并行执行。GPU上为每一个（渲染管线）阶段运行各自的小程序，从而在图形渲染管线中快速处理你的数据。这些小程序叫做着色器(Shader)。</p><p>OpenGL着色器是用OpenGL着色器语言(OpenGL Shading Language, GLSL)写成的。</p><p>下面，你会看到一个图形渲染管线的每个阶段的抽象展示。蓝色部分代表的是可以注入自定义的着色器的部分。</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_pipeline.png" alt="img"></p><p>图形渲染管线包含很多部分，每个部分都将在转换顶点数据到最终像素这一过程中处理各自特定的阶段。概括性地解释一下渲染管线的每个部分。</p><h5 id="顶点数据"><a href="#顶点数据" class="headerlink" title="顶点数据"></a>顶点数据</h5><p>首先，我们以数组的形式传递3个3D坐标作为图形渲染管线的输入，用来表示一个三角形，这个数组叫做顶点数据(Vertex Data)；顶点数据是一系列顶点的集合。一个顶点(Vertex)是一个3D坐标的数据的集合。而顶点数据是用顶点属性(Vertex Attribute)表示的，它可以包含任何我们想用的数据，但是简单起见，我们还是假定每个顶点只由一个3D位置和一些颜色值组成的吧。</p><p>为了让OpenGL知道我们的坐标和颜色值构成的到底是什么，OpenGL需要你去指定这些数据所表示的渲染类型。我们是希望把这些数据渲染成一系列的点？一系列的三角形？还是仅仅是一个长长的线？做出的这些提示叫做图元(Primitive)，任何一个绘制指令的调用都将把图元传递给OpenGL。这是其中的几个：GL_POINTS、GL_TRIANGLES、GL_LINE_STRIP。</p><h5 id="顶点着色器"><a href="#顶点着色器" class="headerlink" title="顶点着色器"></a>顶点着色器</h5><p>图形渲染管线的第一个部分是顶点着色器(Vertex Shader)，它把一个单独的顶点作为输入。顶点着色器主要的目的是把3D坐标转为另一种3D坐标，同时顶点着色器允许我们对顶点属性进行一些基本处理。</p><h5 id="图元组装"><a href="#图元组装" class="headerlink" title="图元组装"></a>图元组装</h5><p>图元装配(Primitive Assembly)阶段将顶点着色器输出的所有顶点作为输入（如果是GL_POINTS，那么就是一个顶点），并所有的点装配成指定图元的形状。</p><h5 id="几何着色器"><a href="#几何着色器" class="headerlink" title="几何着色器"></a>几何着色器</h5><p>图元装配阶段的输出会传递给几何着色器(Geometry Shader)。几何着色器把图元形式的一系列顶点的集合作为输入，它可以通过产生新顶点构造出新的（或是其它的）图元来生成其他形状。例子中，它生成了另一个三角形。</p><h5 id="光栅化"><a href="#光栅化" class="headerlink" title="光栅化"></a>光栅化</h5><p>几何着色器的输出会被传入光栅化阶段(Rasterization Stage)，这里它会把图元映射为最终屏幕上相应的像素，生成供片段着色器(Fragment Shader)使用的片段(Fragment)。在片段着色器运行之前会执行裁切(Clipping)。裁切会丢弃超出你的视图以外的所有像素，用来提升执行效率。</p><h5 id="片段着色器"><a href="#片段着色器" class="headerlink" title="片段着色器"></a>片段着色器</h5><p>OpenGL中的一个片段是OpenGL渲染一个像素所需的所有数据。片段着色器的主要目的是计算一个像素的最终颜色，这也是所有OpenGL高级效果产生的地方。通常，片段着色器包含3D场景的数据（比如光照、阴影、光的颜色等等），这些数据可以被用来计算最终像素的颜色。</p><h5 id="测试混合"><a href="#测试混合" class="headerlink" title="测试混合"></a>测试混合</h5><p>在所有对应颜色值确定以后，最终的对象将会被传到最后一个阶段，我们叫做Alpha测试和混合(Blending)阶段。这个阶段检测片段的对应的深度（和模板(Stencil)）值（后面会讲），用它们来判断这个像素是其它物体的前面还是后面，决定是否应该丢弃。这个阶段也会检查alpha值（alpha值定义了一个物体的透明度）并对物体进行混合(Blend)。所以，即使在片段着色器中计算出来了一个像素输出的颜色，在渲染多个三角形的时候最后的像素颜色也可能完全不同。</p><h4 id="顶点输入"><a href="#顶点输入" class="headerlink" title="顶点输入"></a>顶点输入</h4><p>开始绘制图形之前，我们必须先给OpenGL输入一些顶点数据。OpenGL是一个3D图形库，所以我们在OpenGL中指定的所有坐标都是3D坐标（x、y和z）。OpenGL不是简单地把<strong>所有的</strong>3D坐标变换为屏幕上的2D像素；OpenGL仅当3D坐标在3个轴（x、y和z）上都为-1.0到1.0的范围内时才处理它。所有在所谓的<strong>标准化设备坐标</strong>(Normalized Device Coordinates)范围内的坐标才会最终呈现在屏幕上（在这个范围以外的坐标都不会显示）。</p><p>由于我们希望渲染一个三角形，我们一共要指定三个顶点，每个顶点都有一个3D位置。我们会将它们以标准化设备坐标的形式（OpenGL的可见区域）定义为一个<code>float</code>数组。</p><pre><code>float vertices[] = {    -0.5f, -0.5f, 0.0f,     0.5f, -0.5f, 0.0f,     0.0f,  0.5f, 0.0f};</code></pre><p>由于OpenGL是在3D空间中工作的，而我们渲染的是一个2D三角形，我们将它顶点的z坐标设置为0.0。</p><p><strong>标准化设备坐标(Normalized Device Coordinates, NDC)</strong></p><p>一旦你的顶点坐标已经在顶点着色器中处理过，它们就应该是<strong>标准化设备坐标</strong>了，标准化设备坐标是一个x、y和z值在-1.0到1.0的一小段空间。任何落在范围外的坐标都会被丢弃/裁剪，不会显示在你的屏幕上。下面你会看到我们定义的在标准化设备坐标中的三角形(忽略z轴)：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_ndc.png" alt="NDC"></p><p>与通常的屏幕坐标不同，y轴正方向为向上，(0, 0)坐标是这个图像的中心，而不是左上角。最终你希望所有(变换过的)坐标都在这个坐标空间中，否则它们就不可见了。</p><p>你的标准化设备坐标接着会变换为屏幕空间坐标(Screen-space Coordinates)，这是使用你通过glViewport函数提供的数据，进行视口变换(Viewport Transform)完成的。所得的屏幕空间坐标又会被变换为片段输入到片段着色器中。</p><p>定义这样的顶点数据以后，我们会把它作为输入发送给图形渲染管线的第一个处理阶段：顶点着色器。它会在GPU上创建内存用于储存我们的顶点数据，还要配置OpenGL如何解释这些内存，并且指定其如何发送给显卡。顶点着色器接着会处理我们在内存中指定数量的顶点。</p><p><strong>通过顶点缓冲对象(Vertex Buffer Objects, VBO)管理这个内存，它会在GPU内存（通常被称为显存）中储存大量顶点</strong>。使用这些缓冲对象的好处是我们可以一次性的发送一大批数据到显卡上，而不是每个顶点发送一次。从CPU把数据发送到显卡相对较慢，所以只要可能我们都要尝试尽量一次性发送尽可能多的数据。当数据发送至显卡的内存中后，顶点着色器几乎能立即访问顶点，这是个非常快的过程。</p><p>顶点缓冲对象是OpenGL对象。就像OpenGL中的其它对象一样，这个缓冲有一个独一无二的ID，所以我们可以使用glGenBuffers函数和一个缓冲ID生成一个VBO对象：</p><pre><code>unsigned int VBO;glGenBuffers(1, &amp;VBO);</code></pre><p>OpenGL有很多缓冲对象类型，顶点缓冲对象的缓冲类型是GL_ARRAY_BUFFER。OpenGL允许我们同时绑定多个缓冲，只要它们是不同的缓冲类型。我们可以使用glBindBuffer函数把新创建的缓冲(VBO)绑定到GL_ARRAY_BUFFER目标上：</p><pre><code>glBindBuffer(GL_ARRAY_BUFFER, VBO);  </code></pre><p>从这一刻起，我们使用的任何（在GL_ARRAY_BUFFER目标上的）缓冲调用都会用来配置当前绑定的缓冲(VBO)。然后我们可以调用glBufferData函数，它会把之前定义的顶点数据复制到缓冲的内存中：</p><pre><code>glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);</code></pre><p>glBufferData是一个专门用来把用户定义的数据复制到当前绑定缓冲的函数。它的第一个参数是目标缓冲的类型：顶点缓冲对象当前绑定到GL_ARRAY_BUFFER目标上。第二个参数指定传输数据的大小(以字节为单位)；用一个简单的<code>sizeof</code>计算出顶点数据大小就行。第三个参数是我们希望发送的实际数据。</p><p>第四个参数指定了我们希望显卡如何管理给定的数据。它有三种形式：</p><ul><li>GL_STATIC_DRAW ：数据不会或几乎不会改变。</li><li>GL_DYNAMIC_DRAW：数据会被改变很多。</li><li>GL_STREAM_DRAW ：数据每次绘制时都会改变。</li></ul><p>三角形的位置数据不会改变，每次渲染调用时都保持原样，所以它的使用类型最好是GL_STATIC_DRAW。如果，比如说一个缓冲中的数据将频繁被改变，那么使用的类型就是GL_DYNAMIC_DRAW或GL_STREAM_DRAW，这样就能确保显卡把数据放在能够高速写入的内存部分。</p><p>现在我们已经把顶点数据储存在显卡的内存中，用VBO这个顶点缓冲对象管理。下面我们会创建一个顶点和片段着色器来真正处理这些数据。</p><h4 id="顶点着色器-1"><a href="#顶点着色器-1" class="headerlink" title="顶点着色器"></a>顶点着色器</h4><p>顶点着色器(Vertex Shader)是几个可编程着色器中的一个。我们使用着色器以及配置两个非常简单的着色器来绘制我们第一个三角形。</p><p>我们需要做的第一件事是用着色器语言GLSL(OpenGL Shading Language)编写顶点着色器，然后编译这个着色器，这样我们就可以在程序中使用它了。下面你会看到一个非常基础的GLSL顶点着色器的源代码：</p><pre><code>#version 330 corelayout (location = 0) in vec3 aPos;void main(){    gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);}</code></pre><p>可以看到，GLSL看起来很像C语言。每个着色器都起始于一个版本声明。</p><p>下一步，使用<code>in</code>关键字，在顶点着色器中声明所有的输入顶点属性(Input Vertex Attribute)。现在我们只关心位置(Position)数据，所以我们只需要一个顶点属性。GLSL有一个向量数据类型，它包含1到4个<code>float</code>分量，包含的数量可以从它的后缀数字看出来。由于每个顶点都有一个3D坐标，我们就创建一个<code>vec3</code>输入变量aPos。我们同样也通过<code>layout (location = 0)</code>设定了输入变量的位置值(Location)你后面会看到为什么我们会需要这个位置值。</p><p>为了设置顶点着色器的输出，我们必须把位置数据赋值给预定义的gl_Position变量，它在幕后是<code>vec4</code>类型的。在main函数的最后，我们将gl_Position设置的值会成为该顶点着色器的输出。由于我们的输入是一个3分量的向量，我们必须把它转换为4分量的。我们可以把<code>vec3</code>的数据作为<code>vec4</code>构造器的参数，同时把<code>w</code>分量设置为<code>1.0f</code>（我们会在后面解释为什么）来完成这一任务。</p><p>当前这个顶点着色器可能是我们能想到的最简单的顶点着色器了，因为我们对输入数据什么都没有处理就把它传到着色器的输出了。在真实的程序里输入数据通常都不是标准化设备坐标，所以我们首先必须先把它们转换至OpenGL的可视区域内。</p><h5 id="编译着色器"><a href="#编译着色器" class="headerlink" title="编译着色器"></a>编译着色器</h5><p>我们已经写了一个顶点着色器源码（储存在一个C的字符串中），但是为了能够让OpenGL使用它，我们必须在运行时动态编译它的源码。</p><p>我们首先要做的是创建一个着色器对象，注意还是用ID来引用的。所以我们储存这个顶点着色器为<code>unsigned int</code>，然后用glCreateShader创建这个着色器：</p><pre><code>unsigned int vertexShader;vertexShader = glCreateShader(GL_VERTEX_SHADER);</code></pre><p>我们把需要创建的着色器类型以参数形式提供给glCreateShader。由于我们正在创建一个顶点着色器，传递的参数是GL_VERTEX_SHADER。</p><p>下一步我们把这个着色器源码附加到着色器对象上，然后编译它：</p><pre><code>glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL);glCompileShader(vertexShader);</code></pre><p>glShaderSource函数把要编译的着色器对象作为第一个参数。第二参数指定了传递的源码字符串数量，这里只有一个。第三个参数是顶点着色器真正的源码，第四个参数我们先设置为<code>NULL</code>。</p><p>你可能会希望检测在调用glCompileShader后编译是否成功了，如果没成功的话，你还会希望知道错误是什么，这样你才能修复它们。检测编译时错误可以通过以下代码来实现：</p><pre><code>int  success;char infoLog[512];glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &amp;success);</code></pre><p>首先我们定义一个整型变量来表示是否成功编译，还定义了一个储存错误消息（如果有的话）的容器。然后我们用glGetShaderiv检查是否编译成功。如果编译失败，我们会用glGetShaderInfoLog获取错误消息，然后打印它。</p><pre><code>if(!success){    glGetShaderInfoLog(vertexShader, 512, NULL, infoLog);    std::cout &lt;&lt; &quot;ERROR::SHADER::VERTEX::COMPILATION_FAILED\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl;}</code></pre><p>如果编译的时候没有检测到任何错误，顶点着色器就被编译成功了。</p><h4 id="片段着色器-1"><a href="#片段着色器-1" class="headerlink" title="片段着色器"></a>片段着色器</h4><p>片段着色器所做的是计算像素最后的颜色输出。</p><p>在计算机图形中颜色被表示为有4个元素的数组：红色、绿色、蓝色和alpha(透明度)分量，通常缩写为RGBA。当在OpenGL或GLSL中定义一个颜色的时候，我们把颜色每个分量的强度设置在0.0到1.0之间。比如说我们设置红为1.0f，绿为1.0f，我们会得到两个颜色的混合色，即黄色。这三种颜色分量的不同调配可以生成超过1600万种不同的颜色！</p><pre><code>#version 330 coreout vec4 FragColor;void main(){    FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);} </code></pre><p>片段着色器只需要一个输出变量，这个变量是一个4分量向量，它表示的是最终的输出颜色，我们应该自己将其计算出来。我们可以用<code>out</code>关键字声明输出变量，这里我们命名为FragColor。下面，我们将一个alpha值为1.0(1.0代表完全不透明)的橘黄色的<code>vec4</code>赋值给颜色输出。</p><p>编译片段着色器的过程与顶点着色器类似，只不过我们使用GL_FRAGMENT_SHADER常量作为着色器类型：</p><pre><code>unsigned int fragmentShader;fragmentShader = glCreateShader(GL_FRAGMENT_SHADER);glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL);glCompileShader(fragmentShader);</code></pre><p>两个着色器现在都编译了，剩下的事情是把两个着色器对象链接到一个用来渲染的着色器程序(Shader Program)中。</p><h4 id="着色器程序"><a href="#着色器程序" class="headerlink" title="着色器程序"></a>着色器程序</h4><p>着色器程序对象(Shader Program Object)是多个着色器合并之后并最终链接完成的版本。如果要使用刚才编译的着色器我们必须把它们链接(Link)为一个着色器程序对象，然后在渲染对象的时候激活这个着色器程序。已激活着色器程序的着色器将在我们发送渲染调用的时候被使用。</p><p>当链接着色器至一个程序的时候，它会把每个着色器的输出链接到下个着色器的输入。当输出和输入不匹配的时候，你会得到一个连接错误。</p><p>创建一个程序对象很简单：</p><pre><code>unsigned int shaderProgram;shaderProgram = glCreateProgram();</code></pre><p>glCreateProgram函数创建一个程序，并返回新创建程序对象的ID引用。现在我们需要把之前编译的着色器附加到程序对象上，然后用glLinkProgram链接它们：</p><pre><code>glAttachShader(shaderProgram, vertexShader);glAttachShader(shaderProgram, fragmentShader);glLinkProgram(shaderProgram);</code></pre><p>代码应该很清楚，我们把着色器附加到了程序上，然后用glLinkProgram链接。</p><p>就像着色器的编译一样，我们也可以检测链接着色器程序是否失败，并获取相应的日志。与上面不同，我们不会调用glGetShaderiv和glGetShaderInfoLog，现在我们使用：</p><pre><code>glGetProgramiv(shaderProgram, GL_LINK_STATUS, &amp;success);if(!success) {    glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog);    ...}</code></pre><p>得到的结果就是一个程序对象，我们可以调用glUseProgram函数，用刚创建的程序对象作为它的参数，以激活这个程序对象：</p><pre><code>glUseProgram(shaderProgram);</code></pre><p>在glUseProgram函数调用之后，每个着色器调用和渲染调用都会使用这个程序对象（也就是之前写的着色器)了。</p><p>对了，在把着色器对象链接到程序对象以后，记得删除着色器对象，我们不再需要它们了：</p><pre><code>glDeleteShader(vertexShader);glDeleteShader(fragmentShader);</code></pre><p>现在，我们已经把输入顶点数据发送给了GPU，并指示了GPU如何在顶点和片段着色器中处理它。OpenGL还不知道它该如何解释内存中的顶点数据，以及它该如何将顶点数据链接到顶点着色器的属性上。</p><h4 id="链接顶点属性"><a href="#链接顶点属性" class="headerlink" title="链接顶点属性"></a>链接顶点属性</h4><p>顶点着色器允许我们指定任何以顶点属性为形式的输入。我们必须手动指定输入数据的哪一个部分对应顶点着色器的哪一个顶点属性。所以，我们必须在渲染前指定OpenGL该如何解释顶点数据。</p><p>我们的顶点缓冲数据会被解析为下面这样子：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_vertex_attribute_pointer.png" alt="img"></p><ul><li>位置数据被储存为32位浮点值。</li><li>每个位置包含3个这样的值。</li><li>在这3个值之间没有空隙。这几个值在数组中紧密排列(Tightly Packed)。</li><li>数据中第一个值在缓冲开始的位置。</li></ul><p>有了这些信息我们就可以<strong>使用glVertexAttribPointer函数告诉OpenGL该如何解析顶点数据</strong>（应用到逐个顶点属性上）了：</p><pre><code>//解析顶点数据即解析顶点数据给着色器中的顶点属性glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);//启用顶点属性glEnableVertexAttribArray(0);</code></pre><p>glVertexAttribPointer函数的参数非常多，所以我会逐一介绍它们：</p><ul><li>第一个参数指定我们<strong>要配置的顶点属性</strong>。还记得我们在顶点着色器中使用<code>layout(location = 0)</code>定义了position顶点属性的位置值(Location)吗？它可以把顶点属性的位置值设置为<code>0</code>。因为我们希望把数据传递到这一个顶点属性中，所以这里我们传入<code>0</code>。在着色器中的位置索引。</li><li>第二个参数指定顶点属性的大小。顶点属性是一个<code>vec3</code>，它由3个值组成，所以大小是3。</li><li>第三个参数指定数据的类型，这里是GL_FLOAT(GLSL中<code>vec*</code>都是由浮点数值组成的)。</li><li>第四个参数是否希望数据被标准化(Normalize)。如果我们设置为GL_TRUE，所有数据都会被映射到0（对于有符号型signed数据是-1）到1之间。</li><li>第五个参数叫做步长(Stride)，它告诉我们在连续的顶点属性组之间的间隔。由于下个组位置数据在3个<code>float</code>之后，我们把步长设置为<code>3 * sizeof(float)</code>。</li><li>最后一个参数的类型是<code>void*</code>，需进行这个奇怪的强制类型转换。它表示位置数据在缓冲（vbo）中起始位置的偏移量(Offset)。由于位置数据在数组的开头，所以这里是0。</li></ul><p>每个顶点属性从一个VBO管理的内存中获得它的数据，而具体是<strong>从哪个VBO获取则是通过在调用glVetexAttribPointer时绑定到GL_ARRAY_BUFFER的VBO决定的</strong>。由于在调用glVetexAttribPointer之前绑定的是先前定义的VBO对象，顶点属性<code>0</code>现在会链接到它的顶点数据。</p><p>现在我们已经定义了OpenGL该如何解释顶点数据，我们现在应该<strong>使用glEnableVertexAttribArray，以顶点属性位置值作为参数，启用顶点属性</strong>；顶点属性默认是禁用的。我们使用一个顶点缓冲对象将顶点数据初始化至缓冲中，建立了一个顶点和一个片段着色器，并告诉了OpenGL如何把顶点数据链接到顶点着色器的顶点属性上。在OpenGL中绘制一个物体，代码会像是这样：</p><pre><code>//创建顶点缓冲区对象（vbo）unsigned int VBO;glGenBuffers(1, &amp;VBO);//绑定vbo到GL_ARRAY_BUFFER目标(GL_ARRAY_BUFFER是顶点缓冲区的类型)glBindBuffer(GL_ARRAY_BUFFER, VBO);//复制顶点数组到缓冲中供OpenGL使用glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);//设置顶点属性指针,告诉opengl如何解析顶点数据到顶点属性glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);//启用顶点属性glEnableVertexAttribArray(0);//当我们渲染一个物体时要使用着色器程序glUseProgram(shaderProgram);//绘制物体someOpenGLFunctionThatDrawsOurTriangle();</code></pre><p>当多存多个物体，每个物体有多个顶点的时候，绑定正确的缓冲对象，为每个物体配置所有顶点属性很快就变成一件麻烦事。有没有一些方法可以使我们把所有这些状态配置储存在一个对象中，并且可以通过绑定这个对象来恢复状态呢？</p><h4 id="顶点数组对象"><a href="#顶点数组对象" class="headerlink" title="顶点数组对象"></a>顶点数组对象</h4><p>顶点数组对象(Vertex Array Object, VAO)可以像顶点缓冲对象那样被绑定，任何随后的顶点属性调用都会储存在这个VAO中。这样的好处就是，当配置顶点属性指针时，你只需要将那些调用执行一次，之后再绘制物体的时候只需要绑定相应的VAO就行了。这使在不同顶点数据和属性配置之间切换变得非常简单，只需要绑定不同的VAO就行了。刚刚设置的所有状态都将存储在VAO中</p><p>一个顶点数组对象会储存以下这些内容：</p><ul><li>glEnableVertexAttribArray和glDisableVertexAttribArray的调用。</li><li>通过glVertexAttribPointer设置的顶点属性配置。</li><li>通过glVertexAttribPointer调用与顶点属性关联的顶点缓冲对象。</li></ul><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_vertex_array_objects.png" alt="img"></p><p>创建一个VAO和创建一个VBO很类似：</p><pre><code>unsigned int VAO;glGenVertexArrays(1, &amp;VAO);</code></pre><p>要想使用VAO，要做的只是使用glBindVertexArray绑定VAO。从绑定之后起，我们应该绑定和配置对应的VBO和属性指针，之后解绑VAO供之后使用。当我们打算绘制一个物体的时候，我们只要在绘制物体前简单地把VAO绑定到希望使用的设定上就行了。这段代码应该看起来像这样：</p><pre><code>//初始化代码（只运行一次 (除非你的物体频繁改变)） :: ..//绑定VAOglBindVertexArray(VAO);//把顶点数组复制到缓冲中供OpenGL使用glBindBuffer(GL_ARRAY_BUFFER, VAO);glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);//设置顶点属性指针glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);[...]// ..:: 绘制代码（渲染循环中） :: ..// 4. 绘制物体glUseProgram(shaderProgram);glBindVertexArray(VAO); 设置的顶点属性配置someOpenGLFunctionThatDrawsOurTriangle();</code></pre><p>一个储存了顶点属性配置和应使用的VBO的顶点数组对象。一般当你打算绘制多个物体时，你首先要生成/配置所有的VAO（和必须的VBO及属性指针)，然后储存它们供后面使用。当我们打算绘制物体的时候就拿出相应的VAO，绑定它，绘制完物体后，再解绑VAO。</p><h4 id="绘制三角形"><a href="#绘制三角形" class="headerlink" title="绘制三角形"></a>绘制三角形</h4><p>要想绘制我们想要的物体，OpenGL给我们提供了glDrawArrays函数，它使用当前激活的着色器，之前定义的顶点属性配置，和VBO的顶点数据（通过VAO间接绑定）来绘制图元。</p><pre><code>glUseProgram(shaderProgram); //使用着色器glBindVertexArray(VAO);      //设置的顶点属性配置glDrawArrays(GL_TRIANGLES, 0, 3);</code></pre><p>glDrawArrays函数第一个参数是我们打算绘制的OpenGL图元的类型。由于我们在一开始时说过，我们希望绘制的是一个三角形，这里传递GL_TRIANGLES给它。第二个参数指定了顶点数组的起始索引，我们这里填<code>0</code>。最后一个参数指定我们打算绘制多少个顶点，这里是<code>3</code></p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_hellotriangle.png" alt="img"></p><h4 id="索引缓冲对象"><a href="#索引缓冲对象" class="headerlink" title="索引缓冲对象"></a>索引缓冲对象</h4><p>索引缓冲对象(Element Buffer Object，EBO，也叫Index Buffer Object，IBO)。要解释索引缓冲对象的工作方式最好还是举个例子：假设我们不再绘制一个三角形而是绘制一个矩形。我们可以绘制两个三角形来组成一个矩形（OpenGL主要处理三角形）。这会生成下面的顶点的集合：</p><pre><code>float vertices[] = {    // 第一个三角形    0.5f, 0.5f, 0.0f,   // 右上角    0.5f, -0.5f, 0.0f,  // 右下角    -0.5f, 0.5f, 0.0f,  // 左上角    // 第二个三角形    0.5f, -0.5f, 0.0f,  // 右下角    -0.5f, -0.5f, 0.0f, // 左下角    -0.5f, 0.5f, 0.0f   // 左上角};</code></pre><p>可以看到，有几个顶点叠加了。我们指定了<code>右下角</code>和<code>左上角</code>两次！一个矩形只有4个而不是6个顶点，这样就产生50%的额外开销。当我们有包括上千个三角形的模型之后这个问题会更糟糕，这会产生一大堆浪费。更好的解决方案是只储存不同的顶点，并设定绘制这些顶点的顺序。这样子我们只要储存4个顶点就能绘制矩形了，之后只要指定绘制的顺序就行了。</p><p>索引缓冲对象的工作方式正是这样的。<strong>和顶点缓冲对象一样，EBO也是一个缓冲，它专门储存索引，OpenGL调用这些顶点的索引来决定该绘制哪个顶点</strong>。所谓的索引绘制(Indexed Drawing)正是我们问题的解决方案。</p><ol><li>首先，我们先要定义（不重复的）顶点，和绘制出矩形所需的索引：</li></ol><pre><code>float vertices[] = {    0.5f, 0.5f, 0.0f,   // 右上角    0.5f, -0.5f, 0.0f,  // 右下角    -0.5f, -0.5f, 0.0f, // 左下角    -0.5f, 0.5f, 0.0f   // 左上角};unsigned int indices[] = { // 注意索引从0开始!     0, 1, 3, // 第一个三角形    1, 2, 3  // 第二个三角形};</code></pre><p>你可以看到，当时用索引的时候，我们只定义了4个顶点，而不是6个。</p><ol start="2"><li>下一步我们需要创建索引缓冲对象：</li></ol><pre><code>unsigned int EBO;glGenBuffers(1, &amp;EBO);</code></pre><p>与VBO类似，<strong>我们先绑定EBO然后用glBufferData把索引复制到缓冲里</strong>。同样，和VBO类似，我们会把这些函数调用放在绑定和解绑函数调用之间，只不过这次我们把缓冲的类型定义为GL_ELEMENT_ARRAY_BUFFER。</p><pre><code>glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW);</code></pre><p>要注意的是，我们传递了<strong>GL_ELEMENT_ARRAY_BUFFER</strong>当作缓冲目标。</p><ol start="3"><li><p>最后一件要做的事是用glDrawElements来替换glDrawArrays函数，来指明我们从索引缓冲渲染。</p><p>使用glDrawElements时，我们会使用当前绑定的索引缓冲对象中的索引进行绘制：</p></li></ol><pre><code>glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);</code></pre><p>第一个参数指定了我们绘制的模式，这个和glDrawArrays的一样。第二个参数是我们打算绘制顶点的个数，这里填6，也就是说我们一共需要绘制6个顶点。第三个参数是索引的类型，这里是GL_UNSIGNED_INT。最后一个参数里我们可以指定EBO中的偏移量（或者传递一个索引数组，但是这是当你不在使用索引缓冲对象的时候），但是我们会在这里填写0。</p><p><strong>glDrawElements函数从当前绑定到GL_ELEMENT_ARRAY_BUFFER目标的EBO中获取索引</strong>。这意味着我们必须在每次要用索引渲染一个物体时绑定相应的EBO，这还是有点麻烦。不过顶点数组对象同样可以保存索引缓冲对象的绑定状态。<strong>VAO绑定时正在绑定的索引缓冲对象会被保存为VAO的元素缓冲对象。**</strong>绑定VAO的同时也会自动绑定EBO。**</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_vertex_array_objects_ebo.png" alt="img"></p><p>当目标是GL_ELEMENT_ARRAY_BUFFER的时候，VAO会储存glBindBuffer的函数调用。这也意味着它也会储存解绑调用，所以确保你没有在解绑VAO之前解绑索引数组缓冲，否则它就没有这个EBO配置了。</p><p>最后的初始化和绘制代码现在看起来像这样：</p><pre><code>// ..:: 初始化代码 :: ..// 1. 绑定顶点数组对象glBindVertexArray(VAO);// 2. 把我们的顶点数组复制到一个顶点缓冲中，供OpenGL使用glBindBuffer(GL_ARRAY_BUFFER, VBO);glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);// 3. 复制我们的索引数组到一个索引缓冲中，供OpenGL使用glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW);// 4. 设定顶点属性指针glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);[...]// ..:: 绘制代码（渲染循环中） :: ..glUseProgram(shaderProgram);glBindVertexArray(VAO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0)glBindVertexArray(0);</code></pre><p>运行程序会获得下面这样的图片的结果。左侧图片看应该起来很熟悉，而右侧的则是使用线框模式(Wireframe Mode)绘制的。线框矩形可以显示出矩形的确是由两个三角形组成的。</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_hellotriangle2.png" alt="img"></p><h4 id="绘制三角形的代码"><a href="#绘制三角形的代码" class="headerlink" title="绘制三角形的代码"></a>绘制三角形的代码</h4><pre><code>#include &lt;glad/glad.h&gt;#include &lt;GLFW/glfw3.h&gt;#include &lt;iostream&gt;void framebuffer_size_callback(GLFWwindow* window, int width, int height);void processInput(GLFWwindow *window);// settingsconst unsigned int SCR_WIDTH = 800;const unsigned int SCR_HEIGHT = 600;const char *vertexShaderSource = &quot;#version 330 core\n&quot;    &quot;layout (location = 0) in vec3 aPos;\n&quot;    &quot;void main()\n&quot;    &quot;{\n&quot;    &quot;   gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);\n&quot;    &quot;}\0&quot;;const char *fragmentShaderSource = &quot;#version 330 core\n&quot;    &quot;out vec4 FragColor;\n&quot;    &quot;void main()\n&quot;    &quot;{\n&quot;    &quot;   FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);\n&quot;    &quot;}\n\0&quot;;int main(){    //glfw初始化和设置    glfwInit();    glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);    glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);    glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);    //创建glfw窗口设置当前上下文设置窗口大小变化回调    GLFWwindow* window = glfwCreateWindow(SCR_WIDTH, SCR_HEIGHT, &quot;LearnOpenGL&quot;, NULL, NULL);    if (window == NULL)    {        std::cout &lt;&lt; &quot;Failed to create GLFW window&quot; &lt;&lt; std::endl;        glfwTerminate();        return -1;    }    glfwMakeContextCurrent(window);    glfwSetFramebufferSizeCallback(window, framebuffer_size_callback);    // glad: load all OpenGL function pointers    if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress))    {        std::cout &lt;&lt; &quot;Failed to initialize GLAD&quot; &lt;&lt; std::endl;        return -1;    }    // build and compile our shader program    // 创建编译顶点着色器    int vertexShader = glCreateShader(GL_VERTEX_SHADER);    glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL);    glCompileShader(vertexShader);    // check for shader compile errors    int success;    char infoLog[512];    glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &amp;success);    if (!success)    {        glGetShaderInfoLog(vertexShader, 512, NULL, infoLog);        std::cout &lt;&lt; &quot;ERROR::SHADER::VERTEX::COMPILATION_FAILED\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl;    }    //创建编译片段着色器    int fragmentShader = glCreateShader(GL_FRAGMENT_SHADER);    glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL);    glCompileShader(fragmentShader);    // check for shader compile errors    glGetShaderiv(fragmentShader, GL_COMPILE_STATUS, &amp;success);    if (!success)    {        glGetShaderInfoLog(fragmentShader, 512, NULL, infoLog);        std::cout &lt;&lt; &quot;ERROR::SHADER::FRAGMENT::COMPILATION_FAILED\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl;    }    //创建shader程序 连接顶点片段着色器 连接shader程序    int shaderProgram = glCreateProgram();    glAttachShader(shaderProgram, vertexShader);    glAttachShader(shaderProgram, fragmentShader);    glLinkProgram(shaderProgram);    // check for linking errors    glGetProgramiv(shaderProgram, GL_LINK_STATUS, &amp;success);    if (!success) {        glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog);        std::cout &lt;&lt; &quot;ERROR::SHADER::PROGRAM::LINKING_FAILED\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl;    }    //链接完成着shader程序之后删除着色器程序    glDeleteShader(vertexShader);    glDeleteShader(fragmentShader);    // set up vertex data (and buffer(s)) and configure vertex attributes    //顶点数组    float vertices[] = {         0.5f,  0.5f, 0.0f,  // top right         0.5f, -0.5f, 0.0f,  // bottom right        -0.5f, -0.5f, 0.0f,  // bottom left        -0.5f,  0.5f, 0.0f   // top left     };    //索引数组    unsigned int indices[] = {  // note that we start from 0!        0, 1, 3,  // first Triangle        1, 2, 3   // second Triangle    };    //创建顶点缓冲对象 顶点数组对象 索引缓冲对象    unsigned int VBO, VAO, EBO;    glGenVertexArrays(1, &amp;VAO);    glGenBuffers(1, &amp;VBO);    glGenBuffers(1, &amp;EBO);    // bind the Vertex Array Object first, then bind and set vertex buffer(s), and then configure vertex attributes(s).    glBindVertexArray(VAO);    //绑定顶点缓冲区 copy顶点数据到顶点缓冲区对象    glBindBuffer(GL_ARRAY_BUFFER, VBO);    glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);    //绑定顶点索引缓冲区 copy顶点索引数据到顶点索引缓冲区    glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);    glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW);    //设置顶点属性指针 解释顶点数据 顶点索引获取顶点数据    glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);    glEnableVertexAttribArray(0);    // note that this is allowed, the call to glVertexAttribPointer registered VBO as the vertex attribute&#39;s bound vertex buffer object so afterwards we can safely unbind    glBindBuffer(GL_ARRAY_BUFFER, 0);     // remember: do NOT unbind the EBO while a VAO is active as the bound element buffer object IS stored in the VAO; keep the EBO bound.    //glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0);    // You can unbind the VAO afterwards so other VAO calls won&#39;t accidentally modify this VAO, but this rarely happens. Modifying other    // VAOs requires a call to glBindVertexArray anyways so we generally don&#39;t unbind VAOs (nor VBOs) when it&#39;s not directly necessary.    glBindVertexArray(0);     // uncomment this call to draw in wireframe polygons.    //glPolygonMode(GL_FRONT_AND_BACK, GL_LINE);    // render loop    // -----------    while (!glfwWindowShouldClose(window))    {        // input        // -----        processInput(window);        // render        // ------        glClearColor(0.2f, 0.3f, 0.3f, 1.0f);        glClear(GL_COLOR_BUFFER_BIT);        // draw our first triangle        glUseProgram(shaderProgram);        glBindVertexArray(VAO); // seeing as we only have a single VAO there&#39;s no need to bind it every time, but we&#39;ll do so to keep things a bit more organized        //glDrawArrays(GL_TRIANGLES, 0, 6); //需要绑定顶点数据        glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); //需要绑定顶点索引数据        // glBindVertexArray(0); // no need to unbind it every time         // glfw: swap buffers and poll IO events (keys pressed/released, mouse moved etc.)        // -------------------------------------------------------------------------------        glfwSwapBuffers(window);        glfwPollEvents();    }    // optional: de-allocate all resources once they&#39;ve outlived their purpose:    // ------------------------------------------------------------------------    glDeleteVertexArrays(1, &amp;VAO);    glDeleteBuffers(1, &amp;VBO);    glDeleteBuffers(1, &amp;EBO);    // glfw: terminate, clearing all previously allocated GLFW resources.    // ------------------------------------------------------------------    glfwTerminate();    return 0;}// process all input: query GLFW whether relevant keys are pressed/released this frame and react accordingly// ---------------------------------------------------------------------------------------------------------void processInput(GLFWwindow *window){    if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS)        glfwSetWindowShouldClose(window, true);}// glfw: whenever the window size changed (by OS or user resize) this callback function executes// ---------------------------------------------------------------------------------------------void framebuffer_size_callback(GLFWwindow* window, int width, int height){    // make sure the viewport matches the new window dimensions; note that width and     // height will be significantly larger than specified on retina displays.    glViewport(0, 0, width, height);}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;顶点数组对象：Vertex Array Object，VAO&lt;/li&gt;
&lt;li&gt;顶点缓冲对象：Vertex Buffer Object，VBO&lt;/li&gt;
&lt;li&gt;索引缓冲对象：Element Buffer Object，EBO或Inde
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>opengl纹理</title>
    <link href="https://bytemode.github.io/2018/12/27/opengl%E7%BA%B9%E7%90%86/"/>
    <id>https://bytemode.github.io/2018/12/27/opengl纹理/</id>
    <published>2018-12-27T08:59:39.000Z</published>
    <updated>2018-12-31T08:30:34.961Z</updated>
    
    <content type="html"><![CDATA[<h4 id="关于纹理"><a href="#关于纹理" class="headerlink" title="关于纹理"></a>关于纹理</h4><p>可以为每个顶点添加颜色来增加图形的细节，从而创建出丰富的图像。想让图形看起来更真实，我们就必须有足够多的顶点，从而指定足够多的颜色。这将会产生很多额外开销.纹理是一个2D图片，它可以用来添加物体的细节，这样就可以让物体非常精细而不用指定额外的顶点。</p><p>为了能够把纹理映射(Map)到三角形上，我们需要指定三角形的每个顶点各自对应纹理的哪个部分。这样每个顶点就会关联着一个纹理坐标(Texture Coordinate)，用来标明该从纹理图像的哪个部分采样。之后在图形的其它片段上进行片段插值(Fragment Interpolation)。</p><p>纹理坐标在x和y轴上，范围为0到1之间（注意我们使用的是2D纹理图像）。使用纹理坐标获取纹理颜色叫做采样(Sampling)。纹理坐标起始于(0, 0)，也就是纹理图片的左下角，终始于(1, 1)，即纹理图片的右上角。下面的图片展示了我们是如何把纹理坐标映射到三角形上的。</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_tex_coords.png" alt="img"></p><p>我们为三角形指定了3个纹理坐标点。如上图所示，我们希望三角形的左下角对应纹理的左下角，因此我们把三角形左下角顶点的纹理坐标设置为(0, 0)；三角形的上顶点对应于图片的上中位置所以我们把它的纹理坐标设置为(0.5, 1.0)；同理右下方的顶点设置为(1, 0)。我们只要给顶点着色器传递这三个纹理坐标就行了，接下来它们会被传片段着色器中，它会为每个片段进行纹理坐标的插值</p><p>纹理坐标看起来就像这样：</p><pre><code>float texCoords[] = {    0.0f, 0.0f, // 左下角    1.0f, 0.0f, // 右下角    0.5f, 1.0f // 上中};</code></pre><h4 id="纹理环绕方式"><a href="#纹理环绕方式" class="headerlink" title="纹理环绕方式"></a>纹理环绕方式</h4><p>纹理坐标的范围通常是从(0, 0)到(1, 1)，那如果我们把纹理坐标设置在范围之外会发生什么？OpenGL默认的行为是重复这个纹理图像，其他的环绕方式</p><table><thead><tr><th>环绕方式</th><th>描述</th></tr></thead><tbody><tr><td>GL_REPEAT</td><td>对纹理的默认行为。重复纹理图像。</td></tr><tr><td>GL_MIRRORED_REPEAT</td><td>和GL_REPEAT一样，但每次重复图片是镜像放置的。</td></tr><tr><td>GL_CLAMP_TO_EDGE</td><td>纹理坐标会被约束在0到1之间，超出的部分会重复纹理坐标的边缘，产生一种边缘被拉伸的效果。</td></tr><tr><td>GL_CLAMP_TO_BORDER</td><td>超出的坐标为用户指定的边缘颜色。</td></tr></tbody></table><p>纹理选项都可以使用glTexParameter*函数对单独的一个坐标轴设置（<code>s</code>、<code>t</code>、<code>r</code>）它们和<code>x</code>、<code>y</code>、<code>z</code>是等价的）：</p><pre><code>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT);</code></pre><p>第一个参数指定了纹理目标；我们使用的是2D纹理，因此纹理目标是GL_TEXTURE_2D。第二个参数需要我们指定设置的选项与应用的纹理轴。我们打算配置的是<code>WRAP</code>选项，并且指定<code>S</code>和<code>T</code>轴。最后一个参数需要我们传递一个环绕方式(Wrapping)，在这个例子中OpenGL会给当前激活的纹理设定纹理环绕方式为GL_MIRRORED_REPEAT。</p><p>如果我们选择GL_CLAMP_TO_BORDER选项，我们还需要指定一个边缘的颜色。这需要使用glTexParameter函数的<code>fv</code>后缀形式，用GL_TEXTURE_BORDER_COLOR作为它的选项，并且传递一个float数组作为边缘的颜色值：</p><pre><code>float borderColor[] = { 1.0f, 1.0f, 0.0f, 1.0f };glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, borderColor);</code></pre><h4 id="纹理过滤"><a href="#纹理过滤" class="headerlink" title="纹理过滤"></a>纹理过滤</h4><p>纹理坐标不依赖于分辨率(Resolution)，它可以是任意浮点值，所以OpenGL需要知道怎样将纹理像素(Texture Pixel)映射到纹理坐标。当你有一个很大的物体但是纹理的分辨率很低的时候这就变得很重要了。OpenGL也有对于纹理过滤(Texture Filtering)的选项。纹理过滤有很多个选项，但是现在我们只讨论最重要的两种：GL_NEAREST和GL_LINEAR。</p><p>GL_NEAREST（也叫邻近过滤，Nearest Neighbor Filtering）是OpenGL默认的纹理过滤方式。当设置为GL_NEAREST的时候，OpenGL会选择中心点最接近纹理坐标的那个像素。下图中你可以看到四个像素，加号代表纹理坐标。左上角那个纹理像素的中心距离纹理坐标最近，所以它会被选择为样本颜色：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_filter_nearest.png" alt="img"></p><p>GL_LINEAR（也叫线性过滤，(Bi)linear Filtering）它会基于纹理坐标附近的纹理像素，计算出一个插值，近似出这些纹理像素之间的颜色。一个纹理像素的中心距离纹理坐标越近，那么这个纹理像素的颜色对最终的样本颜色的贡献越大。下图中你可以看到返回的颜色是邻近像素的混合色：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_filter_linear.png" alt="img"></p><p>那么这两种纹理过滤方式有怎样的视觉效果呢？让我们看看在一个很大的物体上应用一张低分辨率的纹理会发生什么吧（纹理被放大了，每个纹理像素都能看到）：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_texture_filtering.png" alt="img"></p><p>GL_NEAREST产生了颗粒状的图案，我们能够清晰看到组成纹理的像素，而GL_LINEAR能够产生更平滑的图案，很难看出单个的纹理像素。GL_LINEAR可以产生更真实的输出，但有些开发者更喜欢8-bit风格，所以他们会用GL_NEAREST选项。</p><p>当进行放大(Magnify)和缩小(Minify)操作的时候可以设置纹理过滤的选项，比如你可以在纹理被缩小的时候使用邻近过滤，被放大时使用线性过滤。我们需要使用glTexParameter*函数为放大和缩小指定过滤方式。这段代码看起来会和纹理环绕方式的设置很相似：</p><pre><code>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);</code></pre><h4 id="多级纹理"><a href="#多级纹理" class="headerlink" title="多级纹理"></a>多级纹理</h4><p>再提个大场景中，每个物体上都有纹理。有些物体会很远，但其纹理会拥有与近处物体同样高的分辨率。由于远处的物体可能只产生很少的片段，OpenGL从高分辨率纹理中为这些片段获取正确的颜色值就很困难，因为它需要对一个跨过纹理很大部分的片段只拾取一个纹理颜色。在小物体上这会产生不真实的感觉，对它们使用高分辨率纹理浪费内存。</p><p>OpenGL使用一种叫做多级渐远纹理(Mipmap)的概念来解决这个问题，它简单来说就是一系列的纹理图像，后一个纹理图像是前一个的二分之一。多级渐远纹理背后的理念很简单：距观察者的距离超过一定的阈值，OpenGL会使用不同的多级渐远纹理，即最适合物体的距离的那个。由于距离远，解析度不高也不会被用户注意到。同时，多级渐远纹理另一加分之处是它的性能非常好。让我们看一下多级渐远纹理是什么样子的：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_mipmaps.png" alt="img"></p><p>手工为每个纹理图像创建一系列多级渐远纹理很麻烦，幸好OpenGL有一个glGenerateMipmaps函数，在创建完一个纹理后调用它OpenGL就会承担接下来的所有工作了。后面的教程中你会看到该如何使用它。</p><p>在渲染中切换多级渐远纹理级别(Level)时，OpenGL在两个不同级别的多级渐远纹理层之间会产生不真实的生硬边界。就像普通的纹理过滤一样，切换多级渐远纹理级别时你也可以在两个不同多级渐远纹理级别之间使用NEAREST和LINEAR过滤。为了指定不同多级渐远纹理级别之间的过滤方式，你可以使用下面四个选项中的一个代替原有的过滤方式：</p><table><thead><tr><th>过滤方式</th><th>描述</th></tr></thead><tbody><tr><td>GL_NEAREST_MIPMAP_NEAREST</td><td>使用最邻近的多级渐远纹理来匹配像素大小，并使用邻近插值进行纹理采样</td></tr><tr><td>GL_LINEAR_MIPMAP_NEAREST</td><td>使用最邻近的多级渐远纹理级别，并使用线性插值进行采样</td></tr><tr><td>GL_NEAREST_MIPMAP_LINEAR</td><td>在两个最匹配像素大小的多级渐远纹理之间进行线性插值，使用邻近插值进行采样</td></tr><tr><td>GL_LINEAR_MIPMAP_LINEAR</td><td>在两个邻近的多级渐远纹理之间使用线性插值，并使用线性插值进行采样</td></tr></tbody></table><p>就像纹理过滤一样，我们可以使用glTexParameteri将过滤方式设置为前面四种提到的方法之一：</p><pre><code>glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);</code></pre><p>一个常见的错误是，将放大过滤的选项设置为多级渐远纹理过滤选项之一。这样没有任何效果，因为多级渐远纹理主要是使用在纹理被缩小的情况下的：纹理放大不会使用多级渐远纹理，为放大过滤设置多级渐远纹理的选项会产生一个GL_INVALID_ENUM错误代码。</p><h2 id="生成纹理"><a href="#生成纹理" class="headerlink" title="生成纹理"></a>生成纹理</h2><p>创建纹理对象，使用id类记录对象</p><pre><code>unsigned int texture;glGenTextures(1, &amp;texture);</code></pre><p>glGenTextures函数首先需要输入生成纹理的数量，然后把它们储存在第二个参数的<code>unsigned int</code>数组中（我们的例子中只是单独的一个<code>unsigned int</code>），</p><p>绑定对象，让之后任何的纹理指令都可以配置当前绑定的纹理：</p><pre><code>glBindTexture(GL_TEXTURE_2D, texture);</code></pre><p>使用图片数据生成一个纹理了：</p><pre><code>glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);glGenerateMipmap(GL_TEXTURE_2D);</code></pre><p>函数很长，参数也不少，所以我们一个一个地讲解：</p><ul><li>第一个参数指定了纹理目标(Target)。设置为GL_TEXTURE_2D意味着会生成与当前绑定的纹理对象在同一个目标上的纹理（任何绑定到GL_TEXTURE_1D和GL_TEXTURE_3D的纹理不会受到影响）。</li><li>第二个参数为纹理指定多级渐远纹理的级别，如果你希望单独手动设置每个多级渐远纹理的级别的话。这里我们填0，也就是基本级别。</li><li>第三个参数告诉OpenGL我们希望把纹理储存为何种格式。我们的图像只有<code>RGB</code>值，因此我们也把纹理储存为<code>RGB</code>值。</li><li>第四个和第五个参数设置最终的纹理的宽度和高度。我们之前加载图像的时候储存了它们，所以我们使用对应的变量。</li><li>下个参数应该总是被设为<code>0</code>（历史遗留的问题）。</li><li>第七第八个参数定义了源图的格式和数据类型。我们使用RGB值加载这个图像，并把它们储存为<code>char</code>(byte)数组，我们将会传入对应值。</li><li>最后一个参数是真正的图像数据。</li></ul><p>当调用glTexImage2D时，当前绑定的纹理对象就会被附加上纹理图像。然而，目前只有基本级别(Base-level)的纹理图像被加载了，如果要使用多级渐远纹理，我们必须手动设置所有不同的图像（不断递增第二个参数）。或者，直接在生成纹理之后调用glGenerateMipmap。这会为当前绑定的纹理自动生成所有需要的多级渐远纹理。</p><p>生成一个纹理的过程应该看起来像这样：</p><pre><code>unsigned int texture;//生成并且绑定纹理对象glGenTextures(1, &amp;texture);glBindTexture(GL_TEXTURE_2D, texture);//为当前绑定的纹理对象设置环绕方式glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);   glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);//多级纹理过滤方式glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);// 加载并生成纹理int width, height, nrChannels;unsigned char *data = stbi_load(&quot;container.jpg&quot;, &amp;width, &amp;height, &amp;nrChannels, 0);if (data){    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);    glGenerateMipmap(GL_TEXTURE_2D);}else{    std::cout &lt;&lt; &quot;Failed to load texture&quot; &lt;&lt; std::endl;}</code></pre><h4 id="应用纹理"><a href="#应用纹理" class="headerlink" title="应用纹理"></a>应用纹理</h4><p>使用glDrawElements绘制,我们需要告知OpenGL如何采样纹理，所以我们必须使用纹理坐标更新顶点数据：</p><pre><code>float vertices[] = {//     ---- 位置 ----       ---- 颜色 ----     - 纹理坐标 -     0.5f,  0.5f, 0.0f,   1.0f, 0.0f, 0.0f,   1.0f, 1.0f,   // 右上     0.5f, -0.5f, 0.0f,   0.0f, 1.0f, 0.0f,   1.0f, 0.0f,   // 右下    -0.5f, -0.5f, 0.0f,   0.0f, 0.0f, 1.0f,   0.0f, 0.0f,   // 左下    -0.5f,  0.5f, 0.0f,   1.0f, 1.0f, 0.0f,   0.0f, 1.0f    // 左上};</code></pre><p>由于我们添加了一个额外的顶点属性，我们必须告诉OpenGL我们新的顶点格式：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_vertex_attribute_pointer_interleaved_textures.png" alt="img"></p><pre><code>glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(6 * sizeof(float)));glEnableVertexAttribArray(2);</code></pre><p>注意，我们同样需要调整前面两个顶点属性的步长参数为<code>8 * sizeof(float)</code>。</p><p>接着我们需要调整顶点着色器使其能够接受顶点坐标为一个顶点属性，并把坐标传给片段着色器：</p><pre><code>#version 330 corelayout (location = 0) in vec3 aPos;layout (location = 1) in vec3 aColor;layout (location = 2) in vec2 aTexCoord;out vec3 ourColor;out vec2 TexCoord;void main(){    gl_Position = vec4(aPos, 1.0);    ourColor = aColor;    TexCoord = aTexCoord;}</code></pre><p>片段着色器应该接下来会把输出变量<code>TexCoord</code>作为输入变量。</p><p>片段着色器也应该能访问纹理对象，但是我们怎样能把纹理对象传给片段着色器呢？GLSL有一个供纹理对象使用的内建数据类型，叫做采样器(Sampler)，它以纹理类型作为后缀，比如<code>sampler1D</code>、<code>sampler3D</code>，或在我们的例子中的<code>sampler2D</code>。我们可以简单声明一个<code>uniform sampler2D</code>把一个纹理添加到片段着色器中，稍后我们会把纹理赋值给这个uniform。</p><pre><code>#version 330 coreout vec4 FragColor;in vec3 ourColor;in vec2 TexCoord;uniform sampler2D ourTexture;void main(){    FragColor = texture(ourTexture, TexCoord);}</code></pre><p>我们使用GLSL内建的texture函数来采样纹理的颜色，它第一个参数是纹理采样器，第二个参数是对应的纹理坐标。texture函数会使用之前设置的纹理参数对相应的颜色值进行采样。这个片段着色器的输出就是纹理的（插值）纹理坐标上的(过滤后的)颜色</p><p>现在只剩下在调用glDrawElements之前绑定纹理了，它会自动把纹理赋值给片段着色器的采样器：</p><pre><code>//glBindTexture中textture是纹理对象的idglBindTexture(GL_TEXTURE_2D, texture);glBindVertexArray(VAO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);</code></pre><p>完成之后你会看到下面的图像：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_textures2.png" alt="img"></p><p>我们还可以把得到的纹理颜色与顶点颜色混合，来获得更有趣的效果。我们只需把纹理颜色与顶点颜色在片段着色器中相乘来混合二者的颜色：</p><pre><code>FragColor = texture(ourTexture, TexCoord) * vec4(ourColor, 1.0);</code></pre><p>最终的效果应该是顶点颜色和纹理颜色的混合色：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_textures_funky.png" alt="img"></p><p>我猜你会说我们的箱子喜欢跳70年代的迪斯科。</p><h4 id="纹理单元"><a href="#纹理单元" class="headerlink" title="纹理单元"></a>纹理单元</h4><p>你可能会奇怪为什么<code>sampler2D</code>变量是个uniform，我们却不用glUniform给它赋值。使用glUniform1i，我们可以给纹理采样器分配一个位置值，这样的话我们能够在一个片段着色器中设置多个纹理。一个纹理的位置值通常称为一个纹理单元(Texture Unit)。一个纹理的默认纹理单元是0，它是默认的激活纹理单元，所以教程前面部分我们没有分配一个位置值。</p><p>纹理单元的主要目的是让我们在着色器中可以使用多于一个的纹理。通过把纹理单元赋值给采样器，我们可以一次绑定多个纹理，只要我们首先激活对应的纹理单元。就像glBindTexture一样，我们可以使用glActiveTexture激活纹理单元，传入我们需要使用的纹理单元：</p><pre><code>glActiveTexture(GL_TEXTURE0); // 在绑定纹理之前先激活纹理单元glBindTexture(GL_TEXTURE_2D, texture);</code></pre><p>激活纹理单元之后，接下来的glBindTexture函数调用会绑定这个纹理到当前激活的纹理单元，纹理单元GL_TEXTURE0默认总是被激活，所以我们在前面的例子里当我们使用<code>glBindTexture</code>的时候，无需激活任何纹理单元。</p><p>OpenGL至少保证有16个纹理单元供你使用，也就是说你可以激活从GL_TEXTURE0到GL_TEXTRUE15。它们都是按顺序定义的，所以我们也可以通过GL_TEXTURE0 + 8的方式获得GL_TEXTURE8，这在当我们需要循环一些纹理单元的时候会很有用。</p><p>我们仍然需要编辑片段着色器来接收另一个采样器。这应该相对来说非常直接了：</p><pre><code>#version 330 core...uniform sampler2D texture1;uniform sampler2D texture2;void main(){    FragColor = mix(texture(texture1, TexCoord), texture(texture2, TexCoord), 0.2);}</code></pre><p>最终输出颜色现在是两个纹理的结合。GLSL内建的mix函数需要接受两个值作为参数，并对它们根据第三个参数进行线性插值。如果第三个值是<code>0.0</code>，它会返回第一个输入；如果是<code>1.0</code>，会返回第二个输入值。<code>0.2</code>会返回<code>80%</code>的第一个输入颜色和<code>20%</code>的第二个输入颜色，即返回两个纹理的混合色。</p><p>我们现在需要载入并创建另一个纹理；你应该对这些步骤很熟悉了。记得创建另一个纹理对象，载入图片，使用glTexImage2D生成最终纹理。</p><p>为了使用第二个纹理（以及第一个），我们必须改变一点渲染流程，<strong>先绑定两个纹理到对应的纹理单元，然后定义哪个uniform采样器对应哪个纹理单元</strong>：</p><pre><code>glActiveTexture(GL_TEXTURE0);glBindTexture(GL_TEXTURE_2D, texture1);glActiveTexture(GL_TEXTURE1);glBindTexture(GL_TEXTURE_2D, texture2);glBindVertexArray(VAO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);</code></pre><p>我们还要通过使用<strong>glUniform1i设置每个采样器的方式告诉OpenGL每个着色器采样器属于哪个纹理单元</strong>。我们只需要设置一次即可，所以这个会放在渲染循环的前面：</p><pre><code>ourShader.use(); // 别忘记在激活着色器前先设置uniform！glUniform1i(glGetUniformLocation(ourShader.ID, &quot;texture1&quot;), 0); // 手动设置ourShader.setInt(&quot;texture2&quot;, 1); // 或者使用着色器类设置while(...) {    [...]}</code></pre><p>通过使用glUniform1i设置采样器，我们保证了每个uniform采样器对应着正确的纹理单元。你应该能得到下面的结果：</p><p><img src="https://www.cnblogs.com/images/cnblogs_com/bytemode/1361208/o_textures_combined.png" alt="img"></p><p>你可能注意到纹理上下颠倒了！这是因为OpenGL要求y轴<code>0.0</code>坐标是在图片的底部的，但是图片的y轴<code>0.0</code>坐标通常在顶部。在图像加载时帮助我们翻转y轴。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;关于纹理&quot;&gt;&lt;a href=&quot;#关于纹理&quot; class=&quot;headerlink&quot; title=&quot;关于纹理&quot;&gt;&lt;/a&gt;关于纹理&lt;/h4&gt;&lt;p&gt;可以为每个顶点添加颜色来增加图形的细节，从而创建出丰富的图像。想让图形看起来更真实，我们就必须有足够多的顶点，从而指定足够多
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx源码分析-批处理渲染</title>
    <link href="https://bytemode.github.io/2018/12/27/cocos2dx%E6%89%B9%E5%A4%84%E7%90%86%E6%B8%B2%E6%9F%93/"/>
    <id>https://bytemode.github.io/2018/12/27/cocos2dx批处理渲染/</id>
    <published>2018-12-27T08:32:40.000Z</published>
    <updated>2019-01-04T10:30:07.347Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>opengl基础</title>
    <link href="https://bytemode.github.io/2018/12/27/opengl%E5%9F%BA%E7%A1%80/"/>
    <id>https://bytemode.github.io/2018/12/27/opengl基础/</id>
    <published>2018-12-27T08:13:48.000Z</published>
    <updated>2018-12-29T13:53:10.763Z</updated>
    
    <content type="html"><![CDATA[<h4 id="opengl"><a href="#opengl" class="headerlink" title="opengl"></a>opengl</h4><p>opengl是一个由<a href="http://www.khronos.org/" target="_blank" rel="noopener">Khronos组织</a>制定并维护的规范(Specification) 。是一系列的图形软件编程接口，和gdi类似。opengl有很多封装的库最有名的GLFW库。接下来很多东西以GLFW 为例子来说明一些api的使用问题，但这并不影响opengl本身的逻辑表述。</p><h5 id="状态机"><a href="#状态机" class="headerlink" title="状态机"></a>状态机</h5><p>OpenGL自身是一个巨大的状态机(State Machine)：一系列的变量描述OpenGL此刻应当如何运行。OpenGL的状态通常被称为OpenGL上下文(Context)。我们通常使用如下途径去更改OpenGL状态：设置选项，操作缓冲。最后，我们使用当前OpenGL上下文来渲染。</p><p>假设当我们想告诉OpenGL去画线段而不是三角形的时候，我们通过改变一些上下文变量来改变OpenGL状态，从而告诉OpenGL如何去绘图。一旦我们改变了OpenGL的状态为绘制线段，下一个绘制命令就会画出线段而不是三角形。</p><p>当使用OpenGL的时候，我们会遇到一些状态设置函数(State-changing Function)，这类函数将会改变上下文。以及状态使用函数(State-using Function)，这类函数会根据当前OpenGL的状态执行一些操作。只要你记住OpenGL本质上是个大状态机，就能更容易理解它的大部分特性。</p><h5 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h5><p>在OpenGL中一个对象是指一些选项的集合，它代表OpenGL状态的一个子集 。</p><p>当我们使用一个对象时，通常看起来像如下一样：</p><pre><code>// OpenGL的状态struct OpenGL_Context {    ...    object* object_Window_Target;    ...     };// 创建对象unsigned int objectId = 0;glGenObject(1, &amp;objectId);// 绑定对象至上下文glBindObject(GL_WINDOW_TARGET, objectId);// 设置当前绑定到 GL_WINDOW_TARGET 的对象的一些选项glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);// 将上下文对象设回默认glBindObject(GL_WINDOW_TARGET, 0);</code></pre><p>这一段代码展现了使用OpenGL时常见的工作流。我们首先创建一个对象，然后用一个id保存它的引用（实际数据被储存在后台）。然后我们将对象绑定至上下文的目标位置（例子中窗口对象目标的位置被定义成GL_WINDOW_TARGET）。接下来我们设置窗口的选项。最后我们将目标位置的对象id设回0，解绑这个对象。设置的选项将被保存在objectId所引用的对象中，一旦我们重新绑定这个对象到GL_WINDOW_TARGET位置，这些选项就会重新生效。</p><h4 id="程序结构"><a href="#程序结构" class="headerlink" title="程序结构"></a>程序结构</h4><p>我们要开始一个图形渲染程序，首要是要选择gl库，因为要使用api.然后创建窗口、设置视口、设置窗口大小调整后的回调在回调中要处理视口、接着是渲染循环、还要处理处输入等。</p><h5 id="实例化配置glfw"><a href="#实例化配置glfw" class="headerlink" title="实例化配置glfw"></a>实例化配置glfw</h5><pre><code>int main(){    glfwInit();  //初始化glfw    glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); //配置glfw    glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);    glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);    //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE);    return 0;}</code></pre><p>首先，我们在main函数中调用glfwInit函数来初始化GLFW，然后我们可以使用glfwWindowHint函数来配置GLFW。glfwWindowHint函数的第一个参数代表选项的名称，我们可以从很多以GLFW_开头的枚举值中选择；第二个参数接受一个整形，用来设置这个选项的值</p><h5 id="创建窗口"><a href="#创建窗口" class="headerlink" title="创建窗口"></a>创建窗口</h5><p>接下来我们创建一个窗口对象，这个窗口对象存放了所有和窗口相关的数据，而且会被GLFW的其他函数频繁地用到。</p><pre><code>GLFWwindow* window = glfwCreateWindow(800, 600, &quot;LearnOpenGL&quot;, NULL, NULL);if (window == NULL){    glfwTerminate();    return -1;}glfwMakeContextCurrent(window);</code></pre><p>glfwCreateWindow函数需要窗口的宽和高作为它的前两个参数。第三个参数表示这个窗口的名称（标题），。这个函数将会返回一个GLFWwindow对象，创建完窗口我们就可以通知GLFW将我们窗口的上下文设置为当前线程的主上下文了。</p><h5 id="视口"><a href="#视口" class="headerlink" title="视口"></a>视口</h5><p>必须告诉OpenGL渲染窗口的尺寸大小，即视口(Viewport)，这样OpenGL才只能知道怎样根据窗口大小显示数据和坐标。我们可以通过调用glViewport函数来设置窗口的<strong>维度</strong>(Dimension)：</p><pre><code>glViewport(0, 0, 800, 600);</code></pre><p>glViewport函数前两个参数控制窗口左下角的位置。第三个和第四个参数控制渲染窗口的宽度和高度（像素）。</p><p>OpenGL幕后使用glViewport中定义的位置和宽高进行2D坐标的转换，将OpenGL中的位置坐标转换为你的屏幕坐标，处理过的OpenGL坐标范围只为-1到1。 </p><p>当窗口大小发生变换的时候需要设置视口的大小：</p><pre><code>glfwSetFramebufferSizeCallback(window, [](GLFWwindow* window, int width, int height){    glViewport(0, 0, width, height);});</code></pre><h5 id="处理输入"><a href="#处理输入" class="headerlink" title="处理输入"></a>处理输入</h5><p>我们同样也希望能够在GLFW中实现一些输入控制，这可以通过使用GLFW的几个输入函数来完成。我们将会使用GLFW的glfwGetKey函数，它需要一个窗口以及一个按键作为输入。这个函数将会返回这个按键是否正在被按下。我们将创建一个processInput函数来让所有的输入代码保持整洁。</p><pre><code>void processInput(GLFWwindow *window){    if(glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS)        glfwSetWindowShouldClose(window, true);}</code></pre><h5 id="渲染循环"><a href="#渲染循环" class="headerlink" title="渲染循环"></a>渲染循环</h5><p>需要在程序中添加一个while循环，我们可以把它称之为渲染循环(Render Loop)，它能在我们让GLFW退出前一直保持运行。下面几行的代码就实现了一个简单的渲染循环：</p><pre><code>// 渲染循环while(!glfwWindowShouldClose(window)){    // 输入    processInput(window);    // 渲染指令    ...    glClearColor(0.2f, 0.3f, 0.3f, 1.0f);    glClear(GL_COLOR_BUFFER_BIT);    // 检查并调用事件，交换缓冲    glfwPollEvents();    glfwSwapBuffers(window);}glfwTerminate();</code></pre><ul><li>glfwWindowShouldClose函数在我们每次循环的开始前检查一次GLFW是否被要求退出，如果是的话该函数返回<code>true</code>然后渲染循环便结束了，之后为我们就可以关闭应用程序了。</li><li>glfwPollEvents函数检查有没有触发什么事件（比如键盘输入、鼠标移动等）、更新窗口状态，并调用对应的回调函数（可以通过回调方法手动设置）。</li><li>glfwSwapBuffers函数会交换颜色缓冲（它是一个储存着GLFW窗口每一个像素颜色值的大缓冲），它在这一迭代中被用来绘制，并且将会作为输出显示在屏幕上。</li><li>glClear函数来清空屏幕的颜色缓冲，它接受一个缓冲位(Buffer Bit)来指定要清空的缓冲，可能的缓冲位有GL_COLOR_BUFFER_BIT，GL_DEPTH_BUFFER_BIT和GL_STENCIL_BUFFER_BIT。 </li><li>调用了glClearColor来设置清空屏幕所用的颜色 </li><li>glClearColor函数是一个<strong>状态设置</strong>函数，而glClear函数则是一个<strong>状态使用</strong>的函数，它使用了当前的状态来获取应该清除为的颜色。 </li><li>glfwTerminate(); 释放所有申请的资源</li></ul><h5 id="双缓冲-Double-Buffer"><a href="#双缓冲-Double-Buffer" class="headerlink" title="双缓冲(Double Buffer)"></a>双缓冲(Double Buffer)</h5><p>应用程序使用单缓冲绘图时可能会存在图像闪烁的问题。 这是因为生成的图像不是一下子被绘制出来的，而是按照从左到右，由上而下逐像素地绘制而成的。最终图像不是在瞬间显示给用户，而是通过一步一步生成的，这会导致渲染的结果很不真实。为了规避这些问题，我们应用双缓冲渲染窗口应用程序。<strong>前</strong>缓冲保存着最终输出的图像，它会在屏幕上显示；而所有的的渲染指令都会在<strong>后</strong>缓冲上绘制。当所有的渲染指令执行完毕后，我们<strong>交换</strong>(Swap)前缓冲和后缓冲，这样图像就立即呈显出来，之前提到的不真实感就消除了。</p><h4 id="最终的程序结构"><a href="#最终的程序结构" class="headerlink" title="最终的程序结构"></a>最终的程序结构</h4><pre><code>#include &lt;glad/glad.h&gt;#include &lt;GLFW/glfw3.h&gt;#include &lt;iostream&gt;void framebuffer_size_callback(GLFWwindow* window, int width, int height);void processInput(GLFWwindow *window);// settingsconst unsigned int SCR_WIDTH = 800;const unsigned int SCR_HEIGHT = 600;int main(){    //glfw初始化和设置    glfwInit();    glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);    glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);    glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);    //创建窗口配置窗口    GLFWwindow* window = glfwCreateWindow(SCR_WIDTH, SCR_HEIGHT, &quot;LearnOpenGL&quot;, NULL, NULL);    if (window == NULL)    {        glfwTerminate();        return -1;    }    //设置问当前窗口上下文    glfwMakeContextCurrent(window);    //设置窗口大小改变的回调 处理视口变化    glfwSetFramebufferSizeCallback(window, framebuffer_size_callback);    // render loop    while (!glfwWindowShouldClose(window))    {        // input        processInput(window);        // render        glClearColor(0.2f, 0.3f, 0.3f, 1.0f);        glClear(GL_COLOR_BUFFER_BIT);        // glfw: swap buffers and poll IO events (keys pressed/released, mouse moved etc.)        // -------------------------------------------------------------------------------        glfwSwapBuffers(window);        glfwPollEvents();    }    // glfw: terminate, clearing all previously allocated GLFW resources.    glfwTerminate();    return 0;}void processInput(GLFWwindow *window){    if(glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS)        glfwSetWindowShouldClose(window, true);}void framebuffer_size_callback(GLFWwindow* window, int width, int height){    glViewport(0, 0, width, height);}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;opengl&quot;&gt;&lt;a href=&quot;#opengl&quot; class=&quot;headerlink&quot; title=&quot;opengl&quot;&gt;&lt;/a&gt;opengl&lt;/h4&gt;&lt;p&gt;opengl是一个由&lt;a href=&quot;http://www.khronos.org/&quot; target=&quot;_b
      
    
    </summary>
    
      <category term="opengl" scheme="https://bytemode.github.io/categories/opengl/"/>
    
    
      <category term="opengl" scheme="https://bytemode.github.io/tags/opengl/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx源码分析-如何绘制图片</title>
    <link href="https://bytemode.github.io/2018/12/18/cocos2dx%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%98%E5%88%B6%E5%9B%BE%E7%89%87%E7%9A%84/"/>
    <id>https://bytemode.github.io/2018/12/18/cocos2dx是如何绘制图片的/</id>
    <published>2018-12-18T13:56:58.000Z</published>
    <updated>2019-01-04T10:29:56.042Z</updated>
    
    <content type="html"><![CDATA[<p>cocos2dx绘制单个图片的渲染命令是QUAD_COMMAND,通过分析这个命令可以学习opengl es是如何处理图片渲染的.</p><h4 id="关于VAO和VBO"><a href="#关于VAO和VBO" class="headerlink" title="关于VAO和VBO"></a>关于VAO和VBO</h4><p>顶点数组对象（Vertex Array Object  即VAO）是一个包含多个顶点缓冲区对象（Vertex Buffer Object， 即 VBO）的对象，一般存储一个可渲染物体的顶点信息. 顶点缓冲区对象（ VBO）是你显卡内存中的一块高速内存缓冲区，用来存储顶点的所有信息。</p><p>顶点数组指定的顶点数据保存在客户内存中,在进行glDrawArray或者glDrawElements等绘图调用时，这些数据必须同客户内存复制到图形内存中,没必要每次绘图时都复制顶点数据，而是在图形内存中缓存这些数据，这样可以显著改善渲染性能，也可以降低内存带宽和电力消耗需求,这就是顶点缓冲区对象发挥作用的地方.在OpenGL3.0中，出现了更进一步的VAO，VBO通过绘制上下文获得绘制状态，VAO可以拥有多个VBO，它记录所有绘制状态，它的代码更简洁，效率更高.</p><pre><code>void Renderer::setupBuffer(){    if(Configuration::getInstance()-&gt;supportsShareableVAO())    {        //初始化VBO和VAO        setupVBOAndVAO();    }    else    {        //不支持VAO，只初始化VBO        setupVBO();    }}void Renderer::setupVBOAndVAO(){    //一个VAO    glGenVertexArrays(1, &amp;_quadVAO);    //绑定VAO    GL::bindVAO(_quadVAO);    //创建生成两个VBO    glGenBuffers(2, &amp;_buffersVBO[0]);    //顶点Buffer    glBindBuffer(GL_ARRAY_BUFFER, _buffersVBO[0]);    glBufferData(GL_ARRAY_BUFFER, sizeof(_quads[0]) * VBO_SIZE, _quads, GL_DYNAMIC_DRAW);    //这里就是VAO和VBO的区别，VAO把这些放到初始化中，无论后面绘制多少次，只要他不被改变，这段代码只会被调用一次，而VBO中，这个功能的代码会在每次被绘制时调用，这样就节约了效率    //位置    glEnableVertexAttribArray(GLProgram::VERTEX_ATTRIB_POSITION);    glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_POSITION, 3, GL_FLOAT, GL_FALSE, sizeof(V3F_C4B_T2F), (GLvoid*) offsetof( V3F_C4B_T2F, vertices));    //颜色    glEnableVertexAttribArray(GLProgram::VERTEX_ATTRIB_COLOR);    glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_COLOR, 4, GL_UNSIGNED_BYTE, GL_TRUE, sizeof(V3F_C4B_T2F), (GLvoid*) offsetof( V3F_C4B_T2F, colors));    //纹理坐标数据    glEnableVertexAttribArray(GLProgram::VERTEX_ATTRIB_TEX_COORDS);    glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_TEX_COORDS, 2, GL_FLOAT, GL_FALSE, sizeof(V3F_C4B_T2F), (GLvoid*) offsetof( V3F_C4B_T2F, texCoords));    //索引Buffer    glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, _buffersVBO[1]);    glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(_indices[0]) * VBO_SIZE * 6, _indices, GL_STATIC_DRAW);    //取消VAO    GL::bindVAO(0);    glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0);    glBindBuffer(GL_ARRAY_BUFFER, 0);    CHECK_GL_ERROR_DEBUG();}void Renderer::setupVBO(){    //创建生成两个VBO    glGenBuffers(2, &amp;_buffersVBO[0]);    //调用函数绑定buffer    mapBuffers();}void Renderer::mapBuffers(){    //GL_ARRAY_BUFFER 表示顶点数据    //GL_ELEMENT_ARRAY_BUFFER 表示索引数据    //避免改变buffer元素    GL::bindVAO(0);    //绑定id 顶点数据    glBindBuffer(GL_ARRAY_BUFFER, _buffersVBO[0]);    //为改id制定一段内存区域    glBufferData(GL_ARRAY_BUFFER, sizeof(_quads[0]) * VBO_SIZE, _quads, GL_DYNAMIC_DRAW);    glBindBuffer(GL_ARRAY_BUFFER, 0);    //第二个VBO 索引数据    glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, _buffersVBO[1]);    glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(_indices[0]) * VBO_SIZE * 6, _indices, GL_STATIC_DRAW);    glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, 0);    CHECK_GL_ERROR_DEBUG();}</code></pre><p>0l;需要介绍的两个关键的函数</p><p>glBindBuffer：它绑定缓冲区对象表示选择未来的操作将影响哪个缓冲区对象。如果应用程序有多个缓冲区对象，就需要多次调用glBindBuffer()函数：一次用于初始化缓冲区对象以及它的数据，以后的调用要么选择用于渲染的缓冲区对象，要么对缓冲区对象的数据进行更新。</p><p>当传入的第二个参数第一次使用一个非零无符号整数时，创建一个新的缓冲区对象；当第二个参数是之前使用过的，这个缓冲区对象成为活动缓冲区对象；如果第二个参数值为0时，停止使用缓冲区对象</p><p>glBufferData：保留空间存储数据，他分配一定大小的（第二个参数）的openGL服务端内存，用于存储顶点数据或索引。这个被绑定的对象之前相关联的数据都会被清除。</p><p>glBufferData参数介绍</p><p>参数1，目标GL_ARRAY_BUFFER或者GL_ELEMENT_ARRAY_BUFFER</p><p>参数2，内存容量</p><p>参数3，用于初始化缓冲区对象，可以使一个指针，也可以是空</p><p>参数4，如何读写，可以选择如下几种</p><pre><code>GL_DYNAMIC_DRAW:多次指定，多次作为绘图和图像指定函数的源数据，缓冲区对象的数据不仅常常需要进行更新，而且使用频率也非常高GL_STATIC_DRAW:数据只指定一次，多次作为绘图和图像指定函数的源数据，缓冲区对象的数据只指定1次，但是这些数据被使用的频率很高GL_STREAM_DRAW:数据只指定一次，最多只有几次作为绘图和图像指定函数的源数据，缓冲区对象中的数据常常需要更新，但是在绘图或其他操作中使用这些数据的次数较少</code></pre><p>从初始化的代码上，为什么VAO反倒复杂了呢？因为他只是把绘制时需要做的一些事情提前放到初始化函数中，来看一下绘制流程。</p><pre><code>//当前的openGL是否支持VAOif (Configuration::getInstance()-&gt;supportsShareableVAO()){    //绑定顶点数组    glBindBuffer(GL_ARRAY_BUFFER, _buffersVBO[0]);    //向缓冲区申请空间并指定数据传输方式    glBufferData(GL_ARRAY_BUFFER, sizeof(_quads[0]) * (_numQuads), nullptr, GL_DYNAMIC_DRAW);    //提供缓冲区对象包含整个数据集合的更新    void *buf = glMapBuffer(GL_ARRAY_BUFFER, GL_WRITE_ONLY);    memcpy(buf, _quads, sizeof(_quads[0])* (_numQuads));    //缓冲区对象的更新完成    glUnmapBuffer(GL_ARRAY_BUFFER);    //为了禁用缓冲区对象，可以用0作为缓冲区对象的标识符来调用glBindBuffer()函数。这将把OpenGL切换为默认的不使用缓冲区对象的模式。    glBindBuffer(GL_ARRAY_BUFFER, 0);    //Bind VAO    GL::bindVAO(_quadVAO);}else{</code></pre><p>#define kQuadSize sizeof(_quads[0].bl)<br>        glBindBuffer(GL_ARRAY_BUFFER, _buffersVBO[0]);<br>        glBufferData(GL_ARRAY_BUFFER, sizeof(_quads[0]) <em> _numQuads , _quads, GL_DYNAMIC_DRAW);<br>        //激活顶点颜色纹理坐标的属性<br>        GL::enableVertexAttribs(GL::VERTEX_ATTRIB_FLAG_POS_COLOR_TEX);<br>        //顶点<br>        glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_POSITION, 3, GL_FLOAT, GL_FALSE, kQuadSize, (GLvoid</em>) offsetof(V3F_C4B_T2F, vertices));<br>        //颜色<br>        glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_COLOR, 4, GL_UNSIGNED_BYTE, GL_TRUE, kQuadSize, (GLvoid<em>) offsetof(V3F_C4B_T2F, colors));<br>        //纹理坐标<br>        glVertexAttribPointer(GLProgram::VERTEX_ATTRIB_TEX_COORDS, 2, GL_FLOAT, GL_FALSE, kQuadSize, (GLvoid</em>) offsetof(V3F_C4B_T2F, texCoords));</p><pre><code>    glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, _buffersVBO[1]);}</code></pre><p>可以看到，这些设置属性的函数放在了绘制函数里，虽然看似是一样的，但是绘制函数会被调用的更频繁，所以把这些函数放到初始化函数中可以大幅提高程序的效率。</p><p>这里介绍VAO的两个函数：</p><p>glMapBuffer函数返回一个指针，指向与第一个参数相关联的当前绑定缓冲区对象的数据存储。第一个参数与glBufferData的第一个参数一致。第二个参数是GL_READ_ONLY、GL_WRITE_ONLY或GL_READ_WRITE之一，表示可以对数据进行的操作。</p><p>glUnmapBuffer表示对当前绑定缓冲区对象的更新已经完成，并且这个缓冲区可以释放。</p><p>enableVertexAttribs激活相关属性，激活的属性可以调用glVertexAttribPointer指定数据源，可选的有VERTEX_ATTRIB_FLAG_POSITION，VERTEX_ATTRIB_FLAG_COLOR和VERTEX_ATTRIB_FLAG_TEX_COORDS，这里这个参数是激活这三个。</p><p>glVertexAttribPointer指定了渲染时第一个参数代表的索引值的顶点属性数组的数据格式和位置。</p><p>第一个参数指定要修改的顶点属性的索引值，包括VERTEX_ATTRIB_POSITION（位置），VERTEX_ATTRIB_COLOR（颜色），VERTEX_ATTRIB_TEX_COORDS（纹理坐标）。</p><p>第二个参数指定每个属性值的组件数量且必须为1、2、3、4之一。</p><p>第三个参数指定数组中每个组件的数据类型。可用的符号常量有GL_BYTE, GL_UNSIGNED_BYTE, GL_SHORT,GL_UNSIGNED_SHORT,GL_FIXED, 和 GL_FLOAT，初始值为GL_FLOAT。</p><p>第四个参数指定当被访问时，固定点数据值是否应该被归一化（GL_TRUE，意味着整数型的值会被映射至区间<a href="有符号整数">-1,1</a>，或者区间[0,1]（无符号整数））或者直接转换为固定点值（GL_FALSE）。</p><p>第五个参数指定了一个属性到下一个属性之间的步长（这就允许属性值被存储在单一数组或者不同的数组中）。也就是连续顶点属性之间的偏移量。如果为0，那么它们是紧密排列在一起的。初始值为0。</p><p>第六个参数指定一个指针，指向数组中第一个顶点属性的第一个组件。初始值为0。</p><p>最后需要调用绘制元素函数，绘制这些信息</p><p>glDrawElements(GL_TRIANGLES, (GLsizei) quadsToDraw<em>6, GL_UNSIGNED_SHORT, (GLvoid</em>) (startQuad<em>6</em>sizeof(_indices[0])) );<br>它根据索引绘图(注意：顶点数据和索引各自使用不同的缓冲区)</p><pre><code>需要注意的是在Renderer的析构函数中要调用glDeleteBuffers来释放它的资源，并使它的标识可以其他缓冲区对象使用。</code></pre><h3 id="QUAD-COMMAND的绘制函数"><a href="#QUAD-COMMAND的绘制函数" class="headerlink" title="QUAD_COMMAND的绘制函数"></a>QUAD_COMMAND的绘制函数</h3><p>QUAD_COMMAND命令回调用drawBatchedQuads调用绘制函数</p><pre><code>else if ( RenderCommand::Type::QUAD_COMMAND == commandType )        {            flush3D();            if(_filledIndex &gt; 0)            {                drawBatchedTriangles();                _lastMaterialID = 0;            }            auto cmd = static_cast&lt;QuadCommand*&gt;(command);            //Batch quads            if( (_numberQuads + cmd-&gt;getQuadCount()) * 4 &gt; VBO_SIZE )            {                drawBatchedQuads();            }            _batchQuadCommands.push_back(cmd);            fillQuads(cmd);        }void Renderer::flush(){    //绘制    drawBatchedQuads();    //清空    _lastMaterialID = 0;}</code></pre><p>这个处理主要是把命令存入_batchedQuadCommands中，如果如果Quad数据量超过VBO的大小，那么调用绘制，将缓存的命令全部绘制.如果一直没有超过VBO的大小，drawBatchedQuads绘制函数将在flush被调用时调用</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;cocos2dx绘制单个图片的渲染命令是QUAD_COMMAND,通过分析这个命令可以学习opengl es是如何处理图片渲染的.&lt;/p&gt;
&lt;h4 id=&quot;关于VAO和VBO&quot;&gt;&lt;a href=&quot;#关于VAO和VBO&quot; class=&quot;headerlink&quot; title=&quot;关
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
  <entry>
    <title>cocos2dx源码分析-渲染架构</title>
    <link href="https://bytemode.github.io/2018/12/17/cocos2dx%E6%B8%B2%E6%9F%93%E6%9E%B6%E6%9E%84/"/>
    <id>https://bytemode.github.io/2018/12/17/cocos2dx渲染架构/</id>
    <published>2018-12-17T12:13:14.000Z</published>
    <updated>2019-01-04T10:29:37.966Z</updated>
    
    <content type="html"><![CDATA[<p>2dx的时代UI树便利和渲染是没有分开的，遍历UI树的时候就渲染.3dx版本为了分离了ui树的遍历和渲染，先遍历生成渲染命令发到渲染队列，之后遍历渲染命令队列开始渲染.这样做的好处是渲染命令可以重用，单独的渲染可以做优化例如自动批绘制.本篇首先介绍cocos2D-X 3.x版本的渲染结构，之后会深入opengl es.</p><h4 id="mainLoop"><a href="#mainLoop" class="headerlink" title="mainLoop"></a>mainLoop</h4><pre><code>void DisplayLinkDirector::mainLoop(){    if (_purgeDirectorInNextLoop)    {        //只有一种情况会调用到这里来，就是导演类调用end函数        _purgeDirectorInNextLoop = false;        //清除导演类        purgeDirector();    }    else if (! _invalid)    {        //绘制        drawScene();        //清除内存        PoolManager::getInstance()-&gt;getCurrentPool()-&gt;clear();    }}</code></pre><p>分析的起点是mainLoop函数，这是在主线程里面会调用的循环，其中drawScene函数进行绘制。那么就进一步来看drawScene函数。mainLoop实在opengl的ondrawframe调用过来的即平台每帧渲染会调用.</p><h4 id="drawScene"><a href="#drawScene" class="headerlink" title="drawScene"></a>drawScene</h4><pre><code>void Director::drawScene(){    //计算间隔时间    calculateDeltaTime();    //如果间隔时间过小会被忽略    if(_deltaTime &lt; FLT_EPSILON){ return;}    //空函数，也许之后会有作用    if (_openGLView)    {        _openGLView-&gt;pollInputEvents();    }    //非暂停状态    if (! _paused)    {        //scheduler更新 会使actionmanager更新和相关的schedule更新 引擎物理模拟都是在绘制之前做的        _scheduler-&gt;update(_deltaTime);        _eventDispatcher-&gt;dispatchEvent(_eventAfterUpdate);    }    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);    //切换下一场景，必须放在逻辑后绘制前，否则会出bug    if (_nextScene)    {        setNextScene();    }    kmGLPushMatrix();    //创建单位矩阵    kmMat4 identity;    kmMat4Identity(&amp;identity);    //绘制场景    if (_runningScene)    {        //递归的遍历scene中的每个node的visit生成渲染命令放入渲染队列        _runningScene-&gt;visit(_renderer, identity, false);        _eventDispatcher-&gt;dispatchEvent(_eventAfterVisit);    }    //绘制观察节点，如果你需要在场景中设立观察节点，请调用摄像机的setNotificationNode函数     if (_notificationNode)    {        _notificationNode-&gt;visit(_renderer, identity, false);//这是一个常驻节点    }    //绘制屏幕左下角的状态    if (_displayStats)    {        showStats();    }    //渲染    _renderer-&gt;render();    //渲染后    _eventDispatcher-&gt;dispatchEvent(_eventAfterDraw);    kmGLPopMatrix();    _totalFrames++;    if (_openGLView)    {        _openGLView-&gt;swapBuffers(); //交换缓冲区    }    //计算绘制时间    if (_displayStats)    {        calculateMPF();    }}</code></pre><p>其中和绘制相关的是visit的调用和render的调用，其中visit函数会调用节点的draw函数，在3.x之前的版本中draw函数就会直接调用绘制代码，3.x版本是在draw函数中生成将绘制命令放入到renderer队列中，然后renderer函数去进行真正的绘制，首先来看sprite的draw函数.</p><h4 id="渲染命令"><a href="#渲染命令" class="headerlink" title="渲染命令"></a>渲染命令</h4><pre><code>void Sprite::draw(Renderer *renderer, const kmMat4 &amp;transform, bool transformUpdated){    //检查是否超出边界，自动裁剪    _insideBounds = transformUpdated ? renderer-&gt;checkVisibility(transform, _contentSize) : _insideBounds;    if(_insideBounds)    {        //初始化        _quadCommand.init(_globalZOrder, _texture-&gt;getName(), _shaderProgram, _blendFunc, &amp;_quad, 1, transform);        renderer-&gt;addCommand(&amp;_quadCommand);        //物理引擎相关绘制边界if CC_SPRITE_DEBUG_DRAW        _customDebugDrawCommand.init(_globalZOrder);        //自定义函数        _customDebugDrawCommand.func = CC_CALLBACK_0(Sprite::drawDebugData, this);        renderer-&gt;addCommand(&amp;_customDebugDrawCommand);endif    }}</code></pre><p>这里面用了两种不同的绘制命令quadCommand初始化后就可以加入到绘制命令中，customDebugDrawCommand传入了一个回调函数，具体的命令种类会在后面介绍。其中自定义的customDebugDrawCommand命令在初始化的时候只传入了全局z轴坐标，因为它的绘制函数全部都在传入的回调函数里面，_quadCommand则需要传入<strong>全局z轴坐标，贴图名称，shader，混合，坐标点集合，坐标点集个数，变换</strong>。</p><h4 id="Render"><a href="#Render" class="headerlink" title="Render"></a>Render</h4><pre><code>void Renderer::render(){    _isRendering = true;    if (_glViewAssigned)    {        //清除        _drawnBatches = _drawnVertices = 0;        //排序        for (auto &amp;renderqueue : _renderGroups)        {            renderqueue.sort();        }        //绘制        visitRenderQueue(_renderGroups[0]);        flush();    }    clean();    _isRendering = false;}</code></pre><p>Render类中的render函数进行真正的绘制，<strong>首先排序，再进行绘制</strong>，从列表中的第一个组开始绘制。在visitRenderQueue函数中可以看到五种不同类型的绘制命令类型，分别对应五个类，这五个类都继承自RenderCommand。</p><h5 id="绘制命令"><a href="#绘制命令" class="headerlink" title="绘制命令"></a>绘制命令</h5><ol><li><p>QUAD_COMMAND：</p><p>QuadCommand类绘制精灵等。所有绘制图片的命令都会调用到这里，处理这个类型命令的代码就是绘制贴图的openGL代码，</p></li><li><p>CUSTOM_COMMAND：</p><p>自定义绘制，自己定义绘制函数，在调用绘制时只需调用已经传进来的回调函数就可以，裁剪节点，绘制图形节点都采用这个绘制，把绘制函数定义在自己的类里。这种类型的绘制命令不会在处理命令的时候调用任何一句openGL代码，而是调用你写好并设置给func的绘制函数，并自己实现一个自定义的绘制。</p></li><li><p>BATCH_COMMAND：</p><p>批处理绘制，批处理精灵和粒子,其实它类似于自定义绘制，也不会再render函数中出现任何一句openGL函数，它调用一个固定的函数。</p></li><li><p>GROUP_COMMAND：</p><p>绘制组，一个节点包括两个以上绘制命令的时候，把这个绘制命令存储到另外一个renderGroups中的元素中，并把这个元素的指针作为一个节点存储到renderGroups[0]中。</p></li></ol><h5 id="render流程"><a href="#render流程" class="headerlink" title="render流程"></a>render流程</h5><pre><code>void Renderer::addCommand(RenderCommand* command){    //获得栈顶的索引    int renderQueue =_commandGroupStack.top();    //调用真正的addCommand    addCommand(command, renderQueue);}void Renderer::addCommand(RenderCommand* command, int renderQueue){    //将命令加入到数组中    _renderGroups[renderQueue].push_back(command);}</code></pre><p>addCommand它是获得需要把命令加入到renderGroups位置中的索引，这个索引是从commandGroupStack获得的，commandGroupStack是个栈，当我们创建一个GROUP_COMMAND时，需要调用pushGroup函数，它是把当前这个命令在_renderGroups的索引位置压到栈顶，当addCommand时，调用top，获得这个位置</p><pre><code>groupCommand.init(globalZOrder);renderer-&gt;addCommand(&amp;_groupCommand);renderer-&gt;pushGroup(_groupCommand.getRenderQueueID());</code></pre><p>GROUP_COMMAND一般用于绘制的节点有一个以上的绘制命 令，把这些命令组织在一起，无需排定它们之间的顺序，他们作为一个整体被调用，所以一定要记住，栈是push，pop对应的，关于这个节点的所有的绘制命令被添加完成后，请调用pop，将这个值从栈顶弹出，否则后面的命令也会被添加到这里。</p><p> 为什么调用的起始只需调用为什么只是0，其他的呢？</p><p><code>visitRenderQueue(_renderGroups[0]);</code></p><p>它们会在处理GROUP_COMMAND被调用</p><pre><code>else if(RenderCommand::Type::GROUP_COMMAND == commandType) {    flush();    int renderQueueID = ((GroupCommand*) command)-&gt;getRenderQueueID();    visitRenderQueue(_renderGroups[renderQueueID]);}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2dx的时代UI树便利和渲染是没有分开的，遍历UI树的时候就渲染.3dx版本为了分离了ui树的遍历和渲染，先遍历生成渲染命令发到渲染队列，之后遍历渲染命令队列开始渲染.这样做的好处是渲染命令可以重用，单独的渲染可以做优化例如自动批绘制.本篇首先介绍cocos2D-X 3.x
      
    
    </summary>
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/categories/cocos2dx/"/>
    
    
      <category term="cocos2dx" scheme="https://bytemode.github.io/tags/cocos2dx/"/>
    
  </entry>
  
</feed>
